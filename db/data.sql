--
-- PostgreSQL database dump
--

-- Dumped from database version 10.9
-- Dumped by pg_dump version 10.9

SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;

--
-- Name: plpgsql; Type: EXTENSION; Schema: -; Owner: 
--

CREATE EXTENSION IF NOT EXISTS plpgsql WITH SCHEMA pg_catalog;


--
-- Name: EXTENSION plpgsql; Type: COMMENT; Schema: -; Owner: 
--

COMMENT ON EXTENSION plpgsql IS 'PL/pgSQL procedural language';


SET default_tablespace = '';

SET default_with_oids = false;

--
-- Name: links; Type: TABLE; Schema: public; Owner: david
--

CREATE TABLE public.links (
    id bigint NOT NULL,
    title character varying(255),
    summary text,
    url text,
    published_at timestamp without time zone DEFAULT timezone('UTC'::text, now())
);


ALTER TABLE public.links OWNER TO david;

--
-- Name: links_id_seq; Type: SEQUENCE; Schema: public; Owner: david
--

CREATE SEQUENCE public.links_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.links_id_seq OWNER TO david;

--
-- Name: links_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: david
--

ALTER SEQUENCE public.links_id_seq OWNED BY public.links.id;


--
-- Name: page_tags; Type: TABLE; Schema: public; Owner: david
--

CREATE TABLE public.page_tags (
    id bigint NOT NULL,
    page_id bigint,
    tag_id bigint
);


ALTER TABLE public.page_tags OWNER TO david;

--
-- Name: page_tags_id_seq; Type: SEQUENCE; Schema: public; Owner: david
--

CREATE SEQUENCE public.page_tags_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.page_tags_id_seq OWNER TO david;

--
-- Name: page_tags_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: david
--

ALTER SEQUENCE public.page_tags_id_seq OWNED BY public.page_tags.id;


--
-- Name: pages; Type: TABLE; Schema: public; Owner: david
--

CREATE TABLE public.pages (
    id bigint NOT NULL,
    title character varying(255),
    intro text,
    content text,
    published boolean DEFAULT false,
    published_at timestamp without time zone DEFAULT timezone('UTC'::text, now())
);


ALTER TABLE public.pages OWNER TO david;

--
-- Name: pages_id_seq; Type: SEQUENCE; Schema: public; Owner: david
--

CREATE SEQUENCE public.pages_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.pages_id_seq OWNER TO david;

--
-- Name: pages_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: david
--

ALTER SEQUENCE public.pages_id_seq OWNED BY public.pages.id;


--
-- Name: tags; Type: TABLE; Schema: public; Owner: david
--

CREATE TABLE public.tags (
    id bigint NOT NULL,
    title character varying(255),
    intro text,
    enabled boolean DEFAULT true
);


ALTER TABLE public.tags OWNER TO david;

--
-- Name: tags_id_seq; Type: SEQUENCE; Schema: public; Owner: david
--

CREATE SEQUENCE public.tags_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.tags_id_seq OWNER TO david;

--
-- Name: tags_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: david
--

ALTER SEQUENCE public.tags_id_seq OWNED BY public.tags.id;


--
-- Name: links id; Type: DEFAULT; Schema: public; Owner: david
--

ALTER TABLE ONLY public.links ALTER COLUMN id SET DEFAULT nextval('public.links_id_seq'::regclass);


--
-- Name: page_tags id; Type: DEFAULT; Schema: public; Owner: david
--

ALTER TABLE ONLY public.page_tags ALTER COLUMN id SET DEFAULT nextval('public.page_tags_id_seq'::regclass);


--
-- Name: pages id; Type: DEFAULT; Schema: public; Owner: david
--

ALTER TABLE ONLY public.pages ALTER COLUMN id SET DEFAULT nextval('public.pages_id_seq'::regclass);


--
-- Name: tags id; Type: DEFAULT; Schema: public; Owner: david
--

ALTER TABLE ONLY public.tags ALTER COLUMN id SET DEFAULT nextval('public.tags_id_seq'::regclass);


--
-- Data for Name: links; Type: TABLE DATA; Schema: public; Owner: david
--

COPY public.links (id, title, summary, url, published_at) FROM stdin;
\.


--
-- Data for Name: page_tags; Type: TABLE DATA; Schema: public; Owner: david
--

COPY public.page_tags (id, page_id, tag_id) FROM stdin;
\.


--
-- Data for Name: pages; Type: TABLE DATA; Schema: public; Owner: david
--

COPY public.pages (id, title, intro, content, published, published_at) FROM stdin;
111	什么是 XMPP	XMPP	## 什么是XMPP\r\n\r\nXMPP（可扩展消息处理现场协议）是基于可扩展标记语言（XML）的协议，它用于即时消息（IM）以及在线通讯的相关场景。XMPP已被IETF国际标准组织完成了标准化工作。标准化的核心结果分为两部分； 核心的XML流传输协议和基于XML流传输的即时通讯扩展。应用XMPP的核心XML流传输协议的定义使得XMPP能够在一个比以往网络通信协议更规范的平台上。借助于XML易于解析和阅读的特性，使得XMPP的协议能够非常容易被理解和调试。XMPP的即时通讯扩展应用部分是根据IETF在这之前对即时通讯的一个抽象定义的，与其他业已得到广泛使用的即时通讯协议，诸如AIM，QQ等相比，XMPP更加开放，更容易扩展并且天生就具有分布式特性。\r\n\r\n由于XMPP协议是一个开源形式组织产生的网络即时通信协议，它的协议内容是开放的，任何人和组织都可以实现该协议，同时XMPP协议还非常强调各不同组织之间的服务器通信和互操作性，这让各个组织之间的消息互通不再是难题了。\r\n\r\n## XMPP的历史\r\n\r\n1999年1月，Jeremie Miller发布了Jabber协议，这是一个开放的且基于实时XML流的传输协议。同年，Jeremie Miller向Jabber社区提交了一个声明，承诺Jabber社区会支持IEEE的标准化，其中包含了Jabber项目的目标：支持开放的协议并且支持即时通信的互操作性。\r\n2000年与2001年，IEEE在推进IMPP，而Jabber社区则不断的在实现开放标准，并编写文档和完善协议。\r\n2002年，XMPP工作组成立，并开始完善协议。\r\n2003年及以后，就是我们所知道的，XMPP不断的发展壮大。\r\n\r\n我们可以从这里看出，XMPP是一个非常有历史的协议，并且XMPP也经过了大量的实战检验。当然，在XMPP的发展中，不单单有Jeremie Miller全身心投入，更有Google的大量推广。我们所周知的GTalk和GMail中的实时聊天都是基于XMPP协议的。\r\n\r\n## XMPP能做什么\r\n\r\n虽然我们因为即时通信（IM）对XMPP有了了解，但是XMPP协议不局限于即时通音（IM）。因为XMPP在协议制定支出着眼点很高，我们可以在XMPP的协议上大量扩展功能。其中包括，但不限于：\r\n\r\n1.Jabber-RPC\r\n2.VPN\r\n3.IOT\r\n\r\n## XMPP服务器\r\n\r\neJabberd Erlang开发的高性能服务器。\r\nMongooseIM 在eJabberd的基础上进行二次开发，提供很多方便使用且非常高性能的服务器。\r\nOpenfire Java开发的也比较常用的一款服务器，但是性能一般般。\r\nProsody IM Lua开发的，不是很常见，据说非常轻量级。	f	2019-09-05 15:22:02.88859
112	Erlang 的 Port Drivers	Erlang	## 什么是Ports\r\n\r\nPorts可以说是Erlang提供的一种和Erts虚拟机以外世界通信的最基本的方式。Ports为Erlang提供了双向字节流，让Erlang可以非常好的和外部程序进行通信。默认情况下，外部程序会在一个全新的OS进程中运行，Erlang通过外部程序的标准输入（文件句柄0）和标准输出（文件句柄1）进行通讯。创建Port的Erlang进程一般我们将它成为，Port的所有者，所有和Port的通信都会通过Port所有者进程进行，当所有者进程停止运行了，外部程序也应该退出。\r\n\r\n## 什么是Port Drivers\r\n\r\n当然我们也可以用C或者C++编写一个动态链接库文件（.so或者.dll）让Erlang动态的加载到虚拟机内，这个动态链接库不会创建新的OS进程，而是直接使用Erlang的进程。但是，Erlang依然使用和Ports，我们将这种内联的Port称为Port Drivers。\r\n\r\n\r\n## Ports和Port Drivers的差异\r\n\r\n创建方式的不同：Port是通过erlang:open_port直接来创建的，而Port Drivers是先要通过erl_ddll:load_driver加载到虚拟机内后再通过erlang:open_port完成创建的。\r\n\r\n运行方式的不同：Port是运行在Erlang虚拟机外的OS进程和Erlang虚拟机不共享进程，不会引起Erlang虚拟机内存泄露和崩溃，而Port Drivers和Erlang的虚拟机共享进程，如果处理不当会引起Erlang虚拟机的崩溃和内存泄露。\r\n\r\n性能的差异：Port在创建的时候，beam.smp会使用vfork复制整个进程，这个会导致整个beam.smp进程阻塞，而Port Drivers只是创建一堆数据，所以性能不用说。\r\n\r\n\r\n## Port Drivers是如何调度的\r\n\r\n在erl_port_task.c中我们可以找到erts_port_task_schedule函数，正式这个函数将Port Driver调度到Erlang虚拟机上的scheduler上的。erts_port_task_schedule函数会在erl_check_io的时候被调用。\r\n\r\n从这些代码中我们可以观察到：\r\n\r\n1.Port Drivers并不会一直放在ErtsPortTaskSched当中。\r\n\r\n2.Erlang的Port Drivers只有在Erlang进程通过erlang:control和erlang:command函数发送命令时，会将Port放入RunQueue。\r\n\r\n3.Erlang的Port Drivers向Erlang虚拟机注册IO任务，erlang会在erl_check_io放到RunQueue中。\r\n\r\n\r\n## Port Drivers为什么这么实现和调度\r\n\r\n1.Erlang的虚拟机的调度器是一个软实时的调度器，它在调度Erlang进程的时候会为Erlang进程分配固定的reduction。Erlang虚拟机规定了每个Erlang的操作的reduction的数量，当Erlang进程的reduction减少到位0的时候，将进行Erlang进程切换。\r\n\r\n2.Erlang的虚拟机要保证调度器是无阻塞的，才能达到软实时调度。通过reduction机制，可以保证不执行IO操作的Erlang进程达到无阻塞。为了让IO操作不阻塞调度器，那么就必须让IO操作变成一种任务。\r\n\r\n3.Port Drivers很多时候，都是为了完成外部通信操作或者IO操作。因此Erlang将所有的IO操作都和事件驱动进行关联，当不能直接向事件驱动器的注册的IO操作则通过异步线程模拟成IO事件。这样就可以将IO操作变成IO任务，这样就如同无阻塞的操作一样。\r\n\r\n4.Port Drivers可以说是Erlang虚拟机对IO操作的高级抽象，这样就将复杂的外部世界和非IO操作尽最大可能的隔离开了。不但可大大减少代码量，同时也提高了平台的兼容性。最终Erlang的虚拟机内，将所有的IO操作和计算抽象成了执行队列上的一个又一个任务，方便运行在多核心上的调度器进行调度和任务密取，提高并发。	f	2019-09-05 15:22:02.889337
113	eJabberd 的 Hook 系统	XMPP	## 什么是Hook\r\n\r\n### Hook的广义理解\r\n\r\n1. Hook直译为“钩子”，钩子就是在事件传送到终点前截获并监控事件的传输或使用内存改写技术改写某个函数的入口点，并且能够在钩上事件时或替换函数后，处理一些自己特定的事件；\r\n1. Hook使它能够将自己的代码“融入”被勾住（Hook）的进程中，成为目标进程的一部分； \r\n1. Hook可以在不改变核心流程的情况，进行一些额外操作。\r\n\r\n### eJabberd的Hook\r\n\r\neJabberd中的Hook可以认为是eJabberd的插件系统，由于Erlang的语言的特性导致eJabberd不是很容易实现常见的插件系统。因此eJabberd设计了Hook系统，Hook系统完全是基于eJabberd的核心流程和事件订阅发布机制。\r\n\r\n在eJabberd中，eJabbrd预先定义了一系列的事件。在eJabberd中，每个模块都可以订阅这些事件，当这些事件发生时，订阅的模块就会被调用起来，进行按顺序的操作。\r\n\r\n#### eJabberd的Hook的核心功能\r\n\r\n1. 管理eJabberd中的所有订阅者（Hook模块）；\r\n1. 事件发生时，调用订阅者处理事件；\r\n\r\n## Hook系统如何工作\r\n\r\n### Hook系统特性\r\n\r\n1. 分域名管理hook，eJabberd支持一个系统绑定多个域名，所以Hook系统可以为每个域名管理一组hook；\r\n1. 按优先级调用，优先级值越小的hook，越先被调用;\r\n1. 事件调用动作在事件发布者进程中执行；\r\n1. hook安全执行，hook不管引起何种异常，均不影响事件发布者进程；\r\n\r\n### Hook系统的启动\r\n\r\neJabberd的ejabberd_hooks进程是一个非常规范的gen_server进程，启动之后会创建一个名为hooks的命名ets表。\r\n\r\n### Hook的添加和删除\r\n\r\neJabberd的hook是具备优先级的，所以在添加hook的时候，会对将新的hook放入原有hook表中进行排序，请看下面的代码：\r\n``` erlang\r\nhandle_call({add, Hook, Host, Module, Function, Seq}, _From, State) ->\r\n    Reply = case ets:lookup(hooks, {Hook, Host}) of\r\n                [{_, Ls}] ->\r\n                    El = {Seq, Module, Function},\r\n                    case lists:member(El, Ls) of\r\n                        true ->\r\n                            ok;\r\n                        false ->\r\n                            NewLs = lists:merge(Ls, [El]),\r\n                            ets:insert(hooks, {{Hook, Host}, NewLs}),\r\n                            ok\r\n                    end;\r\n                [] ->\r\n                    NewLs = [{Seq, Module, Function}],\r\n                    ets:insert(hooks, {{Hook, Host}, NewLs}),\r\n                    mongoose_metrics:create_generic_hook_metric(Host, Hook),\r\n                    ok\r\n            end,\r\n    {reply, Reply, State};\r\nhandle_call({delete, Hook, Host, Module, Function, Seq}, _From, State) ->\r\n    Reply = case ets:lookup(hooks, {Hook, Host}) of\r\n                [{_, Ls}] ->\r\n                    NewLs = lists:delete({Seq, Module, Function}, Ls),\r\n                    ets:insert(hooks, {{Hook, Host}, NewLs}),\r\n                    ok;\r\n                [] ->\r\n                    ok\r\n            end,\r\n    {reply, Reply, State};\r\n```\r\n由于ets表不具备事务性操作，ejabberd_hooks使用handle_call序列化这一添加和删除操作，保证操作顺序。在ets表中保存的是已经经过排序好的hook列表，这样可以大大减少每次执行hook所需要的时间。\r\n\r\n### Hook的触发\r\n\r\n因为所有的ejabberd_c2s进程都会使用Hook系统，如果将调用都让ejabberd_hooks进程来操作， 会产生大量的延迟甚至会引起进程的崩溃。因此ejabberd的Hook系统，选择由事件的发布者进程来执行这些hook的调用的操作。请看下面的代码：\r\n```erlang\r\nrun_fold(Hook, Val, Args) ->\r\n    run_fold(Hook, global, Val, Args).\r\n \r\nrun_fold(Hook, Host, Val, Args) ->\r\n%% 针对Host取出相应的hook\r\n    Res = case ets:lookup(hooks, {Hook, Host}) of\r\n        [{_, Ls}] ->\r\n            mongoose_metrics:increment_generic_hook_metric(Host, Hook),\r\n            run_fold1(Ls, Hook, Val, Args);\r\n        [] ->\r\n            Val\r\n    end,\r\n    record(Hook, Res).\r\n```\r\n Hook系统将自身的ets直接暴露出来，让所有的事件发布者进程直接查询订阅相关事件的hook，之后使用一个内部函数run_fold1来进行安全执行。\r\n```erlang\r\nrun_fold1([], _Hook, Val, _Args) ->\r\n    Val;\r\nrun_fold1([{_Seq, Module, Function} | Ls], Hook, Val, Args) ->\r\n    Res = hook_apply_function(Module, Function, Hook, Val, Args),\r\n    case Res of\r\n        {'EXIT', Reason} ->\r\n            ?ERROR_MSG("~p~nrunning hook: ~p",\r\n                       [Reason, {Hook, Args}]),\r\n            run_fold1(Ls, Hook, Val, Args);\r\n        stop ->\r\n            stopped;\r\n        {stop, NewVal} ->\r\n            NewVal;\r\n        NewVal ->\r\n            run_fold1(Ls, Hook, NewVal, Args)\r\n    end.\r\n%% 优先处理匿名函数\r\nhook_apply_function(_Module, Function, _Hook, Val, Args) when is_function(Function) ->\r\n    safely:apply(Function, [Val | Args]);\r\n%% 处理模块到处的函数    \r\nhook_apply_function(Module, Function, Hook, Val, Args) ->\r\n    Result = safely:apply(Module, Function, [Val | Args]),\r\n    record(Hook, Module, Function, Result).\r\n```\r\nsafely:apply函数就是使用try catch包裹要执行的函数，捕获所有异常从而不影响事件发布进程的执行。\r\n\r\n在hook被执行的过程中，高优先级的hook可以通过返回stop或{stop,NewVal}来阻止低优先级的hook被执行。同时在hook链的实行过程中，高优先级的hook可以改变低优先级hook被执行时传入的初始值。在整个hook链结束执行的时候，会返回最后一个hook的执行结果给事件发布者，事件发布者可以根据这个值进行进一步的操作。\r\n\r\n## 开发Hook的注意事项\r\n\r\n1. hook操作不应该是一个无法退出的循环操作，因为这会影响到原有流程的执行，会引发不可预知的事情；\r\n1. hook函数尽量不要包含私有的上下文，虽然eJabberd的Hook系统中可以这样做，但是非常不推荐，因为Hook系统不会关联事件发布者到hook函数中；\r\n1. hook的函数尽量不要做耗时的超做，因为这会占用事件发布进程的时间片，影响消息的效率；	f	2019-09-05 15:22:02.890207
114	什么是 Linux，什么是 Linux 发行版	Linux/Docker	## Linux历史背景\r\n\r\n### 什么是Linux\r\n\r\nLinux是一套免费使用和自由传播的类Unix操作系统，是一个基于POSIX和UNIX的多用户、多任务、支持多线程和多CPU的操作系统。它能运行主要的UNIX工具软件、应用程序和网络协议。它支持32位和64位硬件。Linux继承了Unix以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统。\r\n\r\n但是，事实上Linux只是GNU/Linux的内核部分，不过由于GNU的内核（详细可以参见GNU Hurd）迟迟无法推出，并且人们已经习惯将GNU/Linux简称为Linux。\r\n\r\n### Linux怎么来的\r\n\r\n一个名叫Linus Torvalds的芬兰大学生想在他的Intel 80386上使用类似Unix的系统，最开始他使用了Minx这个类Unix的变种（因为Minix是微内核，而Unix当时主要为宏内核）。但是Minx当时对于80386 的支持是非常脆弱的，因此他决定要开发出一个全功能的、支持POSIX标准的、类Unix的操作系统内核，该系统吸收了BSD和System V的优点，同时摒弃了它们的缺点。\r\n\r\n### 什么是Unix\r\n\r\nUNIX也是一个操作系统，该操作系统是美国贝尔实验室的Ken.Thompson和Dennis Ritchie 于1969 年夏在DEC PDP-7 小型计算机上开发的一个分时操作系统。Ken Thompson 为了能在闲置不用的PDP-7 计算机上运行他非常喜欢的星际旅行（Space travel）游戏，于是在1969 年夏天乘他夫人回家乡加利福尼亚渡假期间，在一个月内开发出了UNIX 操作系统的原型。当时使用的是BCPL语言（基本组合编程语言），后经Dennis Ritchie 于1972 年用移植性很强的C语言进行了改写，使得UNIX 系统在大专院校得到了推广。现在所说的Unix一般指代的是Unix商标和符合该规范并得到授权的系统，现在还可以称为的Unix系统的有，IBM的AIX，Orcale的Solaris和Apple的MacOS X。\r\n### 什么是GNU\r\n\r\nGNU代表`GNU not Unix`，GNU是自由软件之父Richard Stallman在1984年组织开发的一个完全基于自由软件的软件体系，与此相应的有一分通用公共许可证（General Public License，简称GPL）。Linux以及与他有关的大量软件是在GPL的推动下开发和发布的。该组织为GNU/Linux外围软件做出了巨大的贡献，例如说编译器GCC，常用的Bash等。\r\n\r\n### 什么是POSIX标准\r\n\r\n这个概念非常重要。POSIX（Portable Operating System Interface for Computing System）是由IEEE 和ISO/IEC 开发的一簇标准。 该标准是基于现有的UNIX实践和经验，描述了操作系统的调用服务接口，用于保证编制的应用程序可以在源代码一级上在多种操作系统上移植运行。\r\n### 为什么Linux得到了发展\r\n\r\n在当时有Unix了和很多Unix的变种，为什么发展到今天，只有Linux得到了更广泛的发展呢？\r\n#### 版权之争的Unix\r\n\r\n当时Unix的两个主流版本是AT&T的System V和加州伯克利分校开发的BSD。\r\n\r\n和AT&T的System V分支不同，BSD由大学发布，主要是用于学术研究，希望可以开源和免费软件的形式发布。但是，4.3版本以及之前的BSD中都包括了AT&T的源代码，毫无疑问，这些源代码应该服从AT&T的License。因此Unix版权的拥有者和相关公司，为了这些代码和版权问题，打的不可开交，这大大的影响了Unix的两个发行版的开发和发展。\r\n\r\n#### 过于学术的Minx\r\n\r\nMINIX 系统是由Andrew S. Tanenbaum（AST）开发的。因为AT&T的政策改变，在Version 7 Unix推出之后，发布新的使用许可协议，将UNIX源代码私有化，在大学中不再能使用UNIX源代码Andrew S. Tanenbaum为了能在课堂上教授学生操作系统运作的实务细节，决定在不使用任何AT&T的源代码前提下，自行开发与UNIX兼容的操作系统，以避免版权上的争议。他以小型UNIX（mini-UNIX）之意，将它称为MINIX。到1991 年时版本是1.5，到2017年Minx的版本是3.0。Minix在核心设计上采用微核心，即将操作系统分成微核心和其上的提供文件系统、存储器管理、驱动程序等服务的服务程序，但是正如人们后来所知的微内核过于复杂以及效率问题，在开发和实用上困难很多。\r\n\r\n#### Linus的推广\r\n\r\nLinus在互联网和GNU发展的初期，就很有远见的看到了互联网会推动软件的发展。充分的善用了人和（在comp.os.minix推广Linux，以及和Andrew的对喷，可见英文写作和嘴炮能力多重要），天时（Unix的版权之争，让BSD足足晚了好多年才被人们认知）和地利（GNU/Hurd难产，Linux又使用GPL，Linux和GNU一拍即合）。抓住了互联网和免费的的大潮。\r\n\r\n## Linux的发行版\r\n\r\n### 什么是Linux的发行版\r\n\r\n就Linux的本质来说，它只是操作系统的核心，负责控制硬件、管理文件系统、程序进程等，并不给用户提供各种工具和应用软件。所谓工欲善其事，被必先利其器，一套在优秀的操作系统核心，若没有强大的应用软件可以使用，如C/C++编译器、C/C++库、系统管理工具、网络工具、办公软件、多媒体软件、绘图软件等，也无法发挥它强大的功能，用户也无法仅仅使用这个系统核心进行工作，因此人们以Linux内核为中心，再集成搭配各种各样的系统管理软件或应用工具软件组成一套完整的操作系统，如此的组合便称为Linux发行版。\r\n\r\n### 知名的发型版\r\n因为GNU/Linux本身是开源的，所以任何人，任何厂商只要在遵循社区游戏规则的前提下构建自己的发行版本，目前已知大约有300个Linux的发行版（看着头就疼，还是BSD系列好，OpenBSD和FreeBSD主打，DragonFlyBSD和NetBSD玩票）。所以这里只介绍一些比较知名的发行版本。可以看下Linux发行版流行的一张图。\r\n![](http://otioh6qxv.bkt.clouddn.com/545620da36e9914901db2f74ff316e22_b.png)\r\n\r\n#### Slackware\r\n\r\nSlackware可以说是历史悠久，与很多其他的发行版不同，它坚持KISS（Keep It Simple Stupid）的原则。配置系统会有一些困难，但是更有经验的用户会喜欢这种方式的透明性和灵活性。Slackware 很多特性体现出了KISS原则，最为有名的一些例子就是不依赖图形界面的文本化系统配置、传统的服务管理方式和不解决依赖的包管理方式。它的最大特点就是安装灵活，目录结构严谨，版本力求稳定而非追新。Slackware的软件包都是通常的tgz(tar/gzip) 或者txz(xz) 格式文件再加上安装脚本。Tgz/Txz 对于有经验的用户来说，比RPM更为灵活，并避免了APT 之类管理器可能带来的的依赖地狱。\r\n\r\n#### Fedora\r\n\r\nFedora是一套从Red Hat Linux发展出来的免费Linux系统。Fedora的前身就是Red Hat Linux。Fedora由一个强大的社群开发，这个社群的成员以自己的不懈努力，提供并维护自由、开放源码的软件和开放的标准。Fedora项目由 Fedora 基金会管理和控制，得到了Red Hat, Inc. 的支持。Red Hat会将一些先行技术放入Fedora进行试验（我会告诉你，你是Red Hat的小白鼠嘛），它尤其可以为在Red Hat和CentOS环境下工作的那些人带来便利。它使用RPM包来安装软件，并且提供repo这种包管理器来简化软件包的安装流程和进行软件包升级。\r\n\r\n#### Debian\r\n\r\nDebian的目标是提供一个稳定容错的Linux版本。支持Debian的不是某家公司，而是许多在其改进过程中投入了大量时间的开发人员，这种改进吸取了早期Linux的经验。Debian以其稳定性著称（我会告诉你，这个版本的软件万年不更新嘛），是很多服务器和程序员所喜爱的版本之一。Debian的创始人自杀了，实在是让人惋惜。Debian作为一个服务器专用发行版是非常稳定的，基本上都不需要折腾。\r\n\r\n#### Red Hat\r\n\r\n可能这是最著名的Linux版本了，Red Hat Linux已经创造了自己的品牌，越来越多的人听说过它。Red Hat在1994年创业，当时聘用了全世界500多名员工，他们都致力于开放的源代码体系。它拥有自己的公司，能向用户提供一套完整的服务，这使得它特别适合在公共网络中使用。这个版本的Linux也使用最新的内核，还拥有大多数人都需要使用的主体软件包。\r\nRed Hat Linux的安装过程也十分简单明了。它的图形安装过程提供简易设置服务器的全部信息。磁盘分区过程可以自动完成，还可以选择GUI工具完成，即使对于Linux新手来说这些都非常简单。选择软件包的过程也与其他版本类似；用户可以选择软件包种类或特殊的软件包。系统运行起来后，用户可以从Web站点和 Red Hat那里得到充分的技术支持。Red Hat是一个符合大众需求的最优版本（我会告诉你，你只要拿钱就行了嘛）。在服务器和桌面系统中它都工作得很好。Red Hat的唯一缺陷是带有一些不标准的内核补丁，这使得它难于按用户的需求进行定制。 Red Hat通过论坛和邮件列表提供广泛的技术支持，它还有自己公司的电话技术支持，后者对要求更高技术支持水平的集团客户更有吸引力。\r\n\r\n#### SuSE\r\n\r\nSuSE的总部设立在德国，已经奋斗了多年。SuSE一直致力于创建一个连接数据库的最佳Linux版本。为了实现这一目的，SuSE与Oracle 和IBM合作，以使他们的产品能稳定地工作。SuSE还开发了SuSE Linux eMail Server III，一个非常稳定的电子邮件群组应用。在SuSE发行版，可以非常方便地访问Windows磁盘，这使得两种平台之间的切换，以及使用双系统启动变得更容易。SuSE的硬件检测非常优秀，该版本在服务器和工作站上都用得很好。SuSE拥有界面友好的安装过程，还有图形管理工具，可方便地访问Windows磁盘，对于终端用户和管理员来说使用它同样方便，这使它成为了一个强大的服务器平台。\r\n\r\n#### CentOS\r\n\r\nCentOS（Community ENTerprise Operating System）是来自于Red Hat Enterprise Linux依照开放源代码规定释出的源代码所编译而成。由于出自同样的源代码，因此有些要求高度稳定性的服务器以CentOS替代商业版的Red Hat Enterprise Linux使用（我会告诉你，以为企业想省钱，运维要靠这个东西来赚钱嘛，国内运维主流是CentOS剩下版本很少）。两者的不同，在于CentOS并不包含封闭源代码软件，CentOS 是一个基于Red Hat Linux 提供的可自由使用源代码的企业级Linux发行版本。每个版本的CentOS都会获得十年的支持（通过安全更新方式）。新版本的 CentOS 大约每两年发行一次，而每个版本的 CentOS 会定期（大概每六个月）更新一次，以便支持新的硬件。这样，建立一个安全、低维护、稳定、高预测性、高重复性的 Linux 环境。\r\n\r\n#### Ubuntu\r\n\r\nUbuntu是一个基于Debian的发型版本，但是软件更新频度相对较高。它提供两个主要版本，一个是桌面版本，一个是服务器版本，但是Ubuntu比较注重桌面版本。Ubuntu在发布版本的时候，会发布一个LTS版本，这个版本会提供长达三年的升级支持。\r\n\r\n#### Gentoo\r\n\r\nGentoo它能为几乎任何应用程序或需求自动地作出优化和定制。追求极限的配置、性能，以及顶尖的用户和开发者社区，都是Gentoo体验的标志特点。 Gentoo的哲学是自由和选择，得益于一种称为Portage的技术，Gentoo能成为理想的安全服务器、开发工作站、专业桌面、游戏系统、嵌入式解决方案或者别的东西。Gentoo Linux是滚动升级的发行版，所以在上游软件发布很短时间后，其上就会有软件包可用。Gentoo的基础系统和软件包都是根据用户指定的USE标识直接从源代码构建（我会告诉你，这玩意难用死了嘛，至少不要用Python写好不好）。\r\n\r\n#### Arch\r\n\r\nArch Linux是一个 “以用户为中心”的发行版。此发行版是为了满足贡献者的需求，而不是为了吸引尽可能多的用户。Arch 适用于乐于自己动手的用户，他们愿意花时间阅读文档，解决自己的问题。\r\n报告问题、完善 Wiki 社区文档、为其它用户提供技术支持。Arch 用户仓库 收集用户贡献的软件包，Arch的最大优势就是滚动升级。\r\n\r\n##Linux发行版选择\r\n\r\n### 新手\r\n\r\n作为Linux的新手，简单易用的Ubuntu桌面的LTS或者Debian是非常不错的选择，因为这两个版本的包管理系统非常成熟，桌面也非常简洁。\r\n\r\n### 动手能力强的\r\n\r\n可选发型版本就比较多了，例如说Gentoo，Arch和Slackware，包括这里没有列举的LFS（我会告诉你，用了之后你会怀疑，这也算发行版嘛）。\r\n\r\n### 研发或运维\r\n\r\n根据公司实际使用情况选吧，但是绝大部分国内公司都会选CentOS（我会告诉你，运维圈内不会CentOS会被鄙视嘛）。所以好好的用Fedora，CentOS和Red Hat才是正道。	f	2019-09-05 15:22:02.997188
115	Erlang 集群名字注册	Erlang	## Erlang中的global和local名字\r\n\r\n在开发Erlang/OTP程序的时候，看到最多的就是gen_server，在调用gen_server:start_link是，经常会看到{global,?MODULE}或{local,?MODULE}。那么这之间有什么差异呢？\r\n\r\n### Erlang进程的名字\r\n\r\nErlang在创建的进程的时候，给予Erlang进程一个PID作为进程的标识。那么经常使用的命名进程是怎么来的呢？是调用erlang:register这个函数将原子和PID进行关联，从而产生了命名的Erlang进程。而erlang:register函数接收的第一个参数可以看到是一个原子，而不是一个元组。难么gen_server为什么会使用一个元组呢？\r\n\r\n### gen_server是如何创建进程\r\n先看下gen_server:start_link的代码\r\n```erlang\r\nstart_link(Name, Mod, Args, Options) ->\r\n    gen:start(?MODULE, link, Name, Mod, Args, Options).\r\n```\r\n从这里看到gen_server是调用gen模块进行进程创建的，那么gen模块又是如何创建进程的：\r\n```erlang\r\n-spec start(module(), linkage(), emgr_name(), module(), term(), options()) ->\r\n    start_ret().\r\n \r\nstart(GenMod, LinkP, Name, Mod, Args, Options) ->\r\n    case where(Name) of\r\n    undefined ->\r\n        do_spawn(GenMod, LinkP, Name, Mod, Args, Options);\r\n    Pid ->\r\n        {error, {already_started, Pid}}\r\n    end.\r\n \r\n-spec start(module(), linkage(), module(), term(), options()) -> start_ret().\r\n \r\nstart(GenMod, LinkP, Mod, Args, Options) ->\r\n    do_spawn(GenMod, LinkP, Mod, Args, Options).\r\n \r\n%%-----------------------------------------------------------------\r\n%% Spawn the process (and link) maybe at another node.\r\n%% If spawn without link, set parent to ourselves 'self'!!!\r\n%%-----------------------------------------------------------------\r\ndo_spawn(GenMod, link, Mod, Args, Options) ->\r\n    Time = timeout(Options),\r\n    proc_lib:start_link(?MODULE, init_it,\r\n            [GenMod, self(), self(), Mod, Args, Options], \r\n            Time,\r\n            spawn_opts(Options));\r\ndo_spawn(GenMod, _, Mod, Args, Options) ->\r\n    Time = timeout(Options),\r\n    proc_lib:start(?MODULE, init_it,\r\n           [GenMod, self(), self, Mod, Args, Options], \r\n           Time,\r\n           spawn_opts(Options)).\r\n \r\ndo_spawn(GenMod, link, Name, Mod, Args, Options) ->\r\n    Time = timeout(Options),\r\n    proc_lib:start_link(?MODULE, init_it,\r\n            [GenMod, self(), self(), Name, Mod, Args, Options],\r\n            Time,\r\n            spawn_opts(Options));\r\ndo_spawn(GenMod, _, Name, Mod, Args, Options) ->\r\n    Time = timeout(Options),\r\n    proc_lib:start(?MODULE, init_it,\r\n           [GenMod, self(), self, Name, Mod, Args, Options], \r\n           Time,\r\n           spawn_opts(Options)).\r\n```\r\n 可以清楚的看到，使用的proc_lib，而proc_lib是对erlang:spawn_link进行封装，以确保初始化函数能正确运行，那么注册名字的秘密就在gen:init_it中。在gen:init_it中可以看到一个内部函数name_register\r\n```erlang\r\nname_register({local, Name} = LN) ->\r\n    try register(Name, self()) of\r\n    true -> true\r\n    catch\r\n    error:_ ->\r\n        {false, where(LN)}\r\n    end;\r\nname_register({global, Name} = GN) ->\r\n    case global:register_name(Name, self()) of\r\n    yes -> true;\r\n    no -> {false, where(GN)}\r\n    end;\r\nname_register({via, Module, Name} = GN) ->\r\n    case Module:register_name(Name, self()) of\r\n    yes ->\r\n        true;\r\n    no ->\r\n        {false, where(GN)}\r\n    end.\r\n```\r\n 此时此刻，可以看到global和local的明显差异。\r\n\r\n### local和global的区别\r\n从上面的代码和对Erlang虚拟机的跟踪可以知道，erlang:register管理的名字和进程PID关联表只是调用者本地的Erlang虚拟机内的，不是整个集群中的。而global:register_name是通过global模块对集群中所有Erlang虚拟机进行操作。从这可以看出，Erlang语言本身并没有所谓本地名字或集群名字的概念，而这个概念是OTP当中的（但是Erlang有本地节点进程和远程节点进程的概念）。\r\n\r\n## Global模块分析\r\n\r\n### global模块功能\r\n\r\n1.管理全局名字\r\n2.管理全局锁\r\n3.维护Erlang集群的互联互通\r\n\r\n### global模块启动\r\n\r\n该模块是在Erlang节点启动的时候自动被启动的，并且会组册一个名为global_name_server的进程。并且需要注意的是global模块本身就是一个gen_server，不过为了避免死循环，global模块使用gen_server注册的是本地名字。在global进程创建成功后，建立了大量的ets表，其中global_names表，global_pid_names表就是用来管理全局命名的。\r\n\r\n### global名字注册\r\n\r\n注册名字的时候，就是让所有节点执行{register,Name,Pid,Method}。可以看下面这段代码：\r\n```erlang\r\nregister_name(Name, Pid) when is_pid(Pid) ->\r\n    register_name(Name, Pid, fun random_exit_name/3).\r\n     \r\nregister_name(Name, Pid, Method0) when is_pid(Pid) ->\r\n    Method = allow_tuple_fun(Method0),\r\n    Fun = fun(Nodes) ->\r\n        case (where(Name) =:= undefined) andalso check_dupname(Name, Pid) of\r\n            true ->\r\n                gen_server:multi_call(Nodes,\r\n                                      global_name_server,\r\n                                      {register, Name, Pid, Method}),\r\n                yes;\r\n            _ ->\r\n                no\r\n        end\r\n    end,\r\n    ?trace({register_name, self(), Name, Pid, Method}),\r\n    gen_server:call(global_name_server, {registrar, Fun}, infinity).\r\n```\r\n 当gobal进程收到了{register,Name,Pid,Method}消息后，会向在global进程建立时建立的另一个无名进程发送消息{trans_all_known, Fun, From}，这个无名进程的代码如下：\r\n ```erlang\r\n loop_the_registrar() ->\r\n    receive\r\n        {trans_all_known, Fun, From} ->\r\n            ?trace({loop_the_registrar, self(), Fun, From}),\r\n            gen_server:reply(From, trans_all_known(Fun));\r\n    Other ->\r\n            unexpected_message(Other, register)\r\n    end,\r\n    loop_the_registrar().\r\n \r\nunexpected_message({'EXIT', _Pid, _Reason}, _What) ->\r\n    %% global_name_server died\r\n    ok;\r\nunexpected_message(Message, What) -> \r\n    error_logger:warning_msg("The global_name_server ~w process "\r\n                             "received an unexpected message:\\n~p\\n", \r\n                             [What, Message]).\r\n```\r\n这个进程会使用trans_all_known来执行传入的函数，trans_all_known函数代码如下：\r\n```erlang\r\ntrans_all_known(Fun) ->\r\n    Id = {?GLOBAL_RID, self()},\r\n    Nodes = set_lock_known(Id, 0),\r\n    try\r\n%当锁住了所有的节点，才执行相关的操作\r\n%全局的大锁呀，用多了性能还是比较差的\r\n        Fun(Nodes)\r\n    after\r\n        delete_global_lock(Id, Nodes)\r\n    end.\r\n \r\nset_lock_known(Id, Times) -> \r\n    Known = get_known(),\r\n    Nodes = [node() | Known],\r\n%Boss是List中最后的那个元素\r\n    Boss = the_boss(Nodes),\r\n    %% Use the  same convention (a boss) as lock_nodes_safely. Optimization.\r\n%先锁定住Boss\r\n    case set_lock_on_nodes(Id, [Boss]) of\r\n        true ->\r\n%接这锁住剩下的节点\r\n            case lock_on_known_nodes(Id, Known, Nodes) of\r\n                true ->\r\n                    Nodes;\r\n                false -> \r\n                    del_lock(Id, [Boss]),\r\n                    random_sleep(Times),\r\n                    set_lock_known(Id, Times+1)\r\n            end;\r\n        false ->\r\n            random_sleep(Times),\r\n            set_lock_known(Id, Times+1)\r\n    end.\r\n \r\nlock_on_known_nodes(Id, Known, Nodes) ->\r\n    case set_lock_on_nodes(Id, Nodes) of\r\n        true ->\r\n            (get_known() -- Known) =:= [];\r\n        false ->\r\n            false\r\n    end.\r\n \r\nset_lock_on_nodes(_Id, []) ->\r\n    true;\r\nset_lock_on_nodes(Id, Nodes) ->\r\n    case local_lock_check(Id, Nodes) of\r\n        true ->\r\n            Msg = {set_lock, Id},\r\n            {Replies, _} = \r\n                gen_server:multi_call(Nodes, global_name_server, Msg),\r\n            ?trace({set_lock,{me,self()},Id,{nodes,Nodes},{replies,Replies}}),\r\n            check_replies(Replies, Id, Replies);\r\n        false=Reply ->\r\n            Reply\r\n    end.\r\n```\r\n可以看出执行流程是这样的，先锁住集群中排序最大的那个节点，如上锁成功，则让所有的其余节点跟着上锁，如果上锁失败，则随机睡眠一段时间再接着尝试。如果当所有节点上都拿到锁，就执行名字注册，并且执行注册后。由于使用try after语句进行包裹，在执行最后一定会释放锁。\r\n\r\n#### 为什么这样上锁\r\n\r\n首先全局的锁（GLOBAL_RID）是所有节点共享的，如果从随机的一个节点开始上锁，很容易出现同时好几个节点都在上锁而发生锁冲突，那么大家就约定先上锁某一个节点，这样能快速的发现锁的冲突。\r\n其次，因为要在没给节点上的ets表中添加一个记录，如果不能在所有参与节点上添加记录，会出现数据不一致的问题。\r\n最后，不能只锁定一个约定的节点，考虑到不稳定性，当节点出现异常无法连通的时候，那么这个锁的机制就无效了。	f	2019-09-05 15:22:03.100704
116	Erlang 集群互联	Erlang/Elixir	## Erlang的集群\r\n\r\nErlang语言本身定义的时候就支持了分布式特性。其中在Erlang虚拟机中，通过定义数据的编码方式，Erlang进程的表示方法和大量的基础组件来完成Erlang的分布式。\r\n\r\n### Erlang集群的特性\r\n\r\n每个节点在使用非隐藏模式（在启动的时候没有使用-hidden）加入集群，那么这个节点和集群中所有的节点都会有一个TCP连接，就是大家所知道的无中心和全互联。就如下面的图片所示一样：\r\n![](http://otioh6qxv.bkt.clouddn.com/kyd5kbz.png)\r\nErlang中的Erlang进程位置透明，不管Erlang进程在集群中任何一个节点上，其它节点的进程均可以向它发送消息，就如同该进程和发送消息的进程在同一个节点上一样。\r\n\r\nErlang节点直接使用简单的Cookie机制进行验证，防止错误的接入和非法接入。\r\nErlang节点间的数据传输使用普通TCP传输，也可以使用TLS进行传输，从而防止被窃听。\r\n\r\n### Erlang集群是如何创建的\r\n\r\n一般情况下，节点都是会被命名成nodename@ip或nodename@hostname这种模式。可以通过net_adm:ping('nodename@ip')或net_adm:ping('nodename@hostname')来完成节点的加入工作。但是真正进行节点建立的是net_kernel，因此本篇将重点分析net_kernel都进行了什么样的动作。\r\n\r\n令一种情况，就是Erlang集群中使用了mnesia集群，当mnesia启动的时候，mnesia会要求Erlang虚拟机连接其它节点加入集群。\r\n\r\n### Erlang是如何发现别的节点的\r\n\r\n每个Erlang虚拟机在启动的时候都会尝试启动自带的epmd。epmd就如同大家所知到的DNS一样，它运行在一个约定的端口上，Erlang虚拟机启动后会在epmd上注册一个自己的节点名字和监听的端口号。当节点A想连接节点B的时候，节点A首先会从nodename@ip中取出ip部分，之后去连接这个ip上的epmd，当能成功连接epmd后节点A就会去查询节点B的端口，并进行连接。\r\n\r\n## 代码分析\r\n\r\n### net_kernel\r\n\r\nnet_kernel是Erlang集群构建中最关键的部分之一，它高屋建瓴的控制Erlang虚拟机和OTP库中其它模块成集群的建立和维护。net_kernel是一个gen_server，它在启动后，会完成下面这些功能：\r\n\r\n1.会建立一个定时器进程用来和别的节点进行心跳，检测其它节点是否离开集群。\r\n2.创建连接管理表\r\n3.启动可以连接的端口，用来接收别的节点的连接。\r\n#### net_kernel:connect\r\n当一个节点需要连接另一个节点的时候，就需要使用该函数了。\r\n```erlang\r\nhandle_call({connect, _, Node}, From, State) when Node =:= node() ->\r\n    async_reply({reply, true, State}, From);\r\nhandle_call({connect, Type, Node}, From, State) ->\r\n    verbose({connect, Type, Node}, 1, State),\r\n    case ets:lookup(sys_dist, Node) of\r\n    [Conn] when Conn#connection.state =:= up ->\r\n        async_reply({reply, true, State}, From);\r\n    [Conn] when Conn#connection.state =:= pending ->\r\n        Waiting = Conn#connection.waiting,\r\n        ets:insert(sys_dist, Conn#connection{waiting = [From|Waiting]}),\r\n        {noreply, State};\r\n    [Conn] when Conn#connection.state =:= up_pending ->\r\n        Waiting = Conn#connection.waiting,\r\n        ets:insert(sys_dist, Conn#connection{waiting = [From|Waiting]}),\r\n        {noreply, State};\r\n    _ ->\r\n        case setup(Node,Type,From,State) of\r\n        {ok, SetupPid} ->\r\n            Owners = [{SetupPid, Node} | State#state.conn_owners],\r\n            {noreply,State#state{conn_owners=Owners}};\r\n        _  ->\r\n            ?connect_failure(Node, {setup_call, failed}),\r\n            async_reply({reply, false, State}, From)\r\n        end\r\n    end;\r\n```\r\n 从中可以看出，如果目标节点是自身，那么直接就忽略掉，返回成功。\r\n\r\n如果目标节点不是自身，先看一下ets中是否有向远程节点连接的进程。当这进行连接的进程状态是up，则直接返回true，否则将请求进程加入连接等待队列中。如果我们没有向远程节点进行连接的进程，则调用setup函数来建立一个。在setup函数中，会先找出连接远程节点所使用的模块名称，一般情况下是inet_tcp_dist这个模块。下面先假定是使用inet_tcp_dist这个模块，这个时候net_kernel会调用inet_tcp_dist:setup，并将成功后的Erlang进程PID放入sys_dist这个ets中。\r\n\r\n#### net_kernel的心跳\r\n\r\n创建的ticker进程，它专门负责发心跳给net_kernel进程，然后net_kernel进程会遍历所有远程连接的进程，让其进行一次心跳。当需要改变节点的心跳时间的时候，net_kernel会开启一个aux_ticker进程帮助我们进行过度，直到所有其它节点都知道了该节点改变了心跳周期为止，当所有其它节点都知道了这个节点的心跳周期发生了变化，这个aux_ticker进程也就结束了它的历史性任务，安静的退出了。\r\n\r\n当节点之间心跳发生异常了，就会发生TCP数据传输故障。当TCP传输发生异常的时候，Ports会按照约定好的规则进行清理，这个可参见dist.c中的erts_do_net_exits。\r\n\r\n### inet_tcp_dist\r\n\r\ninet_tcp_dist模块在整个集群建立当中，提供了协议的支持和连接接入这些细节操作。\r\n#### inet_tcp_dist:setup\r\n``` erlang\r\nsetup(Node, Type, MyNode, LongOrShortNames,SetupTime) ->\r\n    spawn_opt(?MODULE, do_setup, \r\n          [self(), Node, Type, MyNode, LongOrShortNames, SetupTime],\r\n          [link, {priority, max}]).\r\n \r\ndo_setup(Kernel, Node, Type, MyNode, LongOrShortNames,SetupTime) ->\r\n    ?trace("~p~n",[{inet_tcp_dist,self(),setup,Node}]),\r\n    [Name, Address] = splitnode(Node, LongOrShortNames),\r\n    case inet:getaddr(Address, inet) of\r\n    {ok, Ip} ->\r\n        Timer = dist_util:start_timer(SetupTime),\r\n        %用epmd协议获得远程节点的端口\r\n        case erl_epmd:port_please(Name, Ip) of\r\n        {port, TcpPort, Version} ->\r\n            ?trace("port_please(~p) -> version ~p~n", \r\n               [Node,Version]),\r\n            dist_util:reset_timer(Timer),\r\n                %连接远程节点\r\n            case inet_tcp:connect(Ip, TcpPort, \r\n                      [{active, false}, \r\n                       {packet,2}]) of\r\n            %拿到Socket之后，定义各种回调函数，状态以及状态机函数\r\n            {ok, Socket} ->\r\n                HSData = #hs_data{\r\n                  kernel_pid = Kernel,\r\n                  other_node = Node,\r\n                  this_node = MyNode,\r\n                  socket = Socket,\r\n                  timer = Timer,\r\n                  this_flags = 0,\r\n                  other_version = Version,\r\n                  f_send = fun inet_tcp:send/2,\r\n                  f_recv = fun inet_tcp:recv/3,\r\n                  f_setopts_pre_nodeup = \r\n                  fun(S) ->\r\n                      inet:setopts\r\n                    (S, \r\n                     [{active, false},\r\n                      {packet, 4},\r\n                      nodelay()])\r\n                  end,\r\n                  f_setopts_post_nodeup = \r\n                  fun(S) ->\r\n                      inet:setopts\r\n                    (S, \r\n                     [{active, true},\r\n                      {deliver, port},\r\n                      {packet, 4},\r\n                      nodelay()])\r\n                  end,\r\n                  f_getll = fun inet:getll/1,\r\n                  f_address = \r\n                  fun(_,_) ->\r\n                      #net_address{\r\n                   address = {Ip,TcpPort},\r\n                   host = Address,\r\n                   protocol = tcp,\r\n                   family = inet}\r\n                  end,\r\n                  mf_tick = fun ?MODULE:tick/1,\r\n                  mf_getstat = fun ?MODULE:getstat/1,\r\n                  request_type = Type\r\n                 },\r\n                %进行握手\r\n                dist_util:handshake_we_started(HSData);\r\n            _ ->\r\n                %% Other Node may have closed since \r\n                %% port_please !\r\n                ?trace("other node (~p) "\r\n                   "closed since port_please.~n", \r\n                   [Node]),\r\n                ?shutdown(Node)\r\n            end;\r\n        _ ->\r\n            ?trace("port_please (~p) "\r\n               "failed.~n", [Node]),\r\n            ?shutdown(Node)\r\n        end;\r\n    _Other ->\r\n        ?trace("inet_getaddr(~p) "\r\n           "failed (~p).~n", [Node,_Other]),\r\n        ?shutdown(Node)\r\n    end.\r\n```\r\n在这函数当中，可以看到，Erlang每次对外建立连接的时候都需要去对方的epmd上进行查询。inet_tcp_dist主要注重流程和协议，将TCP传输细节交给了inet这个模块来进行，这样大大的减少了相应的代码量。在handshake_we_started和远程节点进行一次验证。这个验证过程非常简单，步骤如下：\r\n\r\n1.远程节点生成一个随机数，然后将这个随机数发给当前节点。\r\n2.当前节点用它所知道的远程节点的cookie加上这个随机数生成一个MD5，并将这个MD5返回给远程节点。\r\n\r\n当完成了验证，会使用do_setnode,告诉Erlang虚拟机该节点已经和目标节点的连接上了。同时通知net_kernel已经完成远程节点的连接，需要它改变sys_dist的ets状态和进行后续的操作。\r\n\r\n### dist.c\r\n\r\nErlang虚拟机中，负责管理节点互联的部分，是用纯C实现的。\r\n```c\r\nBIF_RETTYPE setnode_3(BIF_ALIST_3)\r\n{\r\n    BIF_RETTYPE ret;\r\n    Uint flags;\r\n    unsigned long version;\r\n    Eterm ic, oc;\r\n    Eterm *tp;\r\n    DistEntry *dep = NULL;\r\n    Port *pp = NULL;\r\n\r\n    /* Prepare for success */\r\n    ERTS_BIF_PREP_RET(ret, am_true);\r\n\r\n    /*\r\n     * Check and pick out arguments\r\n     */\r\n\r\n    if (!is_node_name_atom(BIF_ARG_1) ||\r\n\t\tis_not_internal_port(BIF_ARG_2) ||\r\n\t\t(erts_this_node->sysname == am_Noname)) {\r\n\t\t goto badarg;\r\n    }\r\n\r\n    if (!is_tuple(BIF_ARG_3))\r\n\t\t goto badarg;\r\n    tp = tuple_val(BIF_ARG_3);\r\n    if (*tp++ != make_arityval(4))\r\n\t\t goto badarg;\r\n    if (!is_small(*tp))\r\n\t\t goto badarg;\r\n    flags = unsigned_val(*tp++);\r\n    if (!is_small(*tp) || (version = unsigned_val(*tp)) == 0)\r\n\t\t goto badarg;\r\n    ic = *(++tp);\r\n    oc = *(++tp);\r\n    if (!is_atom(ic) || !is_atom(oc))\r\n\t\t goto badarg;\r\n\r\n    /* DFLAG_EXTENDED_REFERENCES is compulsory from R9 and forward */\r\n    if (!(DFLAG_EXTENDED_REFERENCES & flags)) {\r\n\t\t erts_dsprintf_buf_t *dsbufp = erts_create_logger_dsbuf();\r\n\t\t erts_dsprintf(dsbufp, "%T", BIF_P->common.id);\r\n\t\t if (BIF_P->common.u.alive.reg)\r\n\t\t\t  erts_dsprintf(dsbufp, " (%T)", BIF_P->common.u.alive.reg->name);\r\n\t\t erts_dsprintf(dsbufp,\r\n\t\t\t\t\t   " attempted to enable connection to node %T "\r\n\t\t\t\t\t   "which is not able to handle extended references.\\n",\r\n\t\t\t\t\t   BIF_ARG_1);\r\n\t\t erts_send_error_to_logger(BIF_P->group_leader, dsbufp);\r\n\t\t goto badarg;\r\n    }\r\n\r\n    /*\r\n     * Arguments seem to be in order.\r\n     */\r\n\r\n    /* get dist_entry */\r\n    dep = erts_find_or_insert_dist_entry(BIF_ARG_1);\r\n    if (dep == erts_this_dist_entry)\r\n\t\t goto badarg;\r\n    else if (!dep)\r\n\t\t goto system_limit; /* Should never happen!!! */\r\n//通过Port的ID获取Port的结构\r\n    pp = erts_id2port_sflgs(BIF_ARG_2,\r\n\t\t\t    BIF_P,\r\n\t\t\t    ERTS_PROC_LOCK_MAIN,\r\n\t\t\t    ERTS_PORT_SFLGS_INVALID_LOOKUP);\r\n    erts_smp_de_rwlock(dep);\r\n\r\n    if (!pp || (erts_atomic32_read_nob(&pp->state)\r\n\t\t& ERTS_PORT_SFLG_EXITING))\r\n\t\t goto badarg;\r\n\r\n    if ((pp->drv_ptr->flags & ERL_DRV_FLAG_SOFT_BUSY) == 0)\r\n\t\t goto badarg;\r\n//如果当前cid和传入的Port的ID相同，且port的sist_entry和找到的dep相同\r\n//那么直接进入结束阶段\r\n    if (dep->cid == BIF_ARG_2 && pp->dist_entry == dep)\r\n\t\t goto done; /* Already set */\r\n\r\n    if (dep->status & ERTS_DE_SFLG_EXITING) {\r\n\t\t /* Suspend on dist entry waiting for the exit to finish */\r\n\t\t ErtsProcList *plp = erts_proclist_create(BIF_P);\r\n\t\t plp->next = NULL;\r\n\t\t erts_suspend(BIF_P, ERTS_PROC_LOCK_MAIN, NULL);\r\n\t\t erts_smp_mtx_lock(&dep->qlock);\r\n\t\t erts_proclist_store_last(&dep->suspended, plp);\r\n\t\t erts_smp_mtx_unlock(&dep->qlock);\r\n\t\t goto yield;\r\n    }\r\n\r\n    ASSERT(!(dep->status & ERTS_DE_SFLG_EXITING));\r\n\r\n    if (pp->dist_entry || is_not_nil(dep->cid))\r\n\t\t goto badarg;\r\n\r\n    erts_atomic32_read_bor_nob(&pp->state, ERTS_PORT_SFLG_DISTRIBUTION);\r\n\r\n    /*\r\n     * Dist-ports do not use the "busy port message queue" functionality, but\r\n     * instead use "busy dist entry" functionality.\r\n     */\r\n    {\r\n\t\t ErlDrvSizeT disable = ERL_DRV_BUSY_MSGQ_DISABLED;\r\n\t\t erl_drv_busy_msgq_limits(ERTS_Port2ErlDrvPort(pp), &disable, NULL);\r\n    }\r\n//更新Port所关联的dist\r\n    pp->dist_entry = dep;\r\n\r\n    dep->version = version;\r\n    dep->creation = 0;\r\n\r\n    ASSERT(pp->drv_ptr->outputv || pp->drv_ptr->output);\r\n\r\n#if 1\r\n    dep->send = (pp->drv_ptr->outputv\r\n\t\t ? dist_port_commandv\r\n\t\t : dist_port_command);\r\n#else\r\n    dep->send = dist_port_command;\r\n#endif\r\n    ASSERT(dep->send);\r\n\r\n#ifdef DEBUG\r\n    erts_smp_mtx_lock(&dep->qlock);\r\n    ASSERT(dep->qsize == 0);\r\n    erts_smp_mtx_unlock(&dep->qlock);\r\n#endif\r\n//更新dist_entry的cid\r\n    erts_set_dist_entry_connected(dep, BIF_ARG_2, flags);\r\n\r\n    if (flags & DFLAG_DIST_HDR_ATOM_CACHE)\r\n\t\t create_cache(dep);\r\n\r\n    erts_smp_de_rwunlock(dep);\r\n    dep = NULL; /* inc of refc transferred to port (dist_entry field) */\r\n//增加远程节点的数量\r\n    inc_no_nodes();\r\n//发送监控信息到调用的进程\r\n    send_nodes_mon_msgs(BIF_P,\r\n\t\t\tam_nodeup,\r\n\t\t\tBIF_ARG_1,\r\n\t\t\tflags & DFLAG_PUBLISHED ? am_visible : am_hidden,\r\n\t\t\tNIL);\r\n done:\r\n\r\n    if (dep && dep != erts_this_dist_entry) {\r\n\t\t erts_smp_de_rwunlock(dep);\r\n\t\t erts_deref_dist_entry(dep);\r\n    }\r\n\r\n    if (pp)\r\n\t\t erts_port_release(pp);\r\n\r\n    return ret;\r\n\r\n yield:\r\n    ERTS_BIF_PREP_YIELD3(ret, bif_export[BIF_setnode_3], BIF_P,\r\n\t\t\t BIF_ARG_1, BIF_ARG_2, BIF_ARG_3);\r\n    goto done;\r\n\r\n badarg:\r\n    ERTS_BIF_PREP_ERROR(ret, BIF_P, BADARG);\r\n    goto done;\r\n\r\n system_limit:\r\n    ERTS_BIF_PREP_ERROR(ret, BIF_P, SYSTEM_LIMIT);\r\n    goto done;\r\n}\r\n```\r\nsetnode函数主要完成下面这几个操作：\r\n\r\n1.将得到的远程节点的名字放入dist的hash表中，并且将这个表项和连接到远程节点的Port（TCP连接）进行了关联。\r\n2.将和远程节点进行连接的Port标记为ERTS_PORT_SFLG_DISTRIBUTION。\r\n3.在Erlang虚拟机内广告nodeup消息。\r\n\r\n其中给Port设置ERTS_PORT_SFLG_DISTRIBUTION标记是为了下面几个事情：\r\n\r\n1.让Port出现Busy的时候我们能区分出是普通的Port还是远程连接的Port。\r\n2.当Port被销毁的时候，确定是否要调用dist.c中的erts_do_net_exits来告诉Erlang虚拟机某个节点掉线。\r\n\r\n### 需要注意的\r\n\r\n#### epmd\r\n\r\n当独立进程epmd发现自己和本地节点的连接断了，那么直接将这个node注册的名字和端口从自身缓存中删除掉，但是这个删除是有一定延迟的。\r\n\r\n但是当empd被不小杀掉了，当empd被再次启动的时候，数据将会全部清除。而且，本地节点不会自动向epmd重新注册自己的端口等。\r\n\r\n#### dist_port\r\n\r\ndist_port负责所有Erlang进程透明调用的数据发送和传输，同时也负责着节点之间存活检测的任务。由于Erlang的节点检测都是以本节点是否能和对应节点有心跳为视角，如果使用使用dist_port传输大量的数据，很容易引起dist_port_busy，从而引起节点离线的误判或性能下降。\r\n\r\nErlang默认会为dist_port设置一个1M的缓存，但是如果在节点之间传输大量的数据很容易就不够用。如果在设计的时候就意识到自己要传输大量数据，可以使用+zdbbl这个参数来改变dist_port的缓存。Erlang提供了erlang:system_info函数来查询dist_piort的缓存大小，同时Erlang还提供erlang:system_monitor函数来监控dist_port_busy。\r\n\r\n并且在实际使用中，可以参考Spil Games的架构，对Erlang的集群进行分层：\r\n![](http://otioh6qxv.bkt.clouddn.com/layer.jpg)\r\n同时需要注意的是，Erlang的集群虽然可以跨越IDC，但是在实际的使用中，并不推荐这样做，原因如下：\r\n\r\n1.IDC间网络延迟偏高，Erlang集群本身对网络延迟敏感。\r\n2.IDC间网络吞吐有限\r\n3.net_kernel并未对高并发连接做优化，很容易被攻击者攻击\r\n4.Erlang集群之间的连接对HA不友好，不如Restful。而IDC之间链路很多时候并不稳定，需要进行冗余，这对Erlang集群并不友好。\r\n\r\n#### 节点重启\r\n\r\n这个是非常需要注意的，Erlang节点之间确认存活是需要心跳时间的。Erlang在进行跨节点操作的时候，都会监控远程节点的状态，尤其是Mnesia数据库很多操作对Erlang节点存活性是非常敏感的。当一个节点掉线后，不应该立刻重启，一般需要等待该节点心跳事件 * 1.5的时间。为什么要这样做呢？因为这样做是为了让节点彻底“死掉”，集群中所有的节点都知道该节点死掉了，这样才不会出现远程操作被锁死的情况（顺便说一句，这个简单问题，在国内某个著名的通讯SaaS中多次出现，该云的架构师曾经多次提出Erlang不是开箱即用，因为他根本没搞清楚Erlang的底层原理，甚至可以说分布式系统中的基础原理）。\r\n	f	2019-09-05 15:22:03.202877
117	Erlang 入门-递归和模式匹配	Erlang	## 两大基本概念\r\n学过计算机编程的读者们都会知道，程序是由算法和数据组成的，近一步说是控制结构和数据体。拿C语言举个例子来说，控制结构有if语句，for语句和case语句等，就是这些控制结构和逻辑判断组成了一个又一个算法。在Erlang这个函数语言中，只要理解递归和模式匹配这两个概念，就完全可以组合出上面的控制结构。本文将重点介绍这两大概念，并用实际例子向读者说明。\r\n\r\n## 递归\r\n我们都知道阶乘这个算法，下面先用C实现一遍这个算法：\r\n``` c\r\nint factorial(int a){\r\n   if(a > 0) {\r\n     return a * factorial( a - 1);\r\n   } else {\r\n     return 1;\r\n   }\r\n} \r\n```\r\n 有经验的读者会发现这个例子会导致堆栈溢出，int上溢出等问题，在此我们不深究这些问题。读者可以很容易发现这个是一个递归算法，那么现在就用Erlang来编写下这个例子：\r\n ``` erlang\r\n-module(ex1).\r\n-export([factorial/1]).\r\nfactorial(0) -> 1;\r\nfactorial(A) -> A * factorial(A -1). \r\n```\r\n 在Erlang中这种递归一样存在堆栈溢出的问题，读者都知道C语言可以通过使用for循环和一个中间变量来解决堆栈溢出。那么对于变量不可变的Erlang应当怎么做呢？让我们重新修改下上面阶乘这个例子：\r\n```erlang\r\n-module(ex2).\r\n-export([factorial/1]).\r\nfactorial(N) -> factorial(N,1).\r\nfactorial(0,Acc) -> Acc;\r\nfactorial(N,Acc) when N > 0 -> factorial(N-1,N*Acc).\r\n```\r\n看起来似乎和前面的那个ex1版本没什么区别，但是其中的差异很大。ex2版本的factorial被称为尾递归，Erlang编译器在编译的过程中，会自动将代码转化成循环形式。同时尾递归也是Erlang中用来保持进程存活，进行列表（数组）遍历的重要工具，在后面教程中，会不断深入介绍相关知识。\r\n\r\n## 模式匹配\r\n\r\n在上面ex1中的例子，可以看到factorial(0)这种写法，这种写法就是Erlang的模式匹配。Erlang会将传入函数的参数和函数的参数列表进行匹配。\r\n\r\n就ex1的例子来说，当我们传入参数3，Erlang会按照factorial函数的定义的顺序，从上到下逐条匹配。第一次执行的时候，参数3和factorial(0)并不匹配，直接进入第二条和factorial(A)进行匹配，Erlang会自动的将参数3绑定到A上。并且值得注意的是，Erlang中大写字母开头的变量一旦绑定了在作用范围内就不可以再次绑定。当执行到最后一次的时候，参数已经变成0，直接和factorial(0)匹配，Erlang对于两个常量并不会进行绑定。\r\n\r\n为了理解模式匹配，我们需要理解Erlang的变量。\r\n\r\n## 变量\r\n\r\nErlang的变量比较特殊，Erlang的变量是不可变的。Erlang的变量一旦绑定了特定的值之后，再作用范围之内就不能再次进行绑定，因此Erlang的变量是被认为不可变的。Erlang中变量的语法非常简单，任何以大写字母开头的单词，大写字母开头后续是字母和数字混合的标识或以下划线开头的标识。例如说，Erlang，JID1，UserA和User1都是合法的变量标识。\r\n\r\n我们可以将Erlang的变量想象成一个盒子，这个盒子一开始是空的，但是一旦放入东西后，就不能放入别的东西了，并且当我们取出这个东西的时候，盒子会自动生成一个一模一样的东西。\r\n![](http://otioh6qxv.bkt.clouddn.com/pattern1.png)\r\n如图所示，绑定变量的时候就相当于我们把东西放入盒子。\r\n![](http://otioh6qxv.bkt.clouddn.com/pattern2.png)\r\n如图所示，当我们取出变量的时候，我们得到一个东西和一个仍装有东西的盒子。因此，我们依然不能将别的东西继续放入这个盒子了。\r\n\r\nErlang中还有一个比较特殊的变量 “\\_”，我们可以把它认为是个黑洞，它无需遵循Erlang变量不变的特性，任何放入 “\\_” 中的值都无法再次取出使用。“\\_” 虽然在作为变量使用时，虽然没有什么太大的意义，但是当进行模式匹配的时候它就非常有意义了。\r\n\r\n## 什么是模式匹配\r\n\r\n那么对于“=”这个操作符号就很好理解了，“=”先检查左侧和右侧两个值，如果左侧是一个未绑定的变量，右侧是一个常量，就把常量放入变量这个盒子里面；如果左侧是一个绑定的变量，右侧是一个绑定变量，就都把盒子打开拿出里面的东西进行比较；如果左侧是绑定的变量，右侧是常量，那么就把盒子打开取出东西进行比较。\r\n\r\n从这里我们就可以看出，模式匹配就是尝试比较装有东西的盒子里面的东西和外面的东西比较，或者比较两个装有东西的盒子中的两个东西是否一样。\r\n\r\n对于上面提到的黑洞‘“_”，在进行模式匹配的时候，它会匹配任何内容，并且在匹配完成后立刻忘记，这么做就可以让我们在写Erlang代码的时候忽略那些我们不行关心的变量。尤其是Erlang的函数有多个参数需要匹配或匹配元组的时候。\r\n\r\n读者这时也许会问到，上面ex1的例子中函数并没有使用“=”的地方，那它怎么进行的模式匹配呢？这是因为Erlang编译器默认替我们做了一下，将函数定义的参数和函数调用时候传入的参数进行了下绑定操作。	f	2019-09-05 15:22:03.318757
118	Erlang 的 RPC 模块	Erlang	## RPC模块的功能\r\nRPC模块的功能主要是为了帮助程序员完成本地节点、两个或多个节点之间的调用。RPC模块将远程调用设定为一定的模式，这样能做到方法和进程的位置透明，简化开发工作。\r\n在RPC模块中主要的方法有下面几个：\r\n\r\n- call 同步调用\r\n- block_call 阻塞同步调用\r\n- cast 广播调用\r\n- abcast 异步广播调用\r\n- sbcast 同步广播调用\r\n\r\n当然还有其它很多方法，就不在这里面一一介绍了\r\n\r\n## RPC的代码分析\r\n\r\n### 进程创建\r\nRPC模块本身是一个gen_server会随着kernel模块启动，也就是说，在Erlang/OTP启动后我们就免费获得了一个RPC进程。\r\nRPC进程启动的时候，会在Erts中通过local注册一个名字rex的进程，这样没有经过修改的Erlang/OTP都会有这个名字在它的名字列表上。\r\n\r\n### RPC调用逻辑\r\n不管是同步调用还是广播调用，在RPC模块中的调用都是依赖gen_server的相关方和erlang:send方法来完成。这样尽最大可能的重用代码，保证了整个OTP中对远程调用的表现的一致性。\r\n并且RPC模块不单单可以调用远程节点的方法或进程，也可以调用本地节点的方法或进程，这样保证了整个RPC的系统位置透明性，并且RPC模块针对本地节点作了相关优化。\r\n\r\n例如说call方法针对本地节点就采用了下面的方法：\r\n``` erlang\r\nlocal_call(M, F, A) when is_atom(M), is_atom(F), is_list(A) ->\r\n    case catch apply(M, F, A) of\r\n\t\t{'EXIT',_} = V -> {badrpc, V};\r\n\t\tOther -> Other\r\n    end.\r\n```\r\n\r\n### call和block_call方法\r\n这两个方法都是同步的调用，但是实现的细节非常不同，对rex进程的影响也是不同的。当然使用两个方法在并发执行的情况下，得到的结果是完全不同的。\r\n不管是call也好，block_call也好，都会在执行阶段暂时的将被调用者进程的console输出重定向到调用者进程所在节点的group leader上。\r\n\r\n#### call方法\r\n在调用发起者一侧，RPC模块会立刻建立一个监控下的Erlang进程，并在该进程内通过gen_server:call方法来调用远程节点。\r\n\r\n``` erlang\r\ndo_call(Node, Request, infinity) ->\r\n    rpc_check(catch gen_server:call({?NAME,Node}, Request, infinity));\r\ndo_call(Node, Request, Timeout) ->\r\n    Tag = make_ref(),\r\n    {Receiver,Mref} =\r\n\terlang:spawn_monitor(\r\n\t  fun() ->\r\n\t\t  process_flag(trap_exit, true),\r\n\t\t  Result = gen_server:call({?NAME,Node}, Request, Timeout),\r\n\t\t  exit({self(),Tag,Result})\r\n\t  end),\r\n    receive\r\n\t{'DOWN',Mref,_,_,{Receiver,Tag,Result}} ->\r\n\t    rpc_check(Result);\r\n\t{'DOWN',Mref,_,_,Reason} ->\r\n\t    rpc_check_t({'EXIT',Reason})\r\n    end.\r\n```\r\nRPC模块会将超时或对方节点失去连接的情况处理为bad_rpc，让顶层逻辑发现并非业务本身引起的远程调用问题。\r\n\r\n在被调用者一些，RPC模块也会立刻创建一个监控下的Erlang进程，并在该进程内处理调用者的call消息，同时会将相关信息保存在rex进程的进程上下文中。当新的进程完成了业务处理，就会把处理结果返回给被调用者节点的rex进程，然后再将结果返回给调用发起者。\r\n我们可以仔细观察它的代码：\r\n``` erlang\r\nhandle_call_call(Mod, Fun, Args, Gleader, To, S) ->\r\n    RpcServer = self(),\r\n    %% Spawn not to block the rpc server.\r\n    {Caller,_} =\r\n\terlang:spawn_monitor(\r\n\t  fun () ->\r\n\t\t  set_group_leader(Gleader),\r\n\t\t  Reply = \r\n\t\t      case catch apply(Mod, Fun, Args) of\r\n\t\t\t  {'EXIT', _} = Exit ->\r\n\t\t\t      {badrpc, Exit};\r\n\t\t\t  Result ->\r\n\t\t\t      Result\r\n\t\t      end,\r\n\t\t  RpcServer ! {self(), {reply, Reply}}\r\n\t  end),\r\n    {noreply, gb_trees:insert(Caller, To, S)}.\r\n```\r\n\r\n#### block_call方法\r\n于call方法一样，在调用发起者一侧，RPC模块会立刻建立一个监控下的Erlang进程，并在该进程内通过gen_server:call方法来调用远程节点。\r\n\r\n但是在被调用者一些，RPC模块会选择使用被调用者所在节点的rex直接执行相关代码\r\n```erlang\r\nhandle_call({block_call, Mod, Fun, Args, Gleader}, _To, S) ->\r\n    MyGL = group_leader(),\r\n    set_group_leader(Gleader),\r\n    Reply = \r\n\tcase catch apply(Mod,Fun,Args) of\r\n\t    {'EXIT', _} = Exit ->\r\n\t\t{badrpc, Exit};\r\n\t    Other ->\r\n\t\tOther\r\n\tend,\r\n    group_leader(MyGL, self()), % restore\r\n    {reply, Reply, S};\r\n```\r\n\r\n#### 同步调用总结\r\ncall方法可以保证，同一调用者的远程请求按序列执行，但是不保证多个调用者的远程请求按序列执行。\r\nblock_call方法保证，多个调用者的远程请求按序列执行。\r\n不管是call还是block_call的方法都会给调用者带来大量的进程创建的压力（Erlang创建进程很快，但不代表没有代价）。\r\ncall方法还会给被调用者节点带来大量的进程创建压力。\r\n\r\n### cast方法\r\nRPC模块的cast方法直接依赖于gen_sever:cast，并没有做更多的事情。\r\n\r\n针对本地节点，cast方法会在调用者节点内创建一个进程来执行相关代码：\r\n```erlang\r\ncast(Node, Mod, Fun, Args) when Node =:= node() ->\r\n    catch spawn(Mod, Fun, Args),\r\n    true;\r\ncast(Node, Mod, Fun, Args) ->\r\n    gen_server:cast({?NAME,Node}, {cast,Mod,Fun,Args,group_leader()}),\r\n    true.\r\n```\r\n被调用者接收到消息后会立刻创建进程执行相关代码：\r\n\r\n``` erlang\r\nhandle_cast({cast, Mod, Fun, Args, Gleader}, S) ->\r\n    spawn(fun() ->\r\n\t\t  set_group_leader(Gleader),\r\n\t\t  apply(Mod, Fun, Args)\r\n\t  end),\r\n    {noreply, S};\r\n```\r\n#### cast方法总结\r\ncast方法是非常简单的。和call方法一样，会给被调用者节点带来大量的进程创建压力。\r\n同样不要忘记了，cast方法也会将新创建的进程的console输出重新定向调用者所在节点的group leader上。\r\n\r\n### abcast和sbcast\r\n这两个方法都是通过erlang:send将调用者的消息发送到被调用者节点上。\r\n\r\n#### abcast\r\nabcast采用的是纯异步，发出去就不管了，直接将消息不经过rex进程直接发送到目标进程上\r\n``` erlang\r\n\r\nabcast(Name, Mess) ->\r\n    abcast([node() | nodes()], Name, Mess).\r\n\r\nabcast([Node|Tail], Name, Mess) ->\r\n    Dest = {Name,Node},\r\n    %这么做的好处是不会让进程被trap\r\n    %从而保证了异步性\r\n    case catch erlang:send(Dest, Mess, [noconnect]) of\r\n\tnoconnect -> spawn(erlang, send, [Dest,Mess]), ok;\r\n\t_ -> ok\r\n    end,\r\n    abcast(Tail, Name, Mess);\r\nabcast([], _,_) -> abcast.\r\n```\r\n此处abcast完全是异步的，如果发现了目标节点是没有连接的时候，直接创建一个新的进程来进行消息发送，完全不会进入Trap状态等待节点连接。\r\n\r\n#### sbcast\r\nsbcast算是同步的广播方式，发送后会回收广播结果，并且当节点没有完成连接的时候，会进入Trap状态等待节点连接完成\r\n\r\n``` erlang\r\nsbcast(Name, Mess) ->\r\n    sbcast([node() | nodes()], Name, Mess).\r\n\r\nsbcast(Nodes, Name, Mess) ->\r\n    Monitors = send_nodes(Nodes, ?NAME, {sbcast, Name, Mess}, []),\r\n    rec_nodes(?NAME, Monitors).\r\n\r\nsend_nodes([Node|Tail], Name, Msg, Monitors) when is_atom(Node) ->\r\n    Monitor = start_monitor(Node, Name),\r\n    %% Handle non-existing names in rec_nodes.\r\n    catch {Name, Node} ! {self(), Msg},\r\n    send_nodes(Tail, Name, Msg, [Monitor | Monitors]);\r\nsend_nodes([_Node|Tail], Name, Msg, Monitors) ->\r\n    %% Skip non-atom _Node\r\n    send_nodes(Tail, Name, Msg, Monitors);\r\nsend_nodes([], _Name,  _Req, Monitors) -> \r\n    Monitors.\r\n\r\nrec_nodes(Name, Nodes) -> \r\n    rec_nodes(Name, Nodes, [], []).\r\n\r\nrec_nodes(_Name, [],  Badnodes, Replies) ->\r\n    {Replies, Badnodes};\r\nrec_nodes(Name, [{N,R} | Tail], Badnodes, Replies) ->\r\n    receive\r\n\t{'DOWN', R, _, _, _} ->\r\n\t    rec_nodes(Name, Tail, [N|Badnodes], Replies);\r\n\t{?NAME, N, {nonexisting_name, _}} ->  \r\n\t    %% used by sbcast()\r\n\t    erlang:demonitor(R, [flush]),\r\n\t    rec_nodes(Name, Tail, [N|Badnodes], Replies);\r\n\t{Name, N, Reply} ->  %% Name is bound !!!\r\n\t    erlang:demonitor(R, [flush]),\r\n\t    rec_nodes(Name, Tail, Badnodes, [Reply|Replies])\r\n    end.\r\n```\r\n\r\n## 总结\r\nRPC模块是Erlang/OTP当中非常重要的一个模块，它的存在简化了很多编码工作但是也为我们带来了很多隐患\r\n\r\n- 单个gen_server的消息承载能力和block_call的阻塞\r\n- 错误使用时，RPC模块大量的进程创建，影响了Erts的调度\r\n- 使用RPC模块来传递大块的数据，引起dist_busy_port\r\n- group leader重定向引起的数据量叠加，引起dist_busy_port\r\n\r\n当然这些问题不影响我们正常使用RPC模块，例如我们可以将RPC用于以下场景：\r\n\r\n- Erlang集群构建boot阶段\r\n- Erlang集群的元信息和控制信息交换	f	2019-09-05 15:22:03.425086
119	Web 服务器-Nginx	DevOps	## 什么是Web服务器\r\n\r\n### Web简介\r\nWEB服务器也称为WWW(WORLD WIDE WEB)服务器，主要功能是提供网上信息浏览服务。世界上第一台Web服务器诞生于1990年，最先被部署在欧洲原子核研究委员会（CERN，European Organization for Nuclear Research）的。起初其被命名为“CERN httpd”，也被称为“W3C httpd”。\r\n\r\n### Web发展简史\r\n- 1990年，CERN httpd是一台NeXT服务器，运行着NeXTSTEP操作系统。最先展示在世人面前是在美国圣安东尼奥举办的Hypertext 91大会上，而且当时它托管着当时世界上首个Web页面（http://info.cern.ch/hypertext/WWW/TheProject.html）。\r\n- 1992年开始，Web服务器开始呈急剧增长态势。1992年全球已经拥有总共26台WWW服务器。\r\n- 在1993年的时候，这一数字增长到了200台\r\n- 在1994年则为1万台，用户数超过千万人。\r\n\r\n### Web服务器\r\nWeb服务器一般指网站服务器，是指驻留于因特网上某种类型计算机的程序，可以向浏览器等Web客户端提供文档，也可以放置网站文件，让全世界浏览；可以放置数据文件，让全世界下载。\r\n\r\n## Nginx\r\n\r\n### 什么是Nginx\r\nNginx是lgor Sysoev为俄罗斯访问量第二的rambler.ru站点设计开发的。从2004年发布至今，凭借开源的力量，已经接近成熟与完善。\r\nNginx功能丰富，可作为HTTP服务器，也可作为反向代理服务器，邮件服务器。支持FastCGI、SSL、Virtual Host、URL Rewrite、Gzip等功能。并且支持很多第三方的模块扩展。\r\n\r\n### Nginx能做什么\r\n\r\n1. 反向代理\r\n1. 负载均衡\r\n1. HTTP服务器\r\n1. 正向代理\r\n\r\n#### 反向代理\r\n\r\n##### 定义\r\n反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。简单来说就是真实的服务器不能直接被外部网络访问，所以需要一台代理服务器，而代理服务器能被外部网络访问的同时又跟真实服务器在同一个网络环境，当然也可能是同一台服务器，端口不同而已。\r\n\r\n##### nginx实现\r\n\r\n``` conf\r\nserver {\r\n        listen       80;\r\n        server_name  www.ttalk.im;\r\n        location / {\r\n            proxy_pass http://localhost:8080;\r\n            proxy_set_header Host $host:$server_port;\r\n        }\r\n    }\r\n```\r\n这里面就是将本站的80端口代理到同一台服务器的8080端口上。\r\n\r\n##### 特点\r\nNginx在做反向代理时，提供性能稳定，并且能够提供配置灵活的转发功能。Nginx可以根据不同的正则匹配，采取不同的转发策略，比如图片文件结尾的走文件服务器，动态页面走Web应用服务器。并且Nginx对返回结果进行错误页跳转，异常判断等。如果被分发的服务器存在异常，他可以将请求重新转发给另外一台服务器，然后自动去除异常服务器。\r\n\r\n#### 负载均衡\r\n\r\n##### 定义\r\n负载均衡其意思就是分摊到多个操作单元上进行执行，例如Web应用服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。简单而言就是当有2台或以上服务器时，根据规则随机的将请求分发到指定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡。\r\n\r\n##### nginx实现\r\n\r\n``` conf\r\n  upstream inner {\r\n        server 192.168.1.2:8080;\r\n        server 192.168.1.3:8080;\r\n    }\r\n    server {\r\n        listen       80;\r\n        server_name  www.ttalk.im;\r\n        location / {\r\n            proxy_pass http://inner;\r\n            proxy_set_header Host $host:$server_port;\r\n        }\r\n    }\r\n```\r\n这里面就是将本站的80端口代理到两台内网服务器的8080端口上，并且均匀分请求。\r\n\r\n##### 特点\r\n- 一般配合反向代理使用\r\n- 自动剔除异常节点\r\n- 多种负载算法\r\n\t1. RR（默认），就是Round Robin的缩写，将请求均分到不同的服务器上\r\n\t1. 权重，因为被代理的服务器性能不同而采取将不同比例的请求分配到不同的服务上\r\n\t1. ip_hash 根据用户的IP不同将某个用户的请求每次都分配到同一台服务器上\r\n\r\n#### HTTP服务器\r\n\r\n##### nginx实现\r\n``` conf\r\n    server {\r\n        listen       80;\r\n        server_name  static.ttalk.im;\r\n        location / {\r\n               root  /var/www/ttalk/static;\r\n               index  index.html;\r\n           }\r\n    }\r\n\r\n```\r\n这段配置，让nginx直接处理本站的所有静态资源文件。\r\n\r\n##### 特点\r\nNginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现。\r\n\r\n#### 正向代理\r\n\r\n##### 定义\r\n正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。\r\n\r\n##### nginx实现\r\n``` conf\r\n    resolver 8.8.8.8;\r\n    server {\r\n        resolver_timeout 5s;\r\n        listen 80;\r\n        location / {\r\n            proxy_pass http://$host$request_uri;\r\n        }\r\n    }\r\n```\r\n##### 特点\r\n\r\n也许是本人没有特别深入用这个功能的关系，感觉nginx这个功能实现的比较弱，并不推荐使用。\r\n\r\n## 总结\r\nNginx和Apache，IIS等相比，是一款较新的Web服务器，但是Nginx凭借着高稳定性、功能强、示例配置文件和低系统资源的消耗让它后来居上。\r\n在我们不需要实现太多复杂的功能，或者有特定需要的场景下，Nginx都是一个非常不错的选择。\r\n当然Nginx也有各种各样的插件和衍生版本，例如著名的OpenResty	f	2019-09-05 15:22:03.532156
120	像架构师一样来思考微服务接口设计	架构	## 为什么做接口设计\r\n\r\n我们在工作的时候一般都是面一个大型项目，随着微服务的兴起，不单单要设计模块之间的接口，还要考虑各个微服务之间的接口。这篇文章就是针对如何去做微服务之间的接口设计的思考。\r\n\r\n## 如何做接口的设计\r\n\r\n从我个人角度来说，可以从以下几个特性进行分析：\r\n\r\n1. 大规模系统和小规模系统\r\n1. 面向内部系统接口和面向外部系统的接口\r\n1. 大数据传输的接口和小数据传输的接口\r\n1. 长链接的接口和短链接的接口\r\n\r\n很多时候我们优先考虑的是系统有多大，扩张性要有多好，对内还是对外以及我们有多大的能力。很多时候这个东西并没有一个定论，更多是基于业务和团队人员组成而决定的。\r\n\r\n\r\n## 接口的实施\r\n\r\n一定要做的事情\r\n\r\n不管接口是对内的还是对外的，我们都要做以下几件事情：\r\n\r\n1. 接口功能定义是否明确，是否有功能重复的地方\r\n1. 接口的升级机制，是否能兼容以前的数据\r\n1. 接口的数据量是多少，是否需要使用传输压缩机制\r\n1. 接口的熔断点在何处，何时该降级或停止服务\r\n1. 接口的安全机制是怎么样的，如何将非法调用隔离开来\r\n\r\n这些事情是我们在开始设计和实现接口的时候，必须要先想到的。但是不要认为我们想到了这些东西，我们就可以高枕无忧，然后事情就会像我们期待的那样发展下去。很多时候，接口都会变成像阿米巴原虫一样，不是圆的而是不规则的多边形。\r\n\r\n### 对内的接口\r\n\r\n对内的接口简单说就是SOA，但是SOA也有很多种做法，例如常见的dubbo框架。在dubbo框架下，我们所做的事情完全可以说是在dubbo框架下进行业务开发，并定义interface然后暴露出去，我们此时貌似没有进行接口设计，但是实际上我们是完全按照dubbo的规范完成了接口的定义，没错就是那个interface。看起来对内部的接口完全非常明确了，没什么可讲的，但是其中还是有很多东西可讲的，我先讲讲我们常见的。\r\n\r\n对服务发现的方案选择：\r\n\r\n1. 使用主动推送的方式，注册中心每次发生变化都会推送最新的列表给服务的使用者\r\n1. 使用被动拉取的方式，注册中心每次变化都保存好，然后使用者每次调用服务者的时候，先到注册中心查询一次\r\n\r\n好了，让我分别来说说这两个方案\r\n\r\n#### 使用主动推送\r\n可以让使用者很快的更新服务者信息，使用者调用服务者的时候只需要在本地的一个hash表中查询一下即可，并且注册中心挂掉了之后，也不影响使用者调用服务者，看起来不错吧。那么让我来说说这方案的弊端，首先要实现watch－notify机制，大概有人会说不是有Zookeeper吗？自带该机制和数据冗余机制，那么我想说的是，当业务量起来的时候，Zookeeper的watch机制真的能顶住吗？接着是，服务者的负载均衡并不好处理。那么有没有解决方法，这个可以参看dubbo中的注册中心是如何玩耍的。\r\n\r\n#### 使用被动拉取\r\n这个好像很直观，但是每次都查询注册中心，这性能，注册中心能处理的了吗？大家不妨想一下DNS服务器，其实该方案完全可以使用简单的内部DNS实现。那么该方案的好处不言而喻，负载均衡好处理，并且非常简单。但是问题呢，性能和稳定性是要深入考虑的事情。\r\n\r\n### 传输协议\r\n\r\n剩下的就是需要考虑的传输协议了，为什么要考虑传输协议？原因很简单：\r\n\r\n1. 接口平均传输的数据量和自己的内网带宽的平衡\r\n1. 是否要跨语言协作\r\n1. 是否侵入业务了\r\n\r\n#### 为何考虑带宽\r\n\r\n虽然注册中心第一步解决了我们的快速扩张的问题，但是呢，内网带宽毕竟是有限的。随着服务数量增多和调用量的增加，有时候我们会发现，同一个服务我们明明增加了N台部署响应时间却下降了很多，按照公式应该响应时间不变的呀？这个时候，我们可能猛然看到监控上我们的内网带宽已经跑满了。\r\n\r\n#### 为何考虑跨语言\r\n\r\n难道一个公司不就是一种后端语言？其实不然，我曾见面试过一个公司，内部的业务之复杂，语言使用之繁多。很多时候，我们需要站在一个公司发展的角度上考虑这个问题，而不是一个纯技术的细节上考虑这个问题。\r\n\r\n#### 为什么要考虑是否侵入业务\r\n\r\n不侵入业务，就是尽可能的封装底层的实现，让业务线更少的去考虑底层发生什么了。很多人说，这对业务线的人不公平，阻碍了他们的技术发展。其实不然，让业务线的同仁们更多，更深入的思考业务发展是非常重要的事情，我个人认为研发分两类，一类是玩算法和底层的，另一类就是深入业务的，他们都有自己的长处和短处。其实减少业务的侵入是为了更快的实现产品功能，让产品上线，让公司的业务快速迭代起来，这样对任何人都是有好处的。\r\n\r\n### 接口升级\r\n\r\n这个与其说是升级，不如说是怎么做不同版本的数据共存和A/B测试。一般在很多成行的SOA系统中，已经很完善了，我没必要在这里面多废话。但是还是要多说一句，数据多版本不易，且升且小心。\r\n\r\n\r\n### 对外接口\r\n\r\n对外接口，大家很快就会想到Restful。随着现在创业的兴起，应当说是智能手机和Web2.0的兴起（更应该说的本质是，网络带宽变好，手机流量降价）。但是对外接口并不限于Restful，还有大家不愿意谈的纯Socket接口。对外接口可讲的东西非常多，不过思路上基本上和对内接口没太大的差别，所以我这里就主要讲下为什么选择纯Socket的接口。\r\n\r\n我们不愿意面对的长链接，很多研发，甚至公司级别，都不愿意去尝试这个技术。原因嘛，请看下面：\r\n\r\n1. 调试复杂，研发成本高\r\n1. 国内网络环境复杂，加重了第一条\r\n1. 国内用户对流量敏感，长链接心跳控制不好，容易被认为是偷流量\r\n1. 协议设计比较复杂，对研发的要求上升了很多\r\n\r\n但是长链接真的就那么难嘛，其实不然。更多时候，是产品层面用不上，一般只有IM类型的应用或者实时对战类的游戏才会选择长链接。当然偶尔我们也想提供一些高互动的交互，如果只是在应用内短暂使用，完全可以选择websocket（不过面对中国强大的高铁和运营商基础建设的规划TT）。\r\n\r\n\r\n\r\n## 接口的保护\r\n\r\n### 安全保护\r\n\r\n当我们面对很多外部接口的时候，我们需要考虑数据的安全性。为什么要考虑安全性：\r\n\r\n1. 包含用户数据\r\n1. 包含交易数据\r\n1. 以及甚至你不想让用户自己知道的数据\r\n\r\n保护接口的方式最基本的是SSL/TLS，然后呢：\r\n\r\n1. 对称加密的方式\r\n1. 非对称加密的方式\r\n1. 动态秘钥\r\n\r\n先说下我们为什么要在SSL/TLS下面再次进行加密呢？大家可能听说过以色列一个网络安全公司的事情了，换句话说一旦根证书被释放出去了，分分钟可以做SSL/TLS的man in middle的攻击。同时有些稍微高级的用户，会针对你的接口进行刷接口的行为。\r\n\r\n#### 对称加密 \r\n简单且易用。但是问题也明显，一旦秘钥泄漏或者被用户强猜出来了，那么影响还是很大的。\r\n\r\n#### 非对称加密的方式\r\n实现略复杂，同样也面临第一种方式的问题。但是可以有一个专门的秘钥管理人员，生成公钥和秘钥对后，将公钥交付给客户端，将秘钥交付给服务器端，大大减少了泄漏的可能性。同时用户即便猜出了客户端的公钥，也无法解密别的用户提交的数据，而只能伪造请求。\r\n\r\n#### 动态秘钥\r\n机器在运行的时候，定期自动和秘钥管控中心进行秘钥交换，每台机器在交互的时候使用的秘钥都不同。虽然可以带来一定的安全性，但是会给秘钥管理中心带来巨大的压力，同时调试也比较麻烦。这种方式个人认为适合使用在，传统小交易量的行业中，例如说银行的ATM机。\r\n\r\n\r\n### 熔断保护\r\n\r\n#### 内部接口需要吗？\r\n我们可以假定一个场景，服务者A有10个服务器，但是由于使用者B的算法错误，总是先选择服务者A的某台服务器，那么我们可以想象到服务者A的某台服务器压力非常大，然后逐步的就失去了响应，接着就会被认为被离线，接着使用者B又同样的方式打掉了第二台服务器。带来的影响就是，轻者响应速度很慢，严重的就是整个系统雪崩性的逐个崩溃停止服务。\r\n\r\n#### 一般怎么做\r\n\r\n不管对内部还是对外部，我们都可以选择使用漏桶和令牌桶等算法来保护接口。对外部，我们还可以通过使用时间戳加整个URL整体签名技术来防止重放攻击和进行限流保护。\r\n\r\n	f	2019-09-05 15:22:03.639104
121	自媒体 CMS 选型	前端技术	## 什么是CMS\r\nCMS是"Content Management System"的缩写，意为"内容管理系统"，从字面的意思上就可以看出来，这套系统系统主要是用来管理内容的，同时将内容进行发布。内容管理系统是企业信息化建设，电子政务和自媒体所不可或缺的一套Web系统。\r\n\r\n### 为什么会有CMS\r\n随着网络内容的丰富和发展，很多时候在短时间内会发布大量的内容，常常需要花费许多时间、人力和物力来处理信息更新和维护工作，甚至会需要专业的程序员来完成整合。\r\n当遇到网站扩充的时候，整合内外网及分支网站的工作就变得更加复杂，甚至还需重新建设网站，这样大大的加重了网站的运营成本。\r\n因此人们希望从每个内容都需要复杂的设置才能发布的情况中解脱出来，从而产生了CMS。\r\n\r\n### CMS的特点\r\n- 页面有序，网站风格统一\r\n- 信息分类明确，容易查找，容易管理\r\n- 上手容易，职责明确，程序员专注于系统设计，编辑专注于内容，运营人员专注于引流和SEO\r\n- 改版容易，只要改变内容模版，整站都统一发生百变。\r\n- 权限明确，可以针对会员和非会员开放不同页面\r\n\r\n### 主流CMS\r\n- Wordpress\r\n- Drupal\r\n- Joomla\r\n\r\n## CMS特性分析\r\n### Wordpress\r\n- 优点\r\n整体设计思路为blog模式，非常容易安装和使用，有大量的站点主题，二次开发也较简单。\r\n\r\n- 缺点\r\n由于核心设计的局限，扩展到复杂的网站功能需要非常多的代码量，而同样的功能也许在drupal和joomla中已经由现成的模块了。\r\n\r\n#### 适用范围\r\n- 无开发团队或小开发团队\r\n- 搭建个人网站\r\n- 个人blog\r\n- 小企业网站\r\n- 展示型网站\r\n- 中小型新闻类网站\r\n\r\n### Drupal\r\n- 优点\r\n程序设计思路有别于大多数CMS，免费模块多，扩展灵活。\r\n\r\n- 缺点\r\n很多常用功能需要自己选择安装模块来实现，中文资料较少，开发难度比较大。\r\n\r\n#### 适用范围\r\n- 有自己的开发小组或团队，团队中有前端工程师\r\n- 项目要求有很高的扩展性，未来的需求不明了\r\n- 高性能的要求站点\r\n- 大型新闻类网站\r\n- 大型展示类网站\r\n\r\n### Joomla \r\n- 优点\r\n设计思路比较传统，容易理解，容易使用，容易安装，模块多，主题多并且很美观，中文资料多。\r\n\r\n- 缺点\r\n很多好主题和模块都是收费的，模块开发灵活度不高。\r\n\r\n#### 适用范围\r\n- 网站目标明确\r\n- 快速搭建网站，有一定的预备投入资金\r\n- 不希望维持研发团队，但还想在可扩展的时候能得到商业支持\r\n- 传统企业中规模企业网站\r\n- 传统企业中规模展示网站\r\n\r\n## 总结\r\nDrupal更接近一个通用的Web应用程序框架，通过扩展开发可以实现几乎所有的网站需求，但是需要投入开发人员，适合有研发和编辑混合的小团队的自媒体使用。\r\n\r\nJoomla很成熟，虽然本身是开源免费，但是其模块和主题已经很商业化，使用这些商业模板和主题可以满足绝大部分企业网站或者电子商务网站的需求，适合大部分企业用户或非技术自媒体团队使用。\r\n\r\nWordpress轻巧简约，能够满足常见的内容发布功能，搭建blog，展示型网站很敏捷，适合个人自媒体或研发人员个人搭建blog使用。\r\n\r\n当然如果你想选择Hard模式挑战以下，可以使用本博主开发的[sblog](https://github.com/DavidAlphaFox/sblog)(深坑警告，自行跨越)。\r\n	f	2019-09-05 15:22:03.746229
122	读懂交换机的参数	DevOps	## 什么是交换机\r\n### 什么是交换\r\n交换（switching）是按照通信两端传输信息的需要，用人工或设备自动完成的方法，把要传输的信息送到符合要求的相应路由上的技术的统称。交换机有多个端口，每个端口都具有桥接功能，可以连接一个局域网或一台高性能服务器或工作站。实际上，交换机有时被称为多端口网桥。\r\n\r\n### 交换机核心功能\r\n交换机工作于OSI参考模型的第二层，即数据链路层。\r\n1. 交换机内部会在每个端口成功连接时，通过将MAC地址和端口对应，形成一张MAC表。\r\n1. 在今后的通讯中，发往该MAC地址的数据包将仅送往其对应的端口，而不是所有的端口。\r\n1. 交换机可用于划分数据链路层广播，即冲突域；但它不能划分网络层广播，即广播域。\r\n\r\n### 交换机如何实现的\r\n交换机拥有一条很高带宽的背部总线和内部交换矩阵。交换机的所有的端口都挂接在这条背部总线上，控制电路收到数据包以后，处理端口会查找内存中的地址对照表以确定目的MAC挂接在哪个端口上，通过内部交换矩阵迅速将数据包传送到目的端口。当目的MAC若不存在，广播到所有的端口，接收端口回应后交换机会“学习”新的MAC地址，并把它添加入内部MAC地址表中。\r\n使用交换机也可以把网络“分段”，通过对照IP地址表，交换机只允许必要的网络流量通过交换机。通过交换机的过滤和转发，可以有效的减少冲突域，但它不能划分网络层广播，即广播域。\r\n\r\n###  交换机和路由器的区别\r\n\r\n#### 交换机\r\n我们经常说到的以太网交换机实际是一个基于网桥技术的多端口第二层网络设备，它为数据帧从一个端口到另一个任意端口的转发提供了低时延、低开销的通路。 交换机内部核心处有一个交换矩阵，为任意两端口间的通信提供通路，或是一个快速交换总线，以使由任意端口接收的数据帧从其他端口送出。\r\n\r\n#### 路由器\r\n而路由器是OSI参考模型的网络层中的分组交换设备（或网络层中继设备），路由器的基本功能是把数据（IP报文）传送到正确的网络，二层转发能力有限。\r\n\r\n路由器支持广域网连接，丰富的广域网接口，包括serial、atm等等，支持多种不同有线传输介质，包括串行线缆、光纤、电话线、专线等等，并且接口上支持广域网连接的封装类型，支持HDLC、FR、ATM、PPP、ISDL封装。\r\n\r\n在主干网上，路由器的主要作用是路由选择。主干网上的路由器，必须知道到达所有下层网络的路径。这需要维护庞大的路由表，并对连接状态的变化作出尽可能迅速的反应。路由器的故障将会导致严重的信息传输问题。\r\n\r\n#### 三层交换机\r\n三层交换机就是具有部分路由器功能的交换机，三层交换机的最重要目的是加快大型局域网内部的数据交换，所具有的路由功能也是为这目的服务的，能够做到一次路由，多次转发。\r\n对于数据包转发等规律性的过程由硬件高速实现，而像路由信息更新、路由表维护、路由计算、路由确定等功能，由软件实现。\r\n三层交换机就是二层交换技术+三层转发技术。传统交换机是在OSI网络标准模型第二层数据链路层进行操作的，而三层交换技术是在网络模型中的第三层实现了数据包的高速转发，既可实现网络路由功能，又可根据不同网络状况做到最优网络性能。\r\n但是三层交换机依然无法取代路由器，三层交换机，它只是提供简单的路由功能及一些三层过滤功能。\r\n\r\n\r\n## 什么是PPS\r\npps的意思是Packet Per Second，每秒钟传输的数据包的数，也就是我们说的 包转发率。\r\n\r\n### 如何计算PPS\r\n假定我们是1个10Mbps的网络端口，那么我们就有以下的算式了，\r\n\r\n\t10M/[(64+12+8)*8]=14.881Kpps \r\n\r\n其中64代表以太网最小包，12代表以太网祯间隙，第一个8代表以太网帧头大小，第二个8代表1 byte = 8 bit。\r\n\r\n### PPS有什么用\r\nPPS代表在这条线路上，最大的转发速度是多少，这里可以看出10Mpbs的网卡接口最大转发速度每秒钟不能超过15K，同时这是我们计算交换机背板带宽和交换机包转发率的一个重要参数。\r\n\r\n##  什么是背板带宽\r\n背板带宽是交换机接口处理器或接口卡和数据总线间所能吞吐的最大数据量。背板带宽标志了交换机总的数据交换能力。\r\n### 如何计算背板带宽\r\n方法很简单，可以通过所有类型端口传输＊该类型端口数量之和的2倍这个方式计算出交换机的背板带宽。\r\n例如一个1个千兆＋4个百兆的端口的交换机，达到全双工无阻塞的需要的背板带宽如下：\r\n\t\r\n\t（1Gbps＋ 4 * 0.1Gbps) * 2 = 2.8Gbps\r\n### 交换机的PPS\r\n 交换机的PPS代表交换机转发数据包能力的大小。我们可以通过，所有类型端口PPS＊该类型端口数量之和的2倍这个方式计算出。\r\n例如 : 1个千兆＋4个百兆的端口的交换机，达到全双工无阻塞需要的包转发率如下：\r\n\r\n\t（1.488Mpps ＋ 4 * 0.1488Mpps) * 2 = 4.1664Mpps\r\n### 无阻塞全双工交换机\r\n我们依然使用 1个千兆＋4个百兆的端口的交换机为例子，当我们看到交换机数据指标中背板带宽>= 2.8Gbps，PPS(包转发率) >= 4.1664Mpps，就可以认为该交换机是无阻塞全双工的交换机。\r\n\r\n## 交换方式\r\n### 什么是交换方式\r\n交换方式代表一个以太网包通过端口A转发到端口B时，交换机内部是如何处理的。常见的交换方式有，直通式，存储转发式，碎片隔离式。\r\n### 常见交换方式\r\n#### 直通式\r\n顾名思义，就是从端口A直接转发到端口B，除了读取下以太网帧的头直接找出目的端口B是谁，直接将包发给端口B。\r\n#### 存储转发式\r\n交换机先将输入端口到来的数据包缓存起来，先检查数据包是否正确，并过滤掉冲突包错误，确定包正确后，取出目的地址，通过查找表找到想要发送的输出端口地址，然后将该包发送出去。\r\n#### 碎片隔离式\r\n该模式则是介于直通式和存储转发式之间的一种解决方案，在这个模式下如果发现一个以太网帧小于64字节，则会被丢弃，从而确保碰撞碎片不通过网络传播，能够在很大程度上提高网络传输效率。\r\n#### 交换方式的差异\r\n直通式，传输时延非常小，但是当出现千兆端口向百兆端口转发的时候，由于速率不匹配容易出现丢包现象，同时由于只读取了目标地址而不进行包完整性和正确性检测，很容易出现碰撞碎片在网络上传播。\r\n存储转发的方式解决了直通方式的问题，但是带来的问题是增加了时延。\r\n碎片隔离式，避免了长时延和碰撞碎片在网络上传播，但是缺少存储的过程，依然无法解决高速端口向低速端口转发丢包的情况。\r\n\r\n## 如何选择一款好的交换机\r\n根据RFC 894的说明，以太网封装IP数据包的最大长度是1500字节，也就是说我们可以得出，一个完整的以太网传输为12字节帧间隙 ＋ 8字节帧头 ＋ 6字节的目的MAC + 6字节的源MAC + 2字节的帧类型 + 1500 + 4字节的FCS。因此根据RFC 894和1秒钟业务数据包所承载的数据量，可以计算出我们要求交换机的PPS至少为下面的大小：\r\n\t\r\n\t 端口速率/(20+平均ip包大小＋12+8) = Xpps\r\n\r\n如果我们的应用在1秒钟发数据包的量要求的PPS > X的时候，就会产生丢包重传的可能性，就会出现我们的系统完全满跑的时候，瓶颈出现在了交换机上，网络时延变大。\r\n因此，不言而喻，我们不单单要选择百兆还是千兆，还要看懂交换机的各项参数。\r\n\r\n## 总结\r\n不要认为所有的交换机都是一样的，在轻负载的时候也许没问题，当你系统满载的时候，就会出现瓶颈吞吐反而一落千丈和自己的估算值相差甚远的情况。因此，在选择交换机的时候，不单单要看是百兆的还是千兆的，更要看背板带宽和包转发率。\r\n\r\n\r\n\r\n\r\n	f	2019-09-05 15:22:03.747146
123	如何实现高性能的秒杀服务	架构	## 什么是秒杀\r\n网络商家在某一预定的营销活动时间里，大幅度降低活动商品的价格，买家只要在这个时间里成功拍得此商品，便可以用超低的价格买到原本很昂贵的物品。由于在这个活动中商品的价格调整幅度很大，几千元商品可以用几十元拍到，或者几百元的商品用1元钱拍到，所以同时参与活动的人数会很多，这样商家就达到了营销的目的。当然正是由于同时参与人数过多的原因，甚至在活动正式开始后的一秒钟之内，所有的活动商品就已经被抢购完毕，所以此活动被称谓秒杀活动。\r\n简单的说，秒杀是网络商家为了提高人气吸引买家而采取的区别于竞拍方式的一种营销手段。\r\n\r\n## 为什么秒杀那么难\r\n从定义上来看，秒杀看起来并不是很难，它也就是普通的销售商品的过程，并且从定义上看业务流程甚至要比普通的商品销售要简单。但是秒杀却成了广大产品经理和程序员的心病。\r\n因为秒杀具有以下几个特点：\r\n\r\n1. 定时性\r\n1. 并发量巨大\r\n1. 购买数量有限制\r\n\r\n因此会引发下面这些问题：\r\n\r\n1. 库存管理\r\n\t- 售出商品总量不能超出投放量\r\n\t- 一个用户不能够买多个商品\r\n\t- 未及时付款的商品重新投放\r\n1. 并发量大\r\n\t- 短时间内大量用户涌入\r\n\t- 秒杀软件的刷单\r\n1. 数据库压力大\r\n\t- 大量的数据查询\r\n\t- 库存减少和付费事务\r\n\r\n## 如何解决\r\n\r\n### 大方向\r\n1. 削峰，不管是随机丢弃，还是多层筛选，尽可能减少进入核心业务的用户数\r\n1. 排队，在秒杀场景下，排队不单单可以减少系统压力，还能保证正确性\r\n1. 分区，使用分区可以降低一个节点当机带来整体性的损害或者雪崩性的系统不可用\r\n1. 最终一致，很多时候，不一定要强一致性，只要能保证最后数据的正确，哪怕是手工修复，都能带来大规模的性能提升\r\n\r\n### 削峰\r\n1. 产品层面\r\n\t- 通过设置秒杀的码，例如说小米的F券等\r\n1. 技术层面\r\n\t- 设置验证码，防止机器人\r\n\t- 随机丢弃部分用户，保护核心秒杀系统\r\n\t- 使用CDN，将静态资源等提前推送到离用户较近的地方，不占用核心机房的带宽\r\n\t- 使用流量保护，限制一个IP在一定时间内对系统的访问\r\n\r\n### 排队\r\n使用消息队列，如RabbitMQ。将可以延后处理的事情，推送到队列中，交给后端的工作工作者慢慢消化。\r\n但是这地方需要注意以下几点：\r\n\r\n1. 数据的排重，不可以让一件商品卖出去多次\r\n1. 服务可用性，防止因为单个队列因为压力过大而崩溃导致服务不可能用\r\n1. 数据安全性，需要队列支持持久化和事务性，防止数据没被处理就被丢弃或因队列崩溃而导致数据丢失\r\n\r\n### 分区\r\n在秒杀系统中，不能将用户全部都压在单个节点上，所以在一开始就应该做好分区策略，例如使用根据用户ID进行分区或者随机分区的方法。\r\n当然不单单要做好用户分区，也要做好系统的分区，例如说在排队阶段，需要使用一致性Hash将相同的数据发到同一个数据队列上，便于数据的排重。\r\n同时使用分区策略的时候，就代表系统是可以扩张的，当用户量级进一步扩大的时候，我们可以随时进行扩容。\r\n\r\n### 最终一致性\r\n不管系统设计的多么好，最终一致性还是需要做的，因为\r\n\r\n1. 在大并发的情况下，很难不出现异常节点（概率问题）\r\n1. 即便所有节点都正常，我们仍需要进行校验（人为出错的概率）\r\n1. 验证产品的稳定性和正确性（测试和公司信誉问题）\r\n\r\n采用最终一致性一般的做法，就是将关键日志收集起来，如用户秒杀到了产品，用户付费了等信息和最终保存在数据库中的数据进行对比，从而确认系统的正确性。	f	2019-09-05 15:22:03.854648
124	Linux 目录结构	Linux/Docker	## 文件系统\r\n\r\n在介绍Linux目录前，我们需要知道什么是文件系统，什么是目录。为了更好的理解Linux目录结构，我们先要了解Linux在文件系统上和我们常用的Windows相比有什么差异。\r\n\r\n### 什么是文件系统\r\n\r\n文件系统是操作系统用于明确存储设备或分区上的文件的方法和数据结构；即在存储设备上组织文件的方法。操作系统中负责管理和存储文件信息的软件机构称为文件管理系统，简称文件系统。文件系统由三部分组成：文件系统的接口，对对象操纵和管理的软件集合，对象及属性。从系统角度来看，文件系统是对文件存储设备的空间进行组织和分配，负责文件存储并对存入的文件进行保护和检索的系统。具体地说，它负责为用户建立文件，存入、读出、修改、转储文件，控制文件的存取，当用户不再使用时撤销文件等。\r\n\r\n### 什么是文件目录\r\n\r\n一个计算机系统中有成千上万个文件，为了便于对文件进行存取和管理，计算机系统建立文件的索引，即文件名和文件物理位置之间的映射关系，这种文件的索引称为文件目录。在我们一般的计算机操作时候，Windows上我们看到的文件夹就是文件目录。\r\n\r\n### Windows和Linux文件系统的差异\r\n\r\n#### 访问路径的差异\r\n\r\n在Windows系统中， 一切东西都是存放在硬盘上的。启动系统后，先确定硬盘，再确定硬盘上的分区以及每个分区所对应文件系统，最后是存放在某个分区特定的文件系统中的文件。 也就是说，Windows是通过 “硬盘上的某个分区-分区上的目录-特定文件” 这样的顺序来访问到一个文件的。\r\n\r\n在Linux系统中的一切都是存放在唯一的虚拟文件系统中，这个虚拟文件系统是树状的结构以一个根目录开始。启动系统后，先有这个虚拟文件系统，再识别出各个硬盘， 再把某个硬盘的某个分区挂载到这个虚拟文件系统的某个子树上，再确定分区对应的子目录文件系统，最后的文件就存放在这个特定的文件系统中。 也就是说， Linux 系统是通过 “虚拟文件系统-虚拟文件系统的目录-特定文件” 这样的顺序来访问一个文件的。\r\n\r\n从这里面我们可以明确的看出，Windows是直接映射物理设备如实的映射到系统中，而Linux是将物理设备映射到一个已经建立好的结构上。\r\n\r\n#### 设计理念的不同\r\n\r\n在Windows系统中，可以把文件大体分为两种： 系统文件和用户文件 。一般来说系统文件（例如Windows操作系统本身，一些系统程序，程序运行所需的库文件，以及一些系统配置文件等）存放的默认位置在C盘，其它用户文件，包含用户后来安装的程序以及一些数据文件等，用户可以把它们随意存放在任意的分区。\r\n\r\n在Linux 系统中，Linux将除了内核之外的东西，无论是键盘，鼠标，数据，程序，CPU，内存，网卡等硬件、软件和数据，还是内存中的东西，我们都可以在虚拟文件系统中的相应子目录对他们进行访问和操作。\r\n\r\n## Linux的目录结构\r\n\r\n因为Linux是一个开源可定制的操作系统，Linux的开发者们可以随便重新定义这些目录结构。为了防止发生这种情况，Linux开发者和爱好者们组建了FHS（Filesystem Hierarchy Standard）用来规范化Linux的虚拟目录结构。\r\n\r\n简单的可以说，Linux目录结构中，大致可以用，是否可变和是否可以被别的主机共享来概括\r\n\r\n|         |可共享的|不可共享的|\r\n| -------- | -------- |--------| -------|\r\n|不可变的|/usr（一般软件）、/opt（第三方可选文件）等 | /etc（全局配置文件）、/boot（启动文件）等|\r\n|可变的|/var/db（数据库文件）等|/var/run（进程PID）等|\r\n\r\n### Linux的目录起点-根目录（/）\r\n\r\n根目录是整个系统最重要的一个目录，因为不但所有的目录都是由根目录衍生出来的，同时根目录也与开机/还原/系统修复等动作有关。 由于系统开机时需要特定的开机软件、核心文件、开机所需程序、 静态或动态库等文件数据，若系统出现错误时，根目录也必须要包含有能够修复文件系统的程序才行。 \r\n\r\n### Linux下比较重要的目录\r\n\r\n#### /boot目录\r\n\r\n主要放置开机会使用到的文件，包括Linux核心档案以及开机选单与开机所需配置文件等等。Linux kernel常用的档名为：vmlinuz，如果使用的是GRUB做引导程序，则还会存在/boot/grub/这个目录。\r\n\r\n#### /bin目录\r\n\r\n/bin是根目录下比较特殊的一个目录。因为/bin放置的是在单人维护模式下还能够被操作的指令。在/bin底下的指令可以被root与一般帐号所使用，主要有：cat，chmod（修改权限），chown，date， mv，mkdir，cp，bash等等常用的指令。所以并不推荐挂载在和/boot目录上不同的硬盘上。\r\n\r\n#### /sbin目录\r\n\r\n和/bin目录类似，但是更加重要，里面的命令功能也更加强大一些。\r\n\r\n#### /lib目录\r\n\r\n/lib放置系统开机时可能用到的动态库或者静态库，，以及在/bin下的指令使用到的动态库或者静态库。 \r\n\r\n#### /etc目录\r\n\r\n系统主要的配置几乎都放置在这个目录内，例如人员的帐号密码文件、各种服务的配置文件等等。 一般来说，这个目录下的各档案属性是可以让一般使用者查阅的，但是只有root有权力修改。\r\n\r\n#### /root目录\r\n\r\n系统管理员（root）的家目录。 之所以放在这里，是因为如果进入单人维护模式而仅挂载根目录时，该目录就能够拥有root的家目录，所以我们会希望root的家目录与根目录放置在同一个分区中。\r\n\r\n#### /home目录\r\n\r\n这是系统预设的使用者家目录（home directory）。 在你新增一个一般使用者帐号时，预设的使用者家目录都会放到这里来。这里一般都是存放用户的个人文件，root可以读取和写入，非家目录的所有者是根据家目录所有者设置的权限来决定是否能看到里面的内容。一般在Linux交互终端的shell中 “~”代表当前使用者的家目录。\r\n\r\n### Linux目录结构为什么是这样的\r\n\r\nLinux目录结构是由Unix目录结构演变而来的。因为Unix的设计者们为了简化设计和提高可操作性提出了一切皆文件的理念，从而有了虚拟文件系统和这个看起来很复杂的目录结构。但是实际上是因为一些历史原因（我会告诉你是磁盘满了吗？）造成的。\r\n\r\n请参考阮一峰大神博客Unix目录结构的来历。\r\n\r\n## 总结\r\n\r\n对于Linux新人来说，Linux的目录结构确实让人混乱，但是它是有规律可寻找的，只要经常使用Linux就会发现里面有很多规律可循。因此我们不要看到Linux中复杂的文件目录结构就被吓到了，从而敬而远之。\r\n\r\n 	f	2019-09-05 15:22:03.961029
125	eJabberd 粘包处理	XMPP	## 什么是粘包\r\n\r\n因为UDP的协议特性，粘包现象并不会出现在UDP当中。因此粘包一般都出现在TCP当中，不过并不是使用TCP进行数据传输就会产生粘包。\r\n\r\n### TCP长链接\r\n\r\n客户端和服务器建立起一个TCP连接后，进行多次数据交换而不断开，必要的时候会插入和数据无关的心跳包来保持TCP连接不被中间路由强制断开。\r\n\r\n### TCP短链接\r\n\r\n客户端与服务器没进行一次数据交换就建立一次连接，完成数据交换后立刻断开连接。\r\n\r\n### 粘包的产生\r\n\r\n从上面可以看出，只有是TCP长连接存在的时候，才会发生粘包，因为TCP是流式传输的。在应用层面上虽然可以划分出一个个数据包，但是TCP传输层会将数据包整合一起发送或缓存着被应用一次性取出。简单的说就是：\r\n\r\n1.发送方需要等到缓存区被填充满了之后，再发送，因此造成了粘包现象。\r\n2.接收方不能快速的处理缓存区中的包，造成多个包堆积在缓存区中，因此造成了粘包现象。\r\n\r\n### 如何解决粘包\r\n\r\n最常见的方式就是，在每次发送数据包之前，先定义一个数据包长度。在接收数据包的时候先读取数据包长度，再读取整个数据包。进一步去完成业务操作。\r\n\r\n## eJabberd是如何处理粘包的\r\n\r\n作为即时通讯，eJabberd在和普通的客户端进行通讯的时候底层技术也使用的是TCP长连接（Web做客户端还有websocket和BOSH这两个技术）。因此eJabberd也会出现粘包这一现象，这里就介绍下eJabberd是如何处理粘包的。 \r\n\r\n### ejabberd_receiver模块\r\n\r\nejabberd_receiver可以说是eJabberd的XML输入流最主要的部分，它负责管理了socket，输入流的流控和XML的解析器。在每次收到数据后，ejabberd_receiver都会更新流量控制器，防止一个客户端过快的发送数据，而给ejabberd_c2s造成过大的负担。\r\n\r\n在ejabberd_receiver进程被创建之后，会立刻初始化一个exml_stream的解析器。因为XMPP是基于TCP长连接的XML流，而XMPP又规定了XML流上传输的数据是通过XML节这种结构化格式封装的，所以这里XML的节就相当于数据包前方的长度字段了。简单的说：读取了一个完整的XML节，就是一个数据包，剩下的数据就是后续的数据包。\r\n\r\n### exml项目\r\n\r\n#### exml_event\r\n\r\nexml_event是一个对libexpat进行封装的NIF，可以进行高效率的XML解析。exml_event会将xml数据解析成xml_element_start，xml_element_end和xml_cdata这三个标签。如果传入的数据没有被完全被解析，会保存在libexpat的parser的上下文当中。\r\n\r\n#### exml_stream\r\n\r\nexml_stream会将数据交给exml_event进行解析，会对解析出来的events（上面提到的xml_element_start，xml_element_end和xml_cdata）进行转换。将它们转化成xmlstreamstart,xmlstreamend和xmlel的Erlang的record。在exml_stream的上下文当中，会将没有闭合的xml节保存起来，直到整个XML节闭合后才会交还给ejabberd_receiver。\r\n\r\n## 总结\r\n\r\neJabberd使用XML节闭合的特性，作为数据包的边界来解决粘包问题。同时使用libexpat的parser来缓存没有解析完的原始数据，使用exml项目中的exml_stream来缓存解析成功，但是没有闭合的XML节。从而保证了XMPP流中的XMPP节的完整性和TCP长链接的粘包问题。	f	2019-09-05 15:22:04.068146
126	ejabberd_listener 代码分析	XMPP	## ejabberd_listener简介\r\n\r\nejabberd_listener模块，虽然是一个文件。但是，它包含了两个部分，第一部分是ejabberd_listener作为监控树进程启动，第二部分是作为这个监控树的子进程启动端口监听。\r\n\r\nejabberd_listener模作为监控树进程启动的时候，是作为ejabberd_sup监控树中的子进程启动的。该进程启动后会在本地注册为ejabberd_listeners进程，是一个one_for_one模式的空监控树为后面启动各种各样的端口监听进程准备的。可以参考ejabberd_sup.erl中的代码。\r\n\r\nejabberd_listener模块作为ejabberd_listeners监控树的子进程启动时，是在eJabberd整个应用启动的最后一步调用ejabberd_listener:start_listeners()完成的。可以参考ejabberd_app.erl中的代码。\r\n\r\nejabberd_listener模块的大量代码都是为端口监听服务的，我们就具体分析下这些代码。\r\n\r\n## ejabberd_listener开启监听\r\n``` erlang\r\nstart_listeners() ->\r\n  case ejabberd_config:get_local_option(listen) of\r\n    undefined ->\r\n      ignore;\r\n    Ls  ->\r\n       Ls2 = lists:map(\r\n          fun({Port, Module, Opts})  ->\r\n             case start_listener(Port, Module, Opts) of\r\n                {ok, _Pid} = R  -> R;\r\n                {error, Error}  -> throw(Error)\r\n           end\r\n        end, Ls),\r\n       report_duplicated_portips(Ls),\r\n      {ok, {{one_for_one, 10, 1}, Ls2}}\r\n   end.\r\n```\r\n从这段代码可以看出，ejabberd_listener:start_listeners()会从配置中找出所有的监听模块并通过start_listener函数逐个启动。start_listener通过调用start_listener2进而调用连个比较核心的函数start_module_sup和start_listener_sup来完成端口监听进程的启动。\r\n``` erlang\r\nstart_module_sup(_PortIPProto, Module) ->\r\n    Proc1 = gen_mod:get_module_proc("sup", Module),\r\n    ChildSpec1 =\r\n        {Proc1,\r\n         {ejabberd_tmp_sup, start_link, [Proc1, Module]},\r\n         permanent,\r\n         infinity,\r\n         supervisor,\r\n         [ejabberd_tmp_sup]},\r\n    supervisor:start_child(ejabberd_sup, ChildSpec1).\r\n```\r\nstart_module_sup使用gen_mod来生成监控树进程的名字，使用ejabberd_tmp_sup模块作为代码载体，创建一个监控进程在ejabberd_sup下启动。例如，ejabberd_c2s作为Module，那么Proc1就是ejabberd_c2s_sup。由于ejabberd_tmp_sup在构建监控树的时候，使用的是simple_one_for_one模式，所以在ejabberd_c2s_sup这个监控进程被创建成功后并不会创建一个ejabberd_c2s的进程。\r\n``` erlang\r\nstart_listener_sup(PortIPProto, Module, Opts) ->\r\n    case Module:socket_type() of\r\n        independent ->\r\n            Module:start_listener(PortIPProto, Opts);\r\n        _ ->\r\n \r\n            ChildSpec = {PortIPProto,\r\n                         {?MODULE, start, [PortIPProto, Module, Opts]},\r\n                         transient,\r\n                         brutal_kill,\r\n                         worker,\r\n                         [?MODULE]},\r\n            supervisor:start_child(ejabberd_listeners, ChildSpec)\r\n    end.\r\n```\r\nstart_listener_sup函数首先会判断Module的端口类型，如果是独立监听的模块，那么就让模块通过start_listener来自行启动监听，如果是其它类型的，都认为是可以使用ejabberd_listener作为监听模块来进行监听。直接将ejabberd_listener模块作为ejabberd_listeners的子进程启动起来。\r\n\r\n## ejabberd_listener进行监听\r\nejabberd_listener是支持TCP端口监听和UDP端口监听的，这里重点分析下ejabberd_listener针对TCP的accept操作。\r\n```erlang\r\naccept(ListenSocket, Module, Opts) ->\r\n    case gen_tcp:accept(ListenSocket) of\r\n        {ok, Socket} ->\r\n            case {inet:sockname(Socket), inet:peername(Socket)} of\r\n                {{ok, Addr}, {ok, PAddr}} ->\r\n                    ?INFO_MSG("(~w) Accepted connection ~w -> ~w",\r\n                              [Socket, PAddr, Addr]);\r\n                _ ->\r\n                    ok\r\n            end,\r\n            ejabberd_socket:start(Module, gen_tcp, Socket, Opts),\r\n            ?MODULE:accept(ListenSocket, Module, Opts);\r\n        {error, Reason} ->\r\n            ?INFO_MSG("(~w) Failed TCP accept: ~w",\r\n                      [ListenSocket, Reason]),\r\n            ?MODULE:accept(ListenSocket, Module, Opts)\r\n    end.\r\n```\r\naccept函数在gen_tcp进行accept成功后，先获取对端的地址，并交付给ejabberd_socket:start函数去关联数据接收进程和协议进程。而accept函数，就继续循环调用gen_tcp的accept来接入连接。\r\n\r\n## 自定义传输方式\r\n\r\n假设我们需要在XMPP协议外面封装一层其它的协议，例如说STOMP，应该如何实现自己的监听和数据解析呢？\r\n\r\n有以下两种方式实现：\r\n\r\n1.使用independent方式，实现监听和协议解析，可以参考ejabberd_cowboy.erl。\r\n\r\n2.使用raw方式，让ejabberd_listener完成监听，自定义模块进行协议解析，可以参考ejabberd_socket.erl\r\n\r\n不管使用哪种方式都需要实现关键函数socket_type。剩下关于自定义传输方式模块的编写，将在后面的博客进一步介绍。\r\n\r\n## 备注\r\n\r\n在MongooseIM中Webosocket和BOSH都被实现了。所以在有需要使用Websocket的生产环境中，博主非常推荐使用MongooseIM来代替社区版本ejabberd。	f	2019-09-05 15:22:04.069407
127	Erlang 的 NIF 资源释放	Erlang	## 为什么要用NIF\r\nErlang在数学运算和字符串处理方面是比较弱，很多时候需要借助C的nif来加速。不过我们今天不讨论这个，因为今天这事情的起因是我要将Redis的AOF嵌入到Erlang程序中。\r\n\r\n大家都知道Redis的AOF是要打开一个文件的，但是如果我们的Erlang进程因为意外退出，NIF打开的文件该怎么处理呢？因为NIF并不像Erlang的Driver那样可以监测Erlang进程的死活。\r\n\r\n## 解决方法\r\n这个时候，我想起了一个伟大的工程eleveldb。leveldb也是需要打开句柄，并且相应的进程也使用这个句柄。所以就去翻看了eleveldb的代码。发现几个非常重要的函数\r\n``` c\r\nErlNifResourceType *enif_open_resource_type(ErlNifEnv* env, const char* module_str, const char* name, ErlNifResourceDtor* dtor, ErlNifResourceFlags flags, ErlNifResourceFlags* tried);\r\n\r\nvoid *enif_alloc_resource(ErlNifResourceType* type, unsigned size);\r\n\r\nERL_NIF_TERM enif_make_resource(ErlNifEnv* env, void* obj);\r\n\r\nvoid enif_release_resource(void* obj);\r\n```\r\n这几个函数是怎么解决资源释放问题的呢？\r\n\r\n我们可以看到eleveldb在on_load的时候，使用enif_open_resource_type创建了一个资源类型。之后在每次请求打开DB的时候，用enif_alloc_resource分配出一个资源，然后用enif_make_resource和enif_release_resource将资源的控制权交给了调用的进程\r\n\r\n### Erts内部实现\r\n根据阅读Erts中NIF相关的代码，可以看到enif_alloc_resource在分配资源的时候，分配的资源引用计数为1，并且该资源不属于任何一个Erlang的进程。\r\n\r\n当我们调用enif_make_resource的时候，相当于在调用者的堆栈上分配了一个指向资源的指针，并将资源的引用计数加1。\r\n\r\n接着我们再使用enif_release_resource将资源的引用计数减少1，这样就相当将资源的控制权交给了调用的Erlang进程。\r\n\r\n那么资源是怎么安全释放的呢？这个时候我们可以看到资源的引用计数为1，并且这个引用者是Erlang进程堆。我们都知道Erlang进程崩溃后，Erts会清理Erlang进程堆和栈，释放资源。\r\n\r\n那么当Erlang进程崩溃后，就会调用enif_open_resource_type被调用的时候所传入的析构函数，而这个析构函数的参数就是前面所分配的资源。\r\n\r\n	f	2019-09-05 15:22:04.176057
128	Linux 的信号和线程	Linux/Docker	## 什么是线程\r\n线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成，每一个程序都至少有一个线程，若程序只有一个线程，那就是程序本身。\r\n\r\n同时线程是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不拥有系统资源，只拥有一点儿在运行中必不可少的资源，但它可与同属一个进程的其它线程共享进程所拥有的全部资源。\r\n\r\n一个线程可以创建和撤消另一个线程，同一进程中的多个线程之间可以并发执行。由于线程之间的相互制约，致使线程在运行中呈现出间断性。因此线程也有就绪、阻塞和运行三种基本状态。就绪状态是指线程具备运行的所有条件，逻辑上可以运行，在等待处理机；运行状态是指线程占有处理机正在运行；阻塞状态是指线程在等待一个事件（如某个信号量），逻辑上不可执行。\r\n\r\n## 什么是信号\r\n信号是一种IPC通信的形式，一般在Unix，类Unix或POSIX兼容的系统中使用。信号是一种异步通知进程或同进程中某个指定线程的方式。\r\n当信号被发送到进程的时候，操作系统会中断进程的控制流程，并且在执行非原子性的CPU指令时可以中断进程。\r\n### 信号使用的风险（新手坑）\r\n信号处理在存在竞态的，因为信号本身是异步的，在处理一个信号的过程中，令一个信号（甚至肯能是同类型的信号）会被直接发送到进程中请求进程处理。\r\n信号是可以打断系统调用的，不谨慎处理会引起程序自身的混乱，所以进程的信号处理过程，尽量做到没有副作用，也不要使用不可重入的函数。\r\n\r\n\r\n## Linux的线程\r\n\r\n### LinuxThreads\r\n在Linux的上古时代，Linux的线程技术和POSIX的标准是不同的，它使用自己的LinuxThreads库。这会为我们带来什么影响呢？\r\n\r\n让我们来回顾一下 LinuxThreads 设计细节的一些基本理念：\r\n\r\n1. 系统必须能够响应终止信号并杀死整个进程。\r\n1. 以堆栈形式使用的内存回收必须在线程完成之后进行。因此，线程无法自行完成这个过程。\r\n1. 终止线程必须进行等待，这样它们才不会进入僵尸状态。\r\n1. 线程本地数据的回收需要对所有线程进行遍历；这必须由管理线程来进行。\r\n1. 如果主线程需要调用 pthread_exit()，那么这个线程就无法结束。主线程要进入睡眠状态，而管理线程的工作就是在所有线程都被杀死之后来唤醒这个主线程。\r\n\r\n为了维护线程本地数据和内存，LinuxThreads使用了进程地址空间的高位内存（就在堆栈地址之下）。\r\n同步元语是使用信号来实现的。例如，线程会一直阻塞，直到被信号唤醒为止。并且，LinuxThreads将每个线程都是作为一个具有惟一进程ID的进程实现的。LinuxThreads接收到终止信号之后，管理线程就会使用相同的信号杀死所有其他线程（进程）。\r\n由于异步信号是内核以进程为单位分发的，而LinuxThreads的每个线程对内核来说都是一个进程，且没有实现"线程组"，因此，某些语义不符合POSIX标准，比如没有实现向进程中所有线程发送信号。如果核心不提供实时信号，LinuxThreads将使用SIGUSR1和SIGUSR2作为内部使用的restart和cancel信号，这样应用程序就不能使用这两个原本为用户保留的信号了。在Linux kernel 2.1.60以后的版本都支持扩展的实时信号（从_SIGRTMIN到_SIGRTMAX），因此不存在这个问题。根据 LinuxThreads 的设计，如果一个异步信号被发送了，那么管理线程就会将这个信号发送给一个线程，如果这个线程现在阻塞了这个信号，那么这个信号也就会被挂起，因此某些信号的缺省动作难以在现行体系上实现，比如SIGSTOP和SIGCONT，LinuxThreads只能将一个线程挂起，而无法挂起整个进程。\r\n\r\n### LinuxThreads带来了什么问题\r\n\r\n首先我们说下POSIX是如何定义多线程的：POSIX下一个多线程的进程只有一个PID。\r\n根据上面我们对LinuxThreads的描述，我们可以总结出LinuxThreads有下面这些问题：\r\n\r\n1. 它使用管理线程来创建线程，并对每个进程所拥有的所有线程进行协调。这增加了创建和销毁线程所需要的开销。\r\n1. 由于它是围绕一个管理线程来设计的，因此会导致很多的上下文切换的开销，这可能会妨碍系统的可伸缩性和性能。\r\n1. 由于管理线程只能在一个 CPU 上运行，因此所执行的同步操作在 SMP 或 NUMA 系统上可能会产生可伸缩性的问题。\r\n1. 由于线程的管理方式，以及每个线程都使用了一个不同的进程 ID，因此 LinuxThreads 与其他与 POSIX 相关的线程库并不兼容。\r\n1. 信号用来实现同步原语，这会影响操作的响应时间。另外，将信号发送到主进程的概念也并不存在。因此，这并不遵守 POSIX 中处理信号的方法。\r\n\r\n我们在这里不关注性能如何只关注POSIX兼容和信号处理问题。\r\n\r\n### NPTL\r\nLinuxThreads的问题，特别是兼容性上的问题，严重阻碍了Linux上的跨平台应用（如Apache）采用多线程设计，从而使得Linux上的线程应用一直保持在比较低的水平。在Linux社区中，已经有很多人在为改进线程性能而努力，其中既包括用户级线程库，也包括核心级和用户级配合改进的线程库。目前最为人看好的有两个项目，一个是RedHat公司牵头研发的NPTL（Native Posix Thread Library），另一个则是IBM投资开发的NGPT（Next Generation Posix Threading），二者都是围绕完全兼容POSIX 1003.1c，同时在核内和核外做工作以而实现多对多线程模型。这两种模型都在一定程度上弥补了LinuxThreads的缺点，且都是重起炉灶全新设计的。\r\nNPTL的设计目标归纳可归纳为以下几点：\r\n\r\n1. POSIX兼容性\r\n1. SMP结构的利用\r\n1. 低启动开销\r\n1. 低链接开销（即不使用线程的程序不应当受线程库的影响）\r\n1. 与LinuxThreads应用的二进制兼容性\r\n1. 软硬件的可扩展能力\r\n1. 多体系结构支持\r\n1. NUMA支持\r\n\r\n在技术实现上，NPTL仍然采用1:1的线程模型，并配合glibc和最新的Linux Kernel2.5.x开发版在信号处理、线程同步、存储管理等多方面进行了优化。和LinuxThreads不同，NPTL没有使用管理线程，核心线程的管理直接放在核内进行，这也带了性能的优化。\r\n\r\n### Linux线程总结\r\n比较新的Linux都已经开始使用NPTL了，所以我们可以忽略LinuxThreads的存在了，介绍它主要是为了让诸位读者更深入的了解线程和信号的恩恩怨怨（不要丢鸡蛋）。\r\n\r\n## Linux的信号\r\n\r\n### Linux是如何处理信号的\r\n\r\n随着Linux的内核版本不断提升，Linux的信号现在已经可以按照线程级别的触发了，换句话说就是，每个线程可以关注自己的信号了，并且可以区别性对待了。那我们需要注意什么呢？\r\n\r\n在多线程应用中，我们应当使用sigaction来代替singal函数，因为按POSIX的说法singal函数并没有明确定义自己在多线程应用中的行为。\r\n\r\n可以使用pthread_sigmask来为每个线程设置独立的信号掩码。同时在多线程应用中应当避免使用sigprocmask这个函数，原因也是POSIX中该函数并没有明确定义自己在多线程应用中的行为。\r\n\r\n这个时候，有人会产生疑问了，那么多线程下kill发出的进程级别的信号A怎么办？Linux是这样解决的，它会把这个信号交付给任意一个没有屏蔽信号A的线程。如果这信号没有被任何线程设置handler进行处理，就会触发POSIX规定的默认动作。\r\n\r\n接着有人就会问，我怎么向某个线程发消息呢，POSIX为我们准备了pthread_kill函数，我们可以直接向特定的线程发送消息。那么如果一个线程收到信号A，但是自己没有安装handler会发生什么？其实和进程级别的信号处理方法一样，直接触发默认动作，同样会结束整个进程。\r\n\r\n### 如何避免新手坑\r\n在具有事件循环的应用中，在信号的的handler中，可以将信号直接放入程序的队列中，立刻返回。这样直到线程从程序的队列中取出这个信号为止，整个线程看起来就像没有“中断”。\r\n如果不知道该怎么做，去看看著名的libev吧。\r\n\r\n\r\n### 信号SIGSEGV\r\n\r\n这个信号，也许是大家最不想见到，为什么呢？我们看这个信号的定义：\r\n\r\n当当前程序对内存的引用无效时，就会产生当前信号，也就是我们常说的“段违例”。\r\n\r\n以下几种情况会产生该信号：\r\n\r\n\t1.进程引用的内存页面不存在（例如，该页面位于堆和栈之间的映射的区域）\r\n\t2.进程试图更新只读内存页（例如，程序文本段或已经被标记为只读的内存映射区域）\r\n\t3.进程试图在用户态去访问内核部分的内存\r\n\r\n好了，我们都知道这个信号引发的结果就是进程退出。不过我们都忽视了一个问题，在现代的Linux上，按照POSIX的定义，这个信号是系统产生的线程级别的信号。换句话说，如果某个线程A出现了内存引用无效，那么产生的信号，会投递到线程A的信号队列中，而不是像进程级别的信号无法确定接受者是谁。\r\n\r\n\r\n## JVM的安全区域\r\n\r\n如果我们想让所有Java线程停下来的时候，在JVM的JavaThread执行到大家所知道的test 特定页面的指令时，就会因为更新不可读页面而触发SIGSEGV信号。那么对于那些正在执行native代码的JavaThread该怎么办，JVM中的注释写的非常清楚，native返回JVM时会检查是否能返回的。\r\n\r\n好了再多说一句，JVM是如果将特定内存保护起来的呢？这个需要看操作系统的API了，在Linux中是mprotect。\r\n\r\n\r\n\r\n## 总结\r\n多读读POSIX标准和Intel的CPU体系结构，会让自己在开发变的容易些。	f	2019-09-05 15:22:04.177324
129	超级总线 eJabberd	XMPP	## Jabber组件协议\r\n前面关于[IQ处理](https://www.ttalk.im/topics/49)的文章中，提到过，可以通过增加IQ处理器来扩展eJabberd。但是这对很多不懂Erlang的同学造成了很大困扰。但是XMPP已经充分考虑到eJabberd作为总线的可能性，因此设计了Jabber组件协议。\r\n\r\n### 简介\r\n传统上有两种完全不同的服务器端组件类型：内部组件（ 利用服务器的内部API提供服务）和外部组件（组件在一个协议框架上与服务器联系，因此不依赖任何特定的服务器实现）。   \r\n目前使用的组件协议框架使得一个外部组件能够连接到一个服务器（通过适当的配置和验证）并能通过服务器发送和接收XML节。有两种连接方法：“accept”和“connect”。使用“accept”方法时，服务器等待并接受被组件初始化的连接。使用“connect”方法时，由服务器初始化到组件的连接。在实际的使用中，“accept”方法更为常用。\r\n\r\n## eJabberd中外部组件处理\r\n### 接入处理\r\neJabberd是通过ejabberd_service来实现的Jabberd组件协议。在eJabberd启动的时候，会启动一个有别于ejabberd_c2s所监听的XML流端口进行监听，因为jabber组件的XML流处理和eJabberd_c2s的流处理方式完全不同。\r\n\r\n组件为了将自己注册到XMPP服务器上，需要和XMPP服务器进行下面交互\r\n``` XML\r\n组件向服务器发送消息\r\n<stream:stream\r\n    xmlns='jabber:component:accept'\r\n    xmlns:stream='http://etherx.jabber.org/streams'\r\n    to='plays.shakespeare.lit'>\r\n\r\n服务器会回应下面的消息\r\n<stream:stream\r\n    xmlns:stream='http://etherx.jabber.org/streams'\r\n    xmlns='jabber:component:accept'\r\n    from='plays.shakespeare.lit'\r\n    id='3BF96D32'>\r\n\r\n接着组件要给服务器发送handshake\r\n\r\n<handshake>aaee83c26aeeafcbabeabfcbcd50df997e0a2a1e</handshake>\r\n\r\n服务器需要给组件回复一个空的handshake来表示确认\r\n<handshake/>\r\n```\r\n### ejabberd_service模块\r\nejabberd_service的基本流程和ejabebrd_c2s进程是相似的，其中重点是wait_for_handshake的处理，这个函数内会验证handshake中的hash，并将自己注册到路由表的组件相关的表。在注册的过程，会默认注册本地和全集群路由。\r\n\r\n``` Erlang\r\n\r\nwait_for_handshake({xmlstreamelement, El}, StateData) ->\r\n    #xmlel{name = Name, children = Els} = El,\r\n    case {Name, xml:get_cdata(Els)} of\r\n        {<<"handshake">>, Digest} ->\r\n            case sha:sha1_hex(StateData#state.streamid ++\r\n                         StateData#state.password) of\r\n                Digest ->\r\n                    %% 如果handleshake的认证成功了\r\n                    %% 就注册路由信息\r\n                    %% 这里面注册的路由和普通的路由是不同的\r\n                    case register_routes(StateData) of\r\n                        ok ->\r\n                            send_text(StateData, <<"<handshake/>">>),\r\n                            {next_state, stream_established, StateData};\r\n                        {error, Reason} ->\r\n                            ?ERROR_MSG("Error in component handshake: ~p", [Reason]),\r\n                            send_text(StateData, ?CONFLICT_ERR),\r\n                            {stop, normal, StateData}\r\n                    end;\r\n                _ ->\r\n                    send_text(StateData, ?INVALID_HANDSHAKE_ERR),\r\n                    {stop, normal, StateData}\r\n            end;\r\n        _ ->\r\n            {next_state, wait_for_handshake, StateData}\r\n    end;\r\n\r\n```\r\n### 处理业务\r\nejabberd_service是外部组件在服务器的代表，如同ejabberd_c2s一样自身并不处理相关业务，只是将数据转发给相应的外部组件。\r\n\r\n需要注意的是，由于ejabberd_service在路由中注册本节点内外部服务的时候，是使用mneisa的set，换句话一个外部服务同时只有一个可用，但是注册全集群的时候是使用mnesia的bag，也就是说如果本节点没相应的服务，会向全集群中任何一个有该该外部服务的节点转发消息。\r\n\r\n\r\n## 总结\r\nJabber组件协议，已经将XMPP协议带离一个聊天服务器的范畴了，可以让研发人员不需要改动XMPP服务器就可以轻松扩展。尤其是eJabberd的优良实现，更是将这一特性发挥的非常好。在很多时候，eJabberd完全可以当作一个强大的消息总线来使用，再上面挂接各种服务。\r\n	f	2019-09-05 15:22:04.284338
130	eJabberd 的 IQ 处理	XMPP	## XMPP的IQ\r\n\r\n### 什么是IQ机制\r\nXMPP将信息系统抽象的非常好，将信息直接划分成了下面三大类：\r\n\r\n1. <message/> 纯粹的消息"推送"机制，将实体推送信息到另一个实体, 类似发生在email系统里的通讯一样。\r\n1. <presence/> 特定的"广播"或"发布-订阅"机制, 这里多个实体接收关于他们订阅的一个实体的信息。\r\n1. <iq/> 是一个"请求-应答"机制, 类似某些情况下的超文本传输协议HTTP。\r\n\r\n从上面的分类就可以看出来，<message/>是一种双向的，异步的，一对一或一对多的通信机制。<presence/>是一种单向的，一对多广播机制。至此可以看出，剩下的就是请求应答机制了。\r\n\r\n### IQ机制怎么工作的\r\nXMPP中规定IQ消息必须满足下面的条件\r\n\r\n1.  必须有id属性，以便于实现跟踪和请求应答机制\r\n1. 必须有type属性，以便于告知操作类型，并且必须是下面相应的值\r\n  - get  用于请求信息, 查询需要什么数据以完成更多操作, 等等。\r\n  - set  用于完成某个操作提供需要的数据, 设置新值, 取代旧值, 等等。\r\n  - result 用于对成功的get或set请求的应答。\r\n  - error 用于报告关于处理或递送一个get或set请求时发生的错误。\r\n1. 接收到类型为get或set的IQ请求的实体必须返回一个类型为result或error的IQ应答. 该应答必须保留请求中的id属性(或为空，如果生成的节没有包含id属性)。\r\n1. 接收到类型为result或error节的实体不能发送更多的类型为"result"或"error"的IQ应答来应答; 但是 请求实体可以发送另一个请求(例如, 使用类型为set的IQ对之前在get/result对中查询到的信息提供特定的信息)。\r\n1. 类型为get或set的IQ节必须严格地包含一个子元素, 用来定义特定请求。\r\n1. 类型为result的IQ节必须包含零或一个子元素。\r\n1. 类型为error的IQ节可以包含相关的get或set子元素并且必须包含一个<error/>子元素。\r\n\r\n### IQ的价值\r\n至此，可以看出IQ机制是在XMPP当中提供了一个完整的RPC方案，可以是同步的，也可以是异步的，这样就可以非常方便的去扩展XMPP了。\r\n\r\n## eJabberd是如何处理IQ请求的\r\n\r\n### eJabberd中的IQ是如何触发的\r\n\r\n在上一篇介绍 [eJabberd的路由系统](https://www.ttalk.im/topics/47) 中就提到，当消息路由到ejabberd_sm模块时，且JID的resource部分为空了，就有可能触发IQ。在ejabberd_sm中IQ的handler都保存在sm_iqtable这个命名的ETS中。当ejabberd_c2s进程在这张ETS中找到相应的IQ处理模块的时候，如果处理模块没有额外参数的情况下，直接就使用模块对应函数处理，但是当模块有额外参数的时候，就会使用gen_iq_handler:handle来进行相应处理。细节可以看下面的代码\r\n``` Erlang\r\nprocess_iq(From, To, Packet) ->\r\n    IQ = jlib:iq_query_info(Packet),\r\n    case IQ of\r\n        #iq{xmlns = XMLNS} ->\r\n            Host = To#jid.lserver,\r\n            %% IQ处理器的NS部分是全局唯一性的\r\n            %% 所以在查找的时候，只有一条记录\r\n            case ets:lookup(sm_iqtable, {XMLNS, Host}) of\r\n                [{_, Module, Function}] ->\r\n                    ResIQ = Module:Function(From, To, IQ),\r\n                    if\r\n                        ResIQ /= ignore ->\r\n                            ejabberd_router:route(To, From,\r\n                                                  jlib:iq_to_xml(ResIQ));\r\n                        true ->\r\n                            ok\r\n                    end;\r\n                [{_, Module, Function, Opts}] ->\r\n                    gen_iq_handler:handle(Host, Module, Function, Opts,\r\n                                          From, To, IQ);\r\n                [] ->\r\n                    Err = jlib:make_error_reply(\r\n                            Packet, ?ERR_SERVICE_UNAVAILABLE),\r\n                    ejabberd_router:route(To, From, Err)\r\n            end;\r\n        reply ->\r\n            ok;\r\n        _ ->\r\n            Err = jlib:make_error_reply(Packet, ?ERR_BAD_REQUEST),\r\n            ejabberd_router:route(To, From, Err),\r\n            ok\r\n    end.\r\n```\r\n\r\n### gen_iq_handler模块\r\n\r\neJabberd将IQ处理方案划分成下面四类：\r\n1. no_queue 无队列\r\n1. one_queue 一个队列\r\n1. {queues, N} 多个队列负载均衡\r\n1. parallel 并发处理\r\n\r\n为了方便管理，eJabberd统一使用gen_iq_handler来进行注册，当然也保留了不使用gen_iq_handler来注册IQ处理机制的方式。当不使用gen_iq_handler注册IQ处理机制的时候，相当于gen_iq_handler的no_queue模式，IQ处理都会在ejabberd_c2s进程中直接执行，唯一的差别是，gen_iq_handler会默认进行异常捕获。\r\n\r\n#### gen_iq_handler是如何注册IQ处理模块的\r\n\r\neJabberd中的IQ处理模块都会被注册到ejabberd_sm进程所拥有的sm_iqtable这个ETS中，整个过程都是依赖ejabberd_sm这个gen_server的消息有序性来保证事务的。当不小心注册了一个同名的IQ，最后写入ETS的模块会被触发。\r\n\r\ngen_iq_handler在注册IQ模块的时候，会检测上面所说的处理方案，如果是one_queue或 {queues, N} 就会通过ejabberd_iq_sup这个supervisor产生一个或多个gen_iq_handler进程，并将这些进程的Pid作为附加参数注册到sm_iqtable中。\r\n\r\n#### gen_iq_handler是如何处理IQ\r\n\r\n当使用gen_iq_handler:handle来触发IQ处理的时候，会出现下面几种情况。\r\n\r\n1.  no_queue 直接使用调用者的ejabberd_c2s 进程来处理，默认捕获异常\r\n1.  one_queue 使用注册时候产生的gen_iq_handler来进行排队处理\r\n1.  {queues, N} 使用注册时候产生的多个gen_iq_handler中的任意一个（随机负载均衡）来进行处理\r\n1. parallel 使用spawn生成一个无关联进程进行处理\r\n\r\n## 总结\r\n\r\nXMPP的IQ机制给XMPP带来了非常强的扩展能力，eJabberd中又将IQ处理方案进行了细化。我们甚至可以将eJabberd服务器当作一个强力的RPC业务处理服务器，是不是很有意思。\r\n\r\n	f	2019-09-05 15:22:04.391017
132	SBCL 中设置 UTF-8	Lisp	## SBCL是什么\r\n\r\nSBCL是Common Lisp的一个实现，支持绝大部分平台。\r\n\r\n## 出现了什么问题\r\nSBCL对UTF8的支持一直很好，但是在编写一个东西的时候出现了个奇怪的东西，通过SBCL的的repl存储到redis中的数据，并不是UTF-8的，并且是完全错误的。\r\n\r\n## 解决问题\r\n\r\n### 输入输出编码检查\r\n在SBCL的repl中使用下面的代码\r\n```lisp\r\n(stream-external-format *standard-output*)\r\n(stream-external-format *standard-input*)\r\nsb-impl::*default-external-format*\r\n```\r\n得到的结果是(:ASCII :REPLACEMENT #\\?)，说明默认的输入输出的格式是ASCII的\r\n\r\n### 如何解决\r\n是用了下面这段代码\r\n```lisp\r\n(defun set-default-external-format (external-format)\r\n  (assert (sb-impl::find-external-format external-format))\r\n  (setf sb-impl::*default-external-format* external-format)\r\n  (with-output-to-string (*error-output*)\r\n    (setf sb-sys:*stdin*\r\n          (sb-sys:make-fd-stream 0 :name "standard input" :input t :buffering :line))\r\n    (setf sb-sys:*stdout*\r\n          (sb-sys:make-fd-stream 1 :name "standard output" :output t :buffering :line))\r\n    (setf sb-sys:*stderr*\r\n          (sb-sys:make-fd-stream 2 :name "standard error" :output t :buffering :line))\r\n    (setf sb-sys:*tty* \r\n        (make-two-way-stream sb-sys:*stdin* sb-sys:*stdout*)) \r\n    (princ (get-output-stream-string *error-output*) sb-sys:*stderr*)))\r\n```\r\n将SBCL的repl输入输出设定为了UTF-8\r\n	f	2019-09-05 15:22:04.605357
133	Sblog 开发笔记	ML类	## 为什么是Haskell\r\n因为想尝试下新东西，在决定使用ttalk.im这个域名，当然现在的你所看到的，已经不是Sblog。前我还做个很多很多的尝试，例如[mate.im](https://github.com/DavidAlphaFox/mate.im)是使用Elixir开发的。当然还有一个叫ailink.io的网站，是使用Clojure开发的。\r\n\r\n令一方面，在使用了很久的Erlang之后，感觉函数类语言比较适合自己，当然我也拿Haskell写过一些非Web的产品，为了让自己更加专注，所以就选择了全部使用函数类语言开发后端（Erlang和Haskell）。\r\n\r\n## Web开发选型\r\n因为自己对Haskell的功底并没有达到很高的境界，就没有选择Haskell开发Web的神奇Yesod，而是选择比较轻量级的Scotty，当然当时也有想尝试Spock（Live long and prosper 或者 Peace and long life）的想法。不过因为自己已经看了好一段时间Scotty的代码，所以就决定使用了Scotty。\r\n\r\n选择Postgresql-simple完全是因为自己还不想接触复杂的Haskell Teamplate，并且为了让整个项目看起来不太恐怖（比较害怕哪天自己都不知道自己在写什么）。\r\n\r\n选择Blaze-html的原因是因为个人一贯喜欢吧View直接写成代码，而不是渲染模板文件的原因，但是从生产角度上来讲，渲染模板文件的做法才更加实际。\r\n\r\n前端CSS框架并没有使用大家所熟知的Bootstrap，而是选择使用了semantic-ui，也是为了尝试些新的东西。不过在JS的选择上，并没有选择比较花哨的ReactJS或Vue这类的，更多是简单的JQuery，因为这个项目的重点是后端Haskell开发Web的实践。\r\n\r\n### Scotty使用心得\r\nScotty作为一个Web框架，代码量非常少，非常轻量级。因此很多东西需要自己重新造轮子，但是也为每个人带来了很多灵活的地方，整个项目相当是我自己在Scotty基础上封装了一些便于操作数据库的东西。\r\n\r\nScotty的优势：\r\n\r\n1. 轻量级，代码简单，有问题可以直接翻代码\r\n1. 上手曲线平滑，没有大的波动\r\n1. 路由解析和异常处理非常完善\r\n1. 性能非常好\r\n\r\nScotty的缺陷：\r\n\r\n1. 没有URI相关操作工具\r\n1. 不提供很多常见的组件，例如说Cache，Cookie，CSRF等\r\n\r\n## 整个项目总结\r\nHaskell开发的Web项目，尤其是对大量的列表读取处理还是非常简单，因为有大量的工具函数，例如说map，filiter，fold等。\r\n整个项目冗余代码偏多，并没有使用太多的Haskell的高级技巧，甚至没有使用Class来完成不同的数据类型进行同名操作。因此整个项目并不是优良的Haskell项目，但是依然不影响它作为一个Scotty入门教程的项目。\r\n### 代码地址\r\n整个项目被开源放到了[Github](https://github.com/DavidAlphaFox/sblog)上，有兴趣的同学可以帮忙添加一些特性。\r\n	f	2019-09-05 15:22:04.606547
135	OCaml 使用 PostgreSQL	ML类语言	安装Ocaml的PostgreSQL的绑定\r\n```\r\nopam install postgresql\r\n```\r\n在PostgreSQL中建立用户\r\n```sql\r\nCREATE ROLE web;\r\nALTER ROLE web LOGIN ;\r\nALTER USER web WITH PASSWORD '123456';\r\n```\r\n在PostgreSQL建立一张表\r\n```sql\r\nCREATE TABLE compay\r\n( id INTEGER PRIMARY KEY,\r\n  name text NOT NULL,\r\n  age integer\r\n );\r\n```\r\n让我们打开OCaml的交互编程，输入下面的代码\r\n```ocaml\r\n#use "topfind";;\r\n#thread;;\r\n#require "postgresql";;\r\n\r\nopen Printf;;\r\nopen Postgresql;;\r\n\r\nlet conn = new connection ~dbname:"postgres" ~host:"localhost" ~user:"web" ~password:"123456" ();;\r\n\r\nlet query = "SELECT id, name,age FROM company WHERE id = $1";;\r\n\r\nlet show res =\r\n  for tuple = 0 to res#ntuples - 1 do\r\n    for field = 0 to res#nfields - 1 do\r\n      printf "%s, " (res#getvalue tuple field)\r\n    done;\r\n    print_newline ()\r\n  done;;\r\n\r\nlet run s = show @@ conn#exec ~expect:[Tuples_ok] ~params:[| s |] query;;\r\n\r\n\r\nassert ((conn#prepare "query_company" query)#status = Command_ok);;\r\n\r\nlet prepared_run s name =\r\n  show @@ conn#exec_prepared ~expect:[Tuples_ok] ~params:[|s|] name\r\n;;\r\n\r\nrun "1";;\r\nprepared_run "2" "query_company";;\r\n```	f	2019-09-05 15:22:04.608306
136	在 SBCL 中获取对象位长	Lisp	## 起因\r\n近期大量语言发生了突飞猛进的发展，很多古代语言从单纯的支持ASCII演变成支持utf8。但是utf8并非是一个有效字符存储方案，所以在Erlang中一个中文字符会被定义为16位，也就是我们常说的utf16，从而达到高效但非节约的存储。那么自己常用的Common Lisp中，一个中文字符又是会被定义为多少位呢？\r\n\r\n## 解决方案\r\n首先要实现下面这函数\r\n``` Lisp\r\n(defun get-object-size/octets (object)\r\n  (sb-sys:without-gcing\r\n    (nth-value 2 (sb-vm::reconstitute-object\r\n                  (ash ;; 因为返回了一个fixnum对象的lispobj，因此需要进行这一步的处理\r\n                        (logandc1 sb-vm:lowtag-mask (sb-kernel:get-lisp-obj-address object)) ;; 掩码掩掉最后nbit，得到lispobj真正地址,n取决于平台，x64是4\r\n                       (- sb-vm:n-fixnum-tag-bits))))))\r\n```\r\n为什么会有这个函数呢，因为lisp在创建对象的时候和Erlang是一致的，都会将指针的空位设置为标签掩码。\r\n\r\n接着我们测试一个中文字符\r\n``` Lisp\r\n(defvar *c* "中")\r\n(get-object-size/octets *c*) ;; 32bit\r\n```\r\n但是查阅了SBCL的代码的时候，发现\r\n``` Lisp\r\n(def!constant sb!xc:char-code-limit #!-sb-unicode 256 #!+sb-unicode #x110000\r\n  "the upper exclusive bound on values produced by CHAR-CODE")\r\n```\r\n也就是说，SBCL会使用一个32bit的位长来表示一个utf16的字符，具体可以参阅[Memory Layout](http://www.sbcl.org/sbcl-internals/Memory-Layout.html)。\r\n## 总结\r\n从这个测试中可以发现，绝大部份古代语言真对宽字符会直接处理成utf16，而不是utf8。当然也有一些特例，例如OCaml，一个字符依然是8bits，对宽字符会处理成utf8。	f	2019-09-05 15:22:04.609308
143	Elixir 中的黑科技	Erlang/Elixir	## 什么宏\r\n宏（Macro)，是一种批量处理的称谓。一般说来，宏是一种规则或模式，或称语法替换 ，用于说明某一特定输入（通常是字符串）如何根据预定义的规则转换成对应的输出（通常也是字符串)。这种替换在预编译时进行，称作宏展开。\r\n说道宏，就不得不提一个经典语言和它的宏。\r\n\r\n### Lisp\r\nLisp的特点\r\n\r\n1. 数据就代码，代码就是数据\r\n1. LISP中所有的都是list, 当然也可以叫做S表达式。\r\n1. 如果把list中的第一元素视为函数，该list就可视作代码一样运行。术语叫做求值, evaluate。当然也可以不求值，此时list就是数据。因此这里引出一个重要概念 ，代码也是数据，一切皆为数据，一切都是list。\r\n\r\n### Lisp的宏\r\n\r\n1. 如果一个list传递给lisp函数，则先被求值为atom（一个特殊的list，不能再被求值）后再传递进去 如果一个list传递给lisp宏，则不被求值，而将其完整的传递进去，至于宏里面怎么干，随便宏的实现者怎么玩。像C的宏吧，不过C的宏只是文本替换，还是简单了点。\r\n1. 宏可以返回的是一个list，而且被视作可以求值的list，也就是代码。\r\n1. 两阶段执行，第一阶段在编译期，称之为展开，第二阶段在运行期，称之为计算。宏在展开时，并不对实参求值，只把宏定义中对形参的引用简单替换为实参。实参在计算阶段时才求值。\r\n\r\n\r\n## Elixir是什么\r\nElixir 是一个基于Erlang虚拟机强大的类Ruby语法的编程语言。\r\n\r\n## Elixir的宏\r\n\r\nElixir也是支持宏的，并且Elixir的宏也是异常强大的，也做到了两阶段执行。\r\n但是今天要介绍的主要是关于Elixir中use和@before_compile的部分。\r\n\r\n### 代码例子\r\n``` elixir\r\ndefmodule MyModule do\r\n  use MyPlugBuilder\r\n\r\n  plug :hello\r\n  plug :world, good: :morning\r\nend\r\n```\r\n\r\n``` elixir\r\ndefmodule MyPlugBuilder do\r\n\r\n  defmacro __using__(_opts) do\r\n    quote do\r\n      import MyPlugBuilder, only: [plug: 1, plug: 2]\r\n      Module.register_attribute(__MODULE__, :plugs, accumulate: :true)\r\n      @before_compile MyPlugBuilder\r\n    end\r\n  end\r\n\r\n  defmacro plug(plug, opts \\\\ []) do\r\n    quote do\r\n      @plugs {unquote(plug), unquote(opts)}\r\n    end\r\n  end\r\n\r\n  defmacro __before_compile__(env) do\r\n    plugs = Module.get_attribute(env.module, :plugs)\r\n    quote do\r\n      def plugs, do: unquote(plugs)\r\n    end\r\n  end\r\nend\r\n```\r\n#### MyPlugBuilder的展开\r\n\r\n#### 第一步\r\n``` elixir\r\ndefmodule MyModule do\r\n  # ----\r\n  # use MyPlugBuilder\r\n  # ---- ↓\r\n  require MyPlugBuilder\r\n  MyPlugBuilder.__using__([])\r\n  # ----\r\n\r\n  plug :hello\r\n  plug :world, good: :morning\r\nend\r\n```\r\n因为use MyPlugBuilder这句话会展开成\r\n\r\n\trequire MyPlugBuilder\r\n\tMyPlugBuilder.__using__\r\nMyModule 会请求引入 MyPlugBuilder，接着会调用`__using__`宏，并且默认参数为[]\r\n\r\n#### 第二步\r\n ``` elixir\r\ndefmodule MyModule do\r\n  require MyPlugBuilder\r\n\r\n  # ----\r\n  # MyPlugBuilder.__using__([])\r\n  # ---- ↓\r\n  import MyPlugBuilder, only: [plug: 1, plug: 2]\r\n  Module.register_attribute(__MODULE__, :plugs, accumulate: :true)\r\n  @before_compile MyPlugBuilder\r\n  # ----\r\n\r\n  plug :hello\r\n  plug :world, good: :morning\r\nend\r\n ```\r\n \r\n `__using__`宏会立刻被执行，相当于立刻将MyPlugBuilder的函数引入进来，并且给MyModule注册了一个叫做plugs的模块属性。同时告诉编译器，稍后编译MyPlugBuilder的时候，调用`__before_compile__`。\r\n\r\n#### 第三步\r\n``` elixir\r\ndefmodule MyModule do\r\n  require MyPlugBuilder\r\n\r\n  import MyPlugBuilder, only: [plug: 1, plug: 2]\r\n  Module.register_attribute(__MODULE__, :plugs, accumulate: :true)\r\n  @before_compile MyPlugBuilder\r\n\r\n  # ----\r\n  # plug :hello\r\n  # plug :world, good: :morning\r\n  # ---- ↓\r\n  @plugs {:hello, []}\r\n  @plugs {:world, [good: :morning]}\r\n  # ----\r\nend\r\n```\r\n此时还没有展开__before_compile__，而是先展开从MyPlugBuilder模块中import进来的plug宏，完成相关定义内容\r\n\r\n#### 第四步\r\n``` elixir\r\ndefmodule MyModule do\r\n  require MyPlugBuilder\r\n\r\n  import MyPlugBuilder, only: [plug: 1, plug: 2]\r\n  Module.register_attribute(__MODULE__, :plugs, accumulate: :true)\r\n  @before_compile MyPlugBuilder\r\n\r\n  @plugs {:hello, []}\r\n  @plugs {:world, [good: :morning]}\r\n\r\n  MyPlugBuilder.__before_compile__(__ENV__)end\r\n```\r\n此时展开了MyPlugBuilder中`__before_compile__`宏，完成整个展开过程。\r\n\r\n### 复杂一下\r\n``` elixir\r\ndefmodule MyPlugBuilder do\r\n\r\n  defmacro __using__(_opts) do\r\n    quote do\r\n      import MyPlugBuilder, only: [plug: 1, plug: 2, aplug: 1]\r\n      Module.register_attribute(__MODULE__, :plugs, accumulate: :true)\r\n      IO.puts __MODULE__\r\n      IO.puts unquote(__MODULE__)\r\n      @before_compile MyPlugBuilder\r\n      unquote(defs())\r\n    end\r\n  end\r\n\r\n  # `plug` 本体\r\n  defmacro plug(plug, opts \\\\ []) do\r\n    quote do\r\n      IO.puts unquote(plug)\r\n      @plugs {unquote(plug), unquote(opts)}\r\n    end\r\n  end\r\n\r\n  defmacro aplug(plug) do\r\n      xplug(plug, [])\r\n  end\r\n\r\n  defp defs() do\r\n    IO.puts "aplug"\r\n    quote unquote: false do\r\n      IO.puts "eval"\r\n      var!(pplug, MyPlugBuilder) = fn resource ->\r\n        IO.puts resource\r\n      end\r\n    end\r\n  end\r\n\r\n  defp xplug(plug,opts \\\\ []) do\r\n    quote do\r\n      plug = unquote(plug)\r\n      var!(pplug, MyPlugBuilder).(plug)\r\n    end\r\n  end\r\n  \r\n  defmacro __before_compile__(env) do\r\n    plugs = Module.get_attribute(env.module, :plugs)\r\n    IO.puts "__before_compile__"\r\n    conn = compile(env)\r\n    quote do\r\n      def plugs, do: unquote(plugs)\r\n      def plug_builder_call(unquote(conn)), do: IO.puts conn\r\n    end\r\n  end\r\n\r\n  def compile(env) do\r\n    conn = quote do: conn\r\n    conn\r\n  end\r\n\r\nend\r\n``` \r\n\r\n#### 展开的差异\r\n``` elixir\r\ndefmodule MyModule do\r\n  # ----\r\n  # use MyPlugBuilder\r\n  # ---- ↓\r\n  require MyPlugBuilder\r\n  MyPlugBuilder.__using__([])\r\n  # ----\r\n\r\n  plug :hello\r\n  plug :world, good: :morning\r\nend\r\n```\r\n\r\n``` elixir\r\ndefmodule MyModule do\r\n  require MyPlugBuilder\r\n\r\n  # ----\r\n  # MyPlugBuilder.__using__([])\r\n  # ---- ↓\r\n  MyPlugBuilder.defs()\r\n  import MyPlugBuilder, only: [plug: 1, plug: 2, aplug: 1]\r\n  Module.register_attribute(__MODULE__, :plugs, accumulate: :true)\r\n  IO.puts __MODULE__\r\n  IO.puts "MyPlugBuilder"\r\n  @before_compile MyPlugBuilder\r\n  # ----\r\n\r\n  plug :hello\r\n  plug :world, good: :morning\r\nend\r\n```\r\n你可能已经注意到了MyPlugBuilder的defs()函数先于两个IO.puts执行了。\r\n\r\n## 总结\r\n\r\n可以在编译期间展开在执行阶段求值实参的宏，确实可以给我们带来很大的方便，但是也大大带来了危险性。\r\n宏乃屠龙之技，但是用的时候要慎之再慎。\r\n\r\n[Elixir 1.1.1](https://github.com/DavidAlphaFox/elixir) 代码分析(未完成)\r\n[mate.im](https://github.com/DavidAlphaFox/mate.im) Phoenix + Ng的一个网站(已死)\r\n\r\n	f	2019-09-05 15:22:04.721661
146	DNS 入门	DevOps	# 什么是DNS\r\nDNS全称Domain Name System，Domain Name被译为域名，中文名为域名系统，也称为域名解析系统；另外域名服务器Domain Name Server也简称为DNS。  \r\n\r\n域名系统是因特网的一项核心服务，它作为可以将域名和IP地址相互映射的一个分布式数据库，能够使人更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。DNS是具有树型结构的名字空间，核心功能是完成域名到IP地址的转换，使用TCP和UDP端口53。\r\n\r\n通俗地说，DNS帮助用户在互联网上寻找路径。在互联网上的每一个计算机都拥有一个唯一的地址，称作“IP地址”（即互联网协议地址）。由于IP地址（为一串数字）不方便记忆，DNS允许用户使用一串常见的字母（即“域名”）取代。DNS命名用于Internet等TCP/IP网络中，通过用户友好的名称查找计算机和服务。当用户在应用程序中输入DNS名称时，DNS服务可以将此名称解析为与之相关的其他信息，如IP地址。因为，你在上网时输入的网址，是通过域名解析系解析找到相对应的IP地址，这样才能上网。其实，域名的最终指向是IP。  \r\n\r\n虽然域名系统后便于人们记忆，但网络中的计算机之间只能互相认识IP地址，它们之间的转换工作称为域名解析，域名解析需要由专门的域名服务器（Domain Name Server）来完成，这里的DNS就是域名服务器。\r\n\r\n# DNS的简史\r\n60年末代，美国资助试验性广域计算机风，称为ARPAnet。70年代时，ARPAnet只是一个拥有几百台主机的小网络，仅需要一个HOSTS文件就可以容纳所需要主机信息，HOSTS提供的是主机名也IP地址的映射关系，也就是说可以用主机名进行网络信息的共享，而不需要记住IP地址。但是随着网络的扩在，HOSTS文件已经不能够快速完成解析任务了，这时DNS出现了。  \r\n\r\nDNS最早于1983年由保罗·莫卡派乔斯（Paul Mockapetris）发明；原始的技术规范在882号因特网标准草案（RFC 882）中发布。1987年发布的第1034和1035号草案修正了DNS技术规范，并废除了之前的第882和883号草案。在此之后对因特网标准草案的修改基本上没有涉及到DNS技术规范部分的改动。\r\n\r\n早期的域名必须以英文句号“.”结尾,当用户访问 www.ttalk.im 的HTTP服务时必须在址栏中输入：http://www.ttalk.im. ，这样DNS才能够进行域名解析。如今DNS服务器已经可以自动补上结尾的句号。\r\n\r\n当前，对于域名长度的限制是63个字符，包括www.和.com或者其他的扩展名。域名同时也仅限于ASCII字符的一个子集，这使得很多其他语言无法正确表示他们的名字和单词。基于Punycode码的IDNA系统，可以将Unicode字符串映射为有效的DNS字符集，这已经通过了验证并被一些注册机构作为一种变通的方法所采纳。\r\n\r\n# DNS的价值和问题\r\nDNS是一个分布式的数据库，它允许对整个数据库的各个部分进行本地控制，本地控制也是就所谓的授权，可以把数据库的一部分进行授权，减轻主DNS服务器的压力，就是按域结构进行授权。同时，一旦DNS配置成功，HOSTS文件可以为空。因为DNS的出现就是要代替HOSTS文件的。只需一条语句就可以127.0.0.1 localhost. 。\r\n\r\n### 价值\r\n- DNS解析是互联网绝大多数应用的实际寻址方式。\r\n- 域名技术的再发展、以及基于域名技术的多种应用，丰富了互联网应用和协议。\r\n- 域名是互联网上的身份标识，是不可重复的唯一标识资源。\r\n- 互联网的全球化使得域名成为标识一国主权的国家战略资源。\r\n\r\n### 问题\r\n但是DNS整个系统在设计之初，并没有太多考虑安全问题，因此，DNS整个体系存在一定的安全问题。主要有：\r\n- 针对域名系统的恶意攻击：DDOS攻击造成域名解析瘫痪。\r\n- 域名劫持：修改注册信息、劫持解析结果。\r\n- 根域名的归属和根域名主机安全问题\r\n	f	2019-09-05 15:22:04.827333
155	eJabberd 的消息路由	XMPP	## 什么是路由\r\n在网络工程上，定义路由（routing）是非常简单的，路由就是指分组从源到目的地时，决定端到端路径的网络范围的进程 。在eJabberd中，路由有这相似的定义，同样也是江西消息分组，从源送到目的地址。\r\n\r\n## ejabberd_c2s进程\r\nejabberd_c2s进程，是客户端在eJabberd服务进程中的代理（agent），全面负责一个客户端在服务进程中的所有的动作，包括认证，特性使用以及我们要说的路由。\r\n\r\n因为ejabberd_c2s进程作为客户端在服务进程中的代理，就要注意以下几个事项\r\n- 所有incoming，代表由服务端发给客户端的消息，所有outcoming，代表客户端发给服务端的消息\r\n- 只代表一个客户端，并且和客户端的链接状况紧密相连\r\n- 不负责网络消息的解码操作，只负责协议的动作操作，包括认证，特性协商和路由\r\n\r\n## ejabberd_router模块\r\nejabberd_router模块在启动的时候，会创建一个进程，但是该进程并不负责消息的路由，只负责路由的部分原信息管理和路由的高级抽象。\r\n\r\n### eJabberd中路由种类\r\n\r\n#### 普通路由\r\n这类路由，一般都是非常简单的消息，只需要经过简单的目的查找，即可将消息直接交付给目标进行处理。这种路由就像网络中路由一样可以存在多个层级，在eJabberd中是被做成分层处理的。\r\n\r\n#### 外部服务路由\r\n这类路由，是代表那些不在eJabberd服务进程内的服务，需要通过特定方式将消息转发给特定服务，这种外部服务是通过某种方式在当前的eJabberd进程中注册的。\r\n\r\n#### 全局外部服务路由\r\n这类路由，同样代表那些不在eJabberd服务进程内的服务，但是唯一区别的是，当前的eJabberd进程是无法直接访问的，需要通过eJabberd集群中特定eJabberd进程来完成访问。\r\n#### s2s路由\r\n这类路由，是eJabberd进行不同域和域之间互通的路由。只要双发都符合XMPP规范，并建立互相信任的链接后，就可以让A域下的用户和B域下的用户消息互通。\r\n\r\n### 路由抽象\r\nejabberd_router将路由过程抽象为一个按序列进行的流水线，按照预先设定好的数据，将一个消息按序列流过各个路由模块，并且在路由模块中将消息处理分成两个阶段，一个阶段是filter，一个阶段是route。简单的说就是先进行初步过滤，在路由前尽可能过滤掉不需要的数据包，减少路由压力。\r\n\r\n``` Erlang\r\nroute(From, To, Packet, []) ->\r\n    ?ERROR_MSG("error routing from=~ts to=~ts, packet=~ts, reason: no more routing modules",\r\n               [jid:to_binary(From), jid:to_binary(To),\r\n                exml:to_binary(Packet)]),\r\n    mongoose_metrics:update(global, routingErrors, 1),\r\n    ok;\r\nroute(OrigFrom, OrigTo, OrigPacket, [M|Tail]) ->\r\n    ?DEBUG("Using module ~p", [M]),\r\n    %% 先过滤数据\r\n    case (catch M:filter(OrigFrom, OrigTo, OrigPacket)) of\r\n        {'EXIT', Reason} ->\r\n            %% 过滤阶段出现异常，记录下来\r\n            %% 之后就不做过多的处理\r\n            ?DEBUG("Filtering error", []),\r\n            ?ERROR_MSG("error when filtering from=~ts to=~ts in module=~p, reason=~p, packet=~ts, stack_trace=~p",\r\n                       [jid:to_binary(OrigFrom), jid:to_binary(OrigTo),\r\n                        M, Reason, exml:to_binary(OrigPacket),\r\n                        erlang:get_stacktrace()]),\r\n            ok;\r\n        drop ->\r\n            %% 过滤后发现需要丢弃，就直接结束路由过程\r\n            ?DEBUG("filter dropped packet", []),\r\n            ok;\r\n        {OrigFrom, OrigTo, OrigPacketFiltered} ->\r\n            ?DEBUG("filter passed", []),\r\n            %% 任何一个匹配且路由成功的模块，都可以直接结束\r\n            case catch(M:route(OrigFrom, OrigTo, OrigPacketFiltered)) of\r\n                {'EXIT', Reason} ->\r\n                    ?ERROR_MSG("error when routing from=~ts to=~ts in module=~p, reason=~p, packet=~ts, stack_trace=~p",\r\n                               [jid:to_binary(OrigFrom), jid:to_binary(OrigTo),\r\n                                M, Reason, exml:to_binary(OrigPacketFiltered),\r\n                                erlang:get_stacktrace()]),\r\n                    ?DEBUG("routing error", []),\r\n                    ok;\r\n                done ->\r\n                    %% 在该模块已经成功路由，就不再向下个模块进行传递了\r\n                    ?DEBUG("routing done", []),\r\n                    ok;\r\n                {From, To, Packet} ->\r\n                    ?DEBUG("routing skipped", []),\r\n                    route(From, To, Packet, Tail)\r\n            end\r\n    end.\r\n```\r\neJabberd优先进行全局过滤，接着进行常规消息路由，再接着进行外部服务的消息路由，最后进行s2s路由。\r\n``` Erlang\r\n%% 默认的路由模块\r\ndefault_routing_modules() ->\r\n    [mongoose_router_global,%% 只使用filter_packet进行过滤，不进行任何路由操作\r\n     mongoose_router_localdomain, %% 只路由本host和subhosts的消息\r\n     mongoose_router_external_localnode, %% 本节点内外挂功能路由\r\n     mongoose_router_external, %% 所有节点外挂功能路由\r\n     ejabberd_s2s].\r\n```\r\n### 节点内路由\r\n节点内路由，会将消息路由给用户和节点内的IQ handler。节点内路由是由ejabberd_local进行负责的，ejabberd_local在eJabberd启动的时候，会建立一个进程，用来管理本地注册的IQ handler。ejabberd_local在启动的时候，不单单建立了进程而且还将模块注册成host节点内默认路由。\r\n\r\n当消息进行路由的时候，ejabberd_local会先查看JID的user部分是否是空的，非空的情况下交给ejabberd_sm处理，当是空的时候那么一定是服务，就交给IQ处理，剩下的消息一概都忽略。\r\n\r\n``` Erlang\r\ndo_route(From, To, Packet) ->\r\n    ?DEBUG("local route~n\\tfrom ~p~n\\tto ~p~n\\tpacket ~P~n",\r\n           [From, To, Packet, 8]),\r\n    if\r\n        %% user部分不为空\r\n        %% 说明是给用户的，或者特定服务的，所以需要让ejabberd_sm来处理这个路由信息\r\n        To#jid.luser /= <<>> ->\r\n            ejabberd_sm:route(From, To, Packet);\r\n        %% resource部分为空，user部分为空了\r\n        %% 如果是message或者presence的消息不进行任何处理\r\n        To#jid.lresource == <<>> ->\r\n            #xmlel{name = Name} = Packet,\r\n            case Name of\r\n                <<"iq">> ->\r\n                    %% 如果是IQ信息，就交给IQ handler来进行处理\r\n                    process_iq(From, To, Packet);\r\n                <<"message">> ->\r\n                    ok;\r\n                <<"presence">> ->\r\n                    ok;\r\n                _ ->\r\n                    ok\r\n            end;\r\n        true ->\r\n            #xmlel{attrs = Attrs} = Packet,\r\n            case xml:get_attr_s(<<"type">>, Attrs) of\r\n                <<"error">> -> ok;\r\n                <<"result">> -> ok;\r\n                _ ->\r\n                    ejabberd_hooks:run(local_send_to_resource_hook,\r\n                                       To#jid.lserver,\r\n                                       [From, To, Packet])\r\n            end\r\n        end.\r\n\r\n```\r\n\r\n### 用户间消息路由\r\n真正在做用户间消息路由的模块ejabberd_sm模块，该模块同样会创建一个进程，但是该进程同样不进行任何路由操作，只保存路由元信息。其中保存着每个客户端JID和ejabberd_c2s进程对应的关系，以及IQ和处理模块和进程对应的关系。\r\n\r\n其中最核心的部分是，通过对session表的查找，将消息路由给特定的ejabberd_c2s进程，让该进程将消息发送给客户端。当无法找到相应的进程，就会进行离线存储处理。当然，当JID的resource部分为空的时候，会尝试匹配群组消息和IQ消息，如果是IQ消息的时候，会去查找sm_iqtable来确定IQ处理模块或进程，从而完成处理。\r\n\r\n``` Erlang\r\n%% 进行普通路由\r\ndo_route(From, To, Packet) ->\r\n    ?DEBUG("session manager~n\\tfrom ~p~n\\tto ~p~n\\tpacket ~P~n",\r\n           [From, To, Packet, 8]),\r\n    #jid{ luser = LUser, lserver = LServer, lresource = LResource} = To,\r\n    #xmlel{name = Name, attrs = Attrs} = Packet,\r\n    %% 没有资源信息的路由里面包含IQ处理\r\n    case LResource of\r\n        <<>> ->\r\n            %% 特殊处理\r\n            do_route_no_resource(Name, xml:get_attr_s(<<"type">>, Attrs),\r\n                                 From, To, Packet);\r\n        _ ->\r\n            case ?SM_BACKEND:get_sessions(LUser, LServer, LResource) of\r\n                [] ->\r\n                    %% 此处进行离线处理\r\n                    do_route_offline(Name, xml:get_attr_s(<<"type">>, Attrs),\r\n                                     From, To, Packet);\r\n                Ss ->\r\n                    Session = lists:max(Ss),\r\n                    Pid = element(2, Session#session.sid),\r\n                    ?DEBUG("sending to process ~p~n", [Pid]),\r\n                    %% 向目标进程route消息\r\n                    Pid ! {route, From, To, Packet}\r\n            end\r\n    end.\r\n```\r\n### 谁来完成路由\r\n我们可以产出，eJabberd的路由是非常复杂的，如果只让一个进程来处理相关操作，会形成非常大的瓶颈。因此，eJabberd选择让发送者的ejabberd_c2s进程来进行路由操作，利用mnesia的高并发性和Erlang的变量不变特性，达到高效路由。\r\n\r\n### 后续\r\neJabberd的路由虽然是个非常简单的部分，但是在eJabberd中确实重中之重。它的设计不单单影响整个eJabberd的消息转发性能，同时影响着eJabberd的扩展性。为什么会影响扩展性，将在后续介绍s2s和外部服务[XEP-0114](https://xmpp.org/extensions/xep-0114.html)中详细说明。\r\n	f	2019-09-05 15:22:05.4723
157	Erlang 和 Elixir 的互操作	Erlang/Elixir	# Elixir调用Erlang的代码\r\n\r\nElixir调用Erlang的代码非常简单，就是将Erlang相应的模块前面加上“:”符号。然后用“.”代替Erlang的“:”符号。\r\n\r\n好了如下面的Erlang代码\r\n\r\n\r\n```erlang\r\nists:sort([3, 2, 1]).\r\n```\r\n\r\n在Elixir中直接可以写成\r\n```elixir\r\n:lists.sort([3, 2, 1])\r\n```\r\n\r\n非常简单方便\r\n\r\n\r\n\r\n# Erlang调用Elixir代码\r\n\r\n首先要在rebar.config中添加Elixir的依赖\r\n\r\n\r\n```erlang\r\ndeps, [{ elixir, "1.1.*",\r\n         {git, "git://github.com/elixir-lang/elixir",{tag,"v1.1.1"}}}]}.\r\n```\r\n\r\n接着要在rebar.config中添加lib支持\r\n\r\n```erlang\r\n{lib_dirs, [\r\n  "deps/elixir/lib"\r\n]}.\r\n```\r\n这样我们才能使用Elixir相关的类库。\r\n\r\n如果我们想在Rebar工程中混合使用Elixir和Erlang，那么就需要使用rebar的插件了。该插件地址为：https://github.com/yrashk/rebar_elixir_plugin\r\n\r\n同样，我们需要在rebar.config中进行下配置\r\n```erlang\r\n{deps, [{ rebar_elixir_plugin, ".*",\r\n         {git, "git://github.com/yrashk/rebar_elixir_plugin"}}]}.\r\n%% Let rebar know about the new plugins\r\n{plugins, [rebar_elixir_compiler, rebar_exunit] }.\r\n```\r\n用Rebar生成独立运行的环境\r\n\r\n为了能让我们生成独立运行的环境，我们还需要在realtool.config中添加\r\n\r\n```erlang\r\n{app, elixir, [{mod_cond, app},{incl_cond, include},{lib_dir,"../deps/elixir/lib/elixir"}]}\r\n```\r\n在rebar.config中添加\r\n\r\n```erlang\r\n{post_hooks, [{compile, "rm -rf deps/elixir/ebin"}]}.\r\n```\r\n这样做是为了让rebar在编译之后删除deps下Elixir没有生成beam的ebin，当我们使用incl_cond的时候，我们才不会发生多个地方存在elixir.app的冲突。	f	2019-09-05 15:22:05.58062
158	eJabberd 的服务发现	XMPP	## 什么是服务发现\r\n\r\n服务发现在微服务和容器部署的项目中会被经常提到，当我们需要远程的访问REST API或者Thrift API时，我们必须得知道服务的网络地址（IP地址和端口号）。传统的应用程序都是运行在固定的物理机器上，IP地址和端口号都是相对固定的，可以通过配置文件方式来实现不定期更新的IP地址和端口号，最常见的例子就是DNS。\r\n\r\n从这里我们可以总结出，服务发现是记录了（大规模）分布式系统中所有服务的信息，人们或者其它服务可以据此找到这些服务。\r\n\r\n## 服务发现应该具备哪些关键特性\r\n\r\n服务发现是支撑大规模 SOA 的核心服务，它必须是高可用的，提供注册、目录和查找三大关键特性，仅仅提供服务目录是不够的。服务元数据存储是服务发现的关键，因为复杂的服务提供了多种服务接口和端口，部署环境也比较复杂。一旦服务发现组件存储了大量元数据，它就必须提供强大的查询功能，包括服务健康和其它状态的查询。\r\n\r\n## eJabberd中的服务发现\r\neJabberd的作为实现XMPP协议的高性能，高可用服务器，自然而然会显现XMPP的服务器发现协议[XEP-0030](https://xmpp.org/extensions/xep-0030.html)。从XEP-0030中可以看出，XMPP将服务发现定义为一种目录逐层查找的IQ处理机制。用来发现服务器上更多的IQ功能。在XMPP中，服务发现被简称为disco，是一个被定义在http://jabber.org/protocol/disco 这个XML命名空间内的IQ处理器。\r\n\r\n###  发现实体上的服务\r\n一个实体可以提供多种服务和特性，为了得到这些信息，就需要去发现实体上的服务，所以XMPP做了下面这些设计。\r\n\r\n#### 要求\r\n为了完成服务发现，实体必须提供下面这些信息\r\n\r\n1. 实体的身份标识。在disco中，一个实体的身份细分成多个种类(服务器、客户端、网关、目录等等)及其种类中的特殊类型（IM服务器、电话或处理的客户端、MSN网关或AIM网关、用户目录或聊天室目录等等）。这些信息帮助请求实体确定最适合放置实体最服务组或服务“桶”，（例如，可能在GUI中用合适的图标把实体显示出来）。一个实体 可以有多个身份。当提供多个identity元素的时候，每个identity元素的 name 属性应该有相同的值。\r\n1.实体的特性和协议。这个信息帮助请求实体测定对目标实体可以做什么样的动作（注册、搜索、联合等等），实体支持什么样的协议，以及是否有感兴趣的特性类型（例如，为了特性协商的目的）。\r\n\r\n#### 查询和响应\r\n\r\ndisco为了让请求实体，发现目标实体，做了这样的规定，必须向特定实体发送一个IQ，其中query的XML命名空间为http://jabber.org/protocol/disco 。\r\n\r\n``` XML\r\n<iq type='get'\r\n    from='romeo@montague.net/orchard'\r\n    to='plays.shakespeare.lit'\r\n    id='info1'>\r\n  <query xmlns='http://jabber.org/protocol/disco#info'/>\r\n</iq>\r\n```\r\n收到该IQ 请求之后，disco必须做出下面三种回应中的一种\r\n\r\n查询成功，返回实体锁能提供的服务，以及特性\r\n``` XML\r\n<iq type='result'\r\n    from='plays.shakespeare.lit'\r\n    to='romeo@montague.net/orchard'\r\n    id='info1'>\r\n  <query xmlns='http://jabber.org/protocol/disco#info'>\r\n    <identity\r\n        category='conference'\r\n        type='text'\r\n        name='Play-Specific Chatrooms'/>\r\n    <identity\r\n        category='directory'\r\n        type='chatroom'\r\n        name='Play-Specific Chatrooms'/>\r\n    <feature var='http://jabber.org/protocol/disco#info'/>\r\n    <feature var='http://jabber.org/protocol/disco#items'/>\r\n    <feature var='http://jabber.org/protocol/muc'/>\r\n    <feature var='jabber:iq:register'/>\r\n    <feature var='jabber:iq:search'/>\r\n    <feature var='jabber:iq:time'/>\r\n    <feature var='jabber:iq:version'/>\r\n  </query>\r\n</iq>\r\n```\r\n发现异常，实体可能不存在的时候，会返回这些信息\r\n``` XML\r\n<iq type='error'\r\n    from='plays.shakespeare.lit'\r\n    to='romeo@montague.net/orchard'\r\n    id='info1'>\r\n  <query xmlns='http://jabber.org/protocol/disco#info'/>\r\n  <error type='cancel'>\r\n    <item-not-found xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\r\n  </error>\r\n</iq>\r\n```\r\n实体不能正常服务\r\n``` XML\r\n<iq type='error'\r\n    from='plays.shakespeare.lit'\r\n    to='romeo@montague.net/orchard'\r\n    id='info1'>\r\n  <query xmlns='http://jabber.org/protocol/disco#info'/>\r\n  <error code='503' type='cancel'>\r\n    <service-unavailable xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\r\n  </error>\r\n</iq>\r\n```\r\n### 发现所有实体\r\n有时候，客户端需要知道，服务器都支持哪些扩展，就需要查询下，现在有多少可发现实体在服务器上。\r\n\r\n#### 基本要求\r\n请求实体为了发现一个服务器上的所有实体， 必须向目标实体发送类型为get的IQ请求，其中包含一个空的<query/>元素，其中query的XML命名空间\r\n为 http://jabber.org/protocol/disco#items\r\n\r\n#### 查询和响应\r\n查询非常简单，唯一的区别就是查询对象直接指向host，查询的命名空间变为 http://jabber.org/protocol/disco#items\r\n\r\n``` XML\r\n<iq type='get'\r\n    from='romeo@montague.net/orchard'\r\n    to='shakespeare.lit'\r\n    id='items1'>\r\n  <query xmlns='http://jabber.org/protocol/disco#items'/>\r\n</iq>\r\n``` \r\n服务端收到请求，就必须做出下面的回应\r\n``` XML\r\n<iq type='result'\r\n    from='shakespeare.lit'\r\n    to='romeo@montague.net/orchard'\r\n    id='items1'>\r\n  <query xmlns='http://jabber.org/protocol/disco#items'>\r\n    <item jid='people.shakespeare.lit'\r\n          name='Directory of Characters'/>\r\n    <item jid='plays.shakespeare.lit'\r\n          name='Play-Specific Chatrooms'/>\r\n    <item jid='mim.shakespeare.lit'\r\n          name='Gateway to Marlowe IM'/>\r\n    <item jid='words.shakespeare.lit'\r\n          name='Shakespearean Lexicon'/>\r\n    <item jid='globe.shakespeare.lit'\r\n          name='Calendar of Performances'/>\r\n    <item jid='headlines.shakespeare.lit'\r\n          name='Latest Shakespearean News'/>\r\n    <item jid='catalog.shakespeare.lit'\r\n          name='Buy Shakespeare Stuff!'/>\r\n    <item jid='en2fr.shakespeare.lit'\r\n          name='French Translation Service'/>\r\n  </query>\r\n</iq>\r\n``` \r\n### eJabberd是如何实现的\r\n\r\neJabberd将[XEP-0030](https://xmpp.org/extensions/xep-0030.html)，作为一个常规的扩展，在mod_disco中进行了实现。\r\n\r\n#### mod_disco模块\r\n\r\nmod_disco会在启动的时候建立一系列的命名，公开且键值有序的ETS，用来保存IQ的特性。同时注册host上最基本的三个IQ特性，iq，presence和presence-invisible。并同时在ejabberd_local和ejabberd_sm中注册IQ处理器，为什么这么做请参考[ eJabberd 的消息路由](https://www.ttalk.im/topics/47)，因为在eJabberd_local中主要处理JID中没有user部分的请求，而eJabberd_sm主要负责JID带有User部分的。\r\n\r\n每当我们在ejabberd_local上注册IQ处理器的时候，会自动注册到mod_disco上\r\n``` Erlang\r\nhandle_info({register_iq_handler, Host, XMLNS, Module, Function}, State) ->\r\n    ets:insert(?IQTABLE, {{XMLNS, Host}, Module, Function}),\r\n    catch mod_disco:register_feature(Host, XMLNS),\r\n    {noreply, State};\r\nhandle_info({register_iq_handler, Host, XMLNS, Module, Function, Opts}, State) ->\r\n    ets:insert(?IQTABLE, {{XMLNS, Host}, Module, Function, Opts}),\r\n    catch mod_disco:register_feature(Host, XMLNS),\r\n    {noreply, State};\r\n```\r\n当我们收到info和items查询的时候，会自动去调用mod_disco的process_local_iq_*和process_sm_iq_*这几个函数。\r\n\r\n## 总结\r\nXMPP的服务发现机制disco，主要是通过目录查询的方式来完成的。并且这种发现机制是针对IQ处理器而设置的，换句话说，在扩展eJabberd的时候仍然需要编写Erlang代码并编译到eJabberd的服务器中。虽然有很多不便利之处，但是却已经让eJabberd服务器（XMPP协议）具有极强的扩展能力。甚至可以使用eJabberd做一个购物APP的后端，这已经超出了一个通讯服务器的能力范围之外，因此拥有了disco协议之后，eJabberd就可以说是一个超级服务器了。后面将会继续介绍如何使用外部服务来扩展eJabberd。\r\n\r\n在这里主要介绍了如何用disco发现服务器上的资源，作为对等实体disco是可以发现客户端上的资源，具体请看[XEP-0030](https://xmpp.org/extensions/xep-0030.html)规范。\r\n	f	2019-09-05 15:22:05.581471
159	深入浅出 Mnesia－schema 创建 (1)	Erlang/Elixir	## Mnesia是什么\r\n\r\nMnesia是一个分布式数据库管理系统（DBMS），适合于电信和其它需要持续运行和具备软实时特性的Erlang应用，是构建电信应用的控制系统平台开放式电信平台(OTP)的一部分。\r\n从这里可以看出Mnesia是Erlang/OTP平台内置的数据库。开发该数据库的原因是电信应用苛刻的容错和高可靠性需求，这些需求如下：\r\n\r\n1. 实时快速的键/值检索\r\n1. 非实时的复杂查询主要在运营和维护时进行\r\n1. 分布式的应用，从而数据也必须分布\r\n1. 高容错性\r\n1. 可动态重新配置\r\n1. 存储复杂的对象数据\r\n\r\n## 如何使用Mnesia\r\nMnesia作为一个数据库，使用的时候就有一定的要求，相对于其它数据库而言，这些需求是非常简单的。\r\n\r\n使用Mnesia需要满足以下需求：\r\n1. 操作系统可以运行Erlang/OTP平台\r\n2. 已经创建Mnesia的schema表\r\n\r\n满足这两点Mnesia就可以使用了。本文将介绍Mnesia是如何创建schema表的\r\n\r\n## Mnesia的cstruct结构\r\n``` Erlang\r\n-record(cstruct, {name,                    % Atom 表名字\r\n\t\t  type = set,                      % set | bag\r\n\t\t  ram_copies = [],                 % [Node]\r\n\t\t  disc_copies = [],                % [Node]\r\n\t\t  disc_only_copies = [],           % [Node]\r\n\t\t  load_order = 0,                  % Integer\r\n\t\t  access_mode = read_write,        % read_write | read_only\r\n\t\t  majority = false,                % true | false\r\n\t\t  index = [],                      % [Integer]\r\n\t\t  snmp = [],                       % Snmp Ustruct\r\n\t\t  local_content = false,           % true | false\r\n\t\t  record_name = {bad_record_name}, % Atom (Default = Name) 表中存放的record的名字\r\n\t\t  attributes = [key, val],         % [Atom] record中的属性名字\r\n\t\t  user_properties = [],            % [Record]\r\n\t\t  frag_properties = [],            % [{Key, Val]\r\n\t\t  storage_properties = [],         % [{Key, Val]\r\n                  cookie = ?unique_cookie,         % Term\r\n                  version = {{2, 0}, []}}).        % {{Integer, Integer}, [Node]}\r\n```\r\nErlang的cstruct非常简明扼要的定义了Mnesia的一张表的属性。对Mnesia来讲，一张表最基本需要包含下面的信息\r\n1. name，表名字\r\n1. type，存储模式\r\n1. access_mode，访问权限\r\n1. record_name，存储字段的record名称\r\n1. attributes，字段名称\r\n\r\n剩下的字段，更多是和集群，容错以及分片相关的。因为有分片技术的存在，就不要再说Mnesia存储上限是4G啥的了。\r\n\r\n## schema创建\r\n\r\n### 确认无schema阶段\r\n在mnesia_bup的create_schema中会使用mnesia_schema:ensure_no_schema来确认单节点或集群的所有节点上都没有schema相关的数据。\r\n``` Erlang\r\n%尝试读取远程的schema\r\nensure_no_schema([H|T]) when is_atom(H) ->\r\n    case rpc:call(H, ?MODULE, remote_read_schema, []) of\r\n        {badrpc, Reason} ->\r\n            %% 返回建表失败\r\n            {H, {"All nodes not running", H, Reason}};\r\n        {ok,Source, _} when Source /= default ->\r\n            %% 返回的source是非default的时候，就代表已经存在了schema表\r\n            {H, {already_exists, H}};\r\n        _ ->\r\n            ensure_no_schema(T)\r\n    end;\r\nensure_no_schema([H|_]) ->\r\n    {error,{badarg, H}};\r\nensure_no_schema([]) ->\r\n    ok.\r\n``` \r\nensure_no_schema是通过Erlang/OTP平台的rpc模块来尝试读取所有节点是否存在，如果存在了会告诉发起创建请求的进程already_exists，如果某个节点无法链接，就会报错。如果在这阶段出现异常，会立刻终止创建。\r\n\r\n### 构建临时备份阶段\r\nmnesia_bup会在mnesia数据目录下创建一个节点名＋时间戳的临时文件，类似 nonode@nohost1513217595933336.TMP 这种形式。之后会通过make_initial_backup来从0构建一个backup文件，用来创建Mnesia的schema。\r\n``` Erlang\r\nmake_initial_backup(Ns, Opaque, Mod) ->\r\n    %%获取最开始的元数据表\r\n    %%元数据是cstruct的[{key,value}]形式\r\n    Orig = mnesia_schema:get_initial_schema(disc_copies, Ns),\r\n    %% 删除掉storage_properties和majority这两个字段\r\n    Modded = proplists:delete(storage_properties, proplists:delete(majority, Orig)),\r\n    %% 向schema表中写入表名和cstruct\r\n    Schema = [{schema, schema, Modded}],\r\n    O2 = do_apply(Mod, open_write, [Opaque], Opaque),\r\n    %写入日志头\r\n    %% 包括日志版本，日志类型，mnesia版本，节点名称，生成时间\r\n    %% 这里日志版本1.2  类型 backup_log\r\n    O3 = do_apply(Mod, write, [O2, [mnesia_log:backup_log_header()]], O2),\r\n    %写入schema数据\r\n    O4 = do_apply(Mod, write, [O3, Schema], O3),\r\n    %%生成Opaque所代表的文件\r\n    O5 = do_apply(Mod, commit_write, [O4], O4),\r\n    {ok, O5}.\r\n```\r\n先通过mnesia_schema:get_initial_schema构建出一个schema的cstruct结构，然后通过mnesia_backup的日志模式，`[{schema, schema, Modded}]`写入的日志文件中。在写入真实数据前，会先写入一个`mnesia_log:backup_log_header()`的日志头，用来说明是什么日志和日志的版本。\r\n\r\n### 安装备份阶段\r\nmnesia_bup会使用do_install_fallback来将上一个阶段构建出来的临时备份安装到单节点或集群上。\r\n安装过程可以明确为以下几步：\r\n1. 初始化安装进程\r\n1. 初始化安装状态\r\n1. 在集群个节点上创建fallback_receiver\r\n1. 从上阶段临时文件中读取数据，并同步到集群各个节点上\r\n\r\n``` Erlang\r\ninstall_fallback_master(ClientPid, FA) ->\r\n    %% 捕获退出异常，关联进程崩溃，但是并不真正捕获\r\n    %% 而是防止崩溃后引起当前进程退出，打断元数据创建\r\n    process_flag(trap_exit, true),\r\n    %% 设置状态\r\n    State = {start, FA},\r\n    %% 拿出日志文件\r\n    Opaque = FA#fallback_args.opaque,\r\n    Mod = FA#fallback_args.module,\r\n    Res = (catch iterate(Mod, fun restore_recs/4, Opaque, State)),\r\n    unlink(ClientPid),\r\n    ClientPid ! {self(), Res},\r\n    exit(shutdown).\r\n```\r\n安装备份文件的时候，会创建一个进程来进行备份文件安装。该进程为了防止请求进程打断安装过程，会进行退出异常捕获。\r\n\r\n``` Erlang\r\n-spec fallback_receiver(pid(), fallback_args()) -> no_return().\r\n%Master,在此处表示，整个mnesia集群在create_schema的时候的发起者\r\nfallback_receiver(Master, FA) ->\r\n    process_flag(trap_exit, true),\r\n%将自己注册到本地名字库，防止创建出另一个fallback_receiver进程\r\n    case catch register(mnesia_fallback, self()) of\r\n        {'EXIT', _} ->\r\n            Reason = {already_exists, node()},\r\n            local_fallback_error(Master, Reason);\r\n        true ->\r\n            FA2 = check_fallback_dir(Master, FA),\r\n            Bup = FA2#fallback_args.fallback_bup,\r\n            %检查是否有backup\r\n            case mnesia_lib:exists(Bup) of\r\n                true ->\r\n                    %如果有则报错\r\n                    Reason2 = {already_exists, node()},\r\n                    local_fallback_error(Master, Reason2);\r\n                false ->\r\n                    %如果没有，创建新的backup的临时文件\r\n                    Mod = mnesia_backup,\r\n                    %% 删除FALLBACK.TMP文件\r\n                    Tmp = FA2#fallback_args.fallback_tmp,\r\n                    R = #restore{mode = replace,\r\n                                 bup_module = Mod,\r\n                                 bup_data = Tmp},\r\n                    file:delete(Tmp),\r\n                    %开始接收fallback信息\r\n                    case catch fallback_receiver_loop(Master, R, FA2, schema) of\r\n                        {error, Reason} ->\r\n                            local_fallback_error(Master, Reason);\r\n                        Other ->\r\n                            exit(Other)\r\n                    end\r\n            end\r\n    end.\r\n```\r\nfallback_receiver进程会在集群的每个节点上创建一个，其中的Master就是上面所说的install_fallback_master这个函数所在的进程。fallback_receiver只是做一些基本的防止重入和错误检查，真正的业务是在fallback_receiver_loop函数中处理。\r\n\r\n``` Erlang\r\nfallback_receiver_loop(Master, R, FA, State) ->\r\n    receive\r\n        {Master, {start, Header, Schema}} when State =:= schema ->\r\n            Dir = FA#fallback_args.mnesia_dir,\r\n            throw_bad_res(ok, mnesia_schema:opt_create_dir(true, Dir)),\r\n            %% 创建FALLBACK.TMP文件\r\n            R2 = safe_apply(R, open_write, [R#restore.bup_data]),\r\n            R3 = safe_apply(R2, write, [R2#restore.bup_data, [Header]]),\r\n            BupSchema = [schema2bup(S) || S <- Schema],\r\n            R4 = safe_apply(R3, write, [R3#restore.bup_data, BupSchema]),\r\n            Master ! {self(), ok},\r\n            %% schema的日志已经写入文件了\r\n            %% 状态切换到接收records\r\n            fallback_receiver_loop(Master, R4, FA, records);\r\n\r\n        {Master, {records, Recs}} when State =:= records ->\r\n            R2 = safe_apply(R, write, [R#restore.bup_data, Recs]),\r\n            Master ! {self(), ok},\r\n            fallback_receiver_loop(Master, R2, FA, records);\r\n        %收到swap，进行commit，并将临时文件重命名为backup文件\r\n        {Master, swap} when State =/= schema ->\r\n            ?eval_debug_fun({?MODULE, fallback_receiver_loop, pre_swap}, []),\r\n            safe_apply(R, commit_write, [R#restore.bup_data]),\r\n            Bup = FA#fallback_args.fallback_bup,\r\n            Tmp = FA#fallback_args.fallback_tmp,\r\n            %% 立刻重命名文件，将FALLBACK.TMP重命名为FALLBACK.BUP\r\n            throw_bad_res(ok, file:rename(Tmp, Bup)),\r\n            catch mnesia_lib:set(active_fallback, true),\r\n            ?eval_debug_fun({?MODULE, fallback_receiver_loop, post_swap}, []),\r\n            Master ! {self(), ok},\r\n            fallback_receiver_loop(Master, R, FA, stop);\r\n\r\n        {Master, stop} when State =:= stop ->\r\n            stopped;\r\n\r\n        Msg ->\r\n            safe_apply(R, abort_write, [R#restore.bup_data]),\r\n            Tmp = FA#fallback_args.fallback_tmp,\r\n            file:delete(Tmp),\r\n            throw({error, "Unexpected msg fallback_receiver_loop", Msg})\r\n    end.\r\n```\r\nfallback_receiver_loop循环State的初始值为{start,FA}，接着不断从发起者出接受schema数据和record数据，并写入FALLBACK.TMP中，当发起者传送完所有数据会要求fallback_receiver进程将FALLBACK.TMP文件重命名为FALLBACK.BUP。\r\n\r\n## 总结\r\n至此，schema创建的第一个阶段已经结束，但是发现mnesia数据目录下并没有生成schema.DAT文件，在后续的文章中将会介绍如何生成schema.DAT文件\r\n	f	2019-09-05 15:22:05.687981
160	深入浅出 Mnesia－schema 创建 (2)	Erlang/Elixir	##  FALLBACK.BUP生成schema.DAT时机\r\n前面的文章提到了[如何生成FALLBACK.BUP](https://www.ttalk.im/topics/52)，但没有提到FALLBACK.BUP是怎样生成schema.DAT文件的。想要知道FALLBACK.BUP是如何生成schema.DAT，就需要去观察Mnesia的启动流程和监控树。\r\n\r\n通过对代码的分析，可以非常清晰的看到，Mnesia的主要进程都被mnesia_kernel_sup这个监控者进程下\r\n``` Erlang\r\ninit([]) ->\r\n    ProcLib = [mnesia_monitor, proc_lib],\r\n    Flags = {one_for_all, 0, timer:hours(24)}, % Trust the top supervisor\r\n    %% 最先启动的是mnesia_monitor\r\n    %% mnesia_monitor持有mnesia_gvar和mnesia_stats两张ets表\r\n    %% mnesia的全局变量全都保存在此处\r\n    Workers = [worker_spec(mnesia_monitor, timer:seconds(3), [gen_server]),\r\n        %% mnesia_subscr 创建订阅管理进程\r\n        %% 自动将mnesia_event加入到系统订阅表中\r\n\t       worker_spec(mnesia_subscr, timer:seconds(3), [gen_server]),\r\n        %% mnesia的锁管理进程\r\n\t       worker_spec(mnesia_locker, timer:seconds(3), ProcLib),\r\n         %% mnesia恢复进程\r\n\t       worker_spec(mnesia_recover, timer:minutes(3), [gen_server]),\r\n         %% mnesia事务进程\r\n\t       worker_spec(mnesia_tm, timer:seconds(30), ProcLib),\r\n         %% 检察点监控者进程\r\n\t       supervisor_spec(mnesia_checkpoint_sup),\r\n         %% snmp监控者进程\r\n\t       supervisor_spec(mnesia_snmp_sup),\r\n         %% mnesia主控进程\r\n\t       worker_spec(mnesia_controller, timer:seconds(3), [gen_server]),\r\n         %% mnesia数据加载进程\r\n\t       worker_spec(mnesia_late_loader, timer:seconds(3), ProcLib)\r\n\t      ],\r\n    {ok, {Flags, Workers}}.\r\n\r\n```\r\n通过逐个进程的检察，在mnesia_tm进程初始化的时候，会通过mnesia_bup:tm_fallback_start函数来使用FALLBACK.BUP进行数据恢复，在此过程中就会生成schema.DAT。\r\n\r\n## 恢复流程\r\n\r\n### tm_fallback_start函数\r\n在mnesia_bup:tm_fallback_start函数中，整个操作过程都是锁住schema表进行操作的，在这个过程中，本节点上所有的其它schema操作都会进行等待。同时，这个函数的整体操作都是在mnesia_tm进程内进行的。\r\n``` Erlang\r\n%执行回滚操作\r\ndo_fallback_start(true, false) ->\r\n    verbose("Starting from fallback...~n", []),\r\n    %拿到备份文件\r\n    BupFile = fallback_bup(),\r\n    Mod = mnesia_backup,\r\n    %创建一个ets，用来保存本地表\r\n    LocalTabs = ?ets_new_table(mnesia_local_tables, [set, public, {keypos, 2}]),\r\n    case catch iterate(Mod, fun restore_tables/4, BupFile, {start, LocalTabs}) of\r\n        {ok, _Res} ->\r\n            %%  让dets关闭掉schema\r\n            catch dets:close(schema),\r\n            %% 设置临时的文件为schema.TMP\r\n            TmpSchema = mnesia_lib:tab2tmp(schema),\r\n            %% 设置数据文件为schema.DAT\r\n            DatSchema = mnesia_lib:tab2dat(schema),\r\n            %% 得到所有本地表\r\n\t          AllLT  = ?ets_match_object(LocalTabs, '_'),\r\n            %关闭ets\r\n\t          ?ets_delete_table(LocalTabs),\r\n            %% schema.TMP重命名为schema.DAT\r\n            case file:rename(TmpSchema, DatSchema) of\r\n                ok ->\r\n                    %% 除了schema表外，全部进行swap操作\r\n\t\t                [(LT#local_tab.swap)(LT#local_tab.name, LT) ||\r\n\t\t\t                 LT <- AllLT, LT#local_tab.name =/= schema],\r\n                    file:delete(BupFile),\r\n                    ok;\r\n                {error, Reason} ->\r\n                    file:delete(TmpSchema),\r\n                    {error, {"Cannot start from fallback. Rename error.", Reason}}\r\n            end;\r\n        {error, Reason} ->\r\n            {error, {"Cannot start from fallback", Reason}};\r\n        {'EXIT', Reason} ->\r\n            {error, {"Cannot start from fallback", Reason}}\r\n    end.\r\n```\r\ndo_fallback_start函数会进行数据恢复的准备工作，它进行了下面这些工作\r\n- 建立mnesia_local_tables的ets表，用来保存restore_tables函数在恢复过程中，恢复出本节点内的表的信息\r\n- 生成schema.DAT文件\r\n- 生成本节点内所有表的.DAT文件，.DCL文件和.DCD文件\r\n\r\n### restore_tables函数\r\nrestore_tables函数依旧是依赖mnesia_bup的通用函数iterate，将FALLBACK.BUP文件中的schema数据和表项目数据读取出来，并逐条遍历。\r\n\r\nrestore_tables函数会有几个状态，这几个状态分别是\r\n- {start, LocalTabs}，从FALLBACK.BUP中读取schema信息，根据表信息构建local_tab这个record，并保存到mnesia_local_tables中，为了可以在后面的恢复操作中使用\r\n- {new, LocalTabs} ，开始各表的数据恢复，会对FALLBACK中的数据项的record名和mnesia_local_tables的table名称进行比对，从而决定是恢复数据还是忽略\r\n- {not_local, LocalTabs, Tab}，如果在mnesia_local_tables查找不到对应的表名称的时候，就会进入此状态，这个过程中读取的数据会全部忽略掉\r\n- {local, LocalTabs, LT}，在mnesia_local_tables中查找到对应表明，进入此状态，进行数据恢复\r\n\r\n### init_dat_files函数\r\ninit_dat_files是restore_tables在构建mnesia_local_tables中项目的重要函数。\r\n\r\n它的主要工作有：\r\n- 根据schema提供的信息生成local_tab的record，包括schema表自身的信息\r\n- 创建除了schema表外所有的表的数据文件\r\n\r\n在仔细观察这个函数会发现，针对存储类型为disc_only_copies的表会建立一个dets，而对ram_copies和disc_copies类型存储的表只会建立.DCL日志存储和.DCD存储。存储方式的不同直接影响到了Mnesia如何读取数据和管理数据，在后面的文章将逐步分析相关内容。\r\n\r\n## 总结\r\n从整个过程中，可以看到Mnesia创建schema的过程后半段不仅仅可以创建一个schema.DAT文件，而且能创建包含数据的表。同时可以看出，Mnesia的Schema.DAT就是一个dets文件，完全可以简单的创建出来，但是这个过程确大费周章。当然这样做是有很大的原因的，这就需要考察Mnesia的备份机制和远程安装数据的机制了，在分析完Mnesia的启动和读写过程后，将会逐步对相关机制展开分析。\r\n\r\n	f	2019-09-05 15:22:05.795095
161	什么是 Erlang	Erlang/Elixir	## 什么是Erlang\r\n\r\nErlang（['ə:læŋ]）是一种通用的面向并发的编程语言，其创立者是Joe Armstrong，在1987年由瑞典电信设备制造商爱立信于主持开发。Erlang的开发目的是创造一种可以应对大规模并发活动的编程语言和运行环境，从而简化交换机的开发工作，提高电话交换机的稳定性和可扩展性。\r\n\r\nErlang是一个结构化，动态类型编程语言，内建并行计算支持，非常适合于构建分布式，实时软并行计算系统。使用Erlang编写出的应用运行时通常由成千上万个轻量级进程组成，并通过消息传递相互通讯。Erlang使用用户态抢占式协作线程来完成Erlang进程的调度，这比起C程序的线程切换要高效得多得多了。\r\n\r\n## Erlang的特点\r\n\r\n- 并发性：Erlang支持超大量级的并发进程，并且不需要操作系统具有并发机制。\r\n- 分布式： 一个分布式Erlang系统是多个Erlang节点组成的网络。\r\n- 健壮性：Erlang具有多种基本的错误检测能力，它们能够用于构建容错系统。\r\n- 软实时性： Erlang支持可编程的“软”实时系统，使用了用户态抢占式协作线程，同时使用了递增式垃圾收集技术。\r\n- 热代码升级：Erlang允许程序代码在运行系统中被修改。旧代码能被逐步淘汰而后被新代码替换。在此过渡期间，新旧代码是共存的。\r\n- 递增式代码装载：用户能够控制代码如何被装载的细节。\r\n- 函数式编程：尾递归优化，变量不可变，可预知的函数输出，匿名函数，闭包等。\r\n- 动态类型：无需声明变量类型，Erlang会根据情况自动确定变量类型。\r\n\r\n\r\n\r\n## 什么是OTP\r\n\r\nOTP是Open Telecom Platform的缩写，字面上直接的意思就是开放电信平台，这刚接触Erlang/OTP的人感到这玩意好像和一般服务器开发没什么关系。但是OTP是基于Erlang语言的一个非常强大，且非常通用的平台。\r\n\r\nOTP当中提供了大量的工具模块来帮助我们完成日常开发工作，同时该平台抽象了大量的行为模式，例如常见的状态机，通用服务器，进程监控以及内置的Mnesia数据库等。这些库不单单加快了我们的开发工作，同时也提高了整个系统的稳定性和可扩展性。\r\n\r\n	f	2019-09-05 15:22:05.902215
162	从 Erts 中学的 C 技巧	Erlang/Elixir	## 起因\r\n因为对Erlang的OTP 17.0做了一段时间的代码分析，并且近期看到了大神写的书[The Erlang Runtime System](https://happi.github.io/theBeamBook/)。发现了Erts中的erl_emu.c的process_main有个C语言写法自己从没用过，就查阅了相关资料。\r\n\r\n## 跳转标签作为值\r\n\r\n[原文](http://gcc.gnu.org/onlinedocs/gcc/Labels-as-Values.html)在这个地方。\r\n\r\n简单说就是在函数内定义的标签，可以使用操作符‘&&’来进行取值，值的类型是void*，这个值是一个定值，是不可以改变的。然后可以使用goto语句进行跳转。代码如下\r\n\r\n``` C\r\nvoid *ptr;\r\n/* … */\r\nptr = &&foo;\r\ngoto *ptr;\r\n\r\nstatic void *array[] = { &&foo, &&bar, &&hack };\r\ngoto *array[i];\r\n```\r\n在Erlang中，这种模式被用来完成Erlang的Beam指令流转，做了一个简单的模拟代码\r\n``` C\r\n#include<string.h>      \r\n#include<stdlib.h>       \r\n#include<stdio.h>                                                                                                      \r\ntypedef unsigned long Uint;  \r\ntypedef unsigned long  BeamInstr;   \r\ntypedef unsigned long  UWord;                                                                                          \r\n                                                                                                                       \r\n#define OpCase(OpCode)    lb_##OpCode \r\n#define Goto(Rel) goto *((void *)Rel)   \r\n#define OpCode(OpCode)  (&&lb_##OpCode)                                                                             \r\nint main(){                                                \r\n     BeamInstr* I;                                                                         \r\n     BeamInstr* next; \r\n     BeamInstr beam_apply[2];   \r\n     \r\n     beam_apply[0]             = (BeamInstr) OpCode(i_apply);   \r\n     beam_apply[1]             = (BeamInstr) OpCode(normal_exit);   \r\n     \r\n     printf("beam_apply %p\\r\\n",beam_apply);    \r\n     printf("beam_apply[0] %p\\r\\n",beam_apply[0]);  \r\n     printf("beam_apply[1] %p\\r\\n",beam_apply[1]);                                                                     \r\n     I = (BeamInstr *) beam_apply;  \r\n     next = (BeamInstr *) *I;   \r\n     printf("next: %p\\r\\n",next);   \r\n     Goto(next);\r\n     OpCase(i_apply):{        \r\n          printf("i_apply %p %p \\r\\n",I,(*I)); \r\n          I = I + 1;                          \r\n          Goto(*I);                                                                           \r\n     }\r\n     OpCase(normal_exit):{   \r\n          printf("normal_exit %p %p \\r\\n",I,(*I));  \r\n          return 0;     \r\n     }         \r\n     return 1;          \r\n}\r\n\r\n```\r\nbeam_apply这个数组中存放的是被转化成整形数值的地址。赋值给next的时候，next类型是指针，并且指向相应lb地址。\r\n``` C\r\nnext = (BeamInstr *) *I;\r\n```\r\ngcc会吧switch编译成jmp语句，为什么还要使用这种费劲的方式而不使用switch呢？这是因为switch在jmp前需要进行一次判断，而使用这种JUMP TABLE的模式是直接jmp到后面的地址。\r\n\r\n\r\n	f	2019-09-05 15:22:05.903473
163	Erlang 入门-模块和进程	Erlang/Elixir	## 什么是模块\r\n在前面的教程中，编写的代码都是在Erlang的shell中进行的。而交互式shell也被认为是绝大部分动态语言的特性之一。但是，任何一个项目不可能都是靠在shell中输入代码完成的，那么代码必须保存在某处。保存的代码就是模块，模块就是一个包含了大量函数的文件，因为模块是文件，就一定要有一个名字。\r\n\r\n### 如何编写一个模块\r\n编写模块非常简单，只要打开任意一款文本编辑器就可以了（推荐使用VScode，当然如果你喜欢命令行我十分乐意的推荐你使用Emacs），然后将我们前面教程中的函数放入其中，但是这并不能形成一个模块。\r\n\r\nErlang定义一个模块必须满足下面两点\r\n1. 声明属性，这些属性描述模块自身的特质，例如模块的名字\r\n1. 声明函数。\r\n\r\n声明函数已经完成了，那么如何声明属性呢？Erlang的模块一般会定义模块名和导出函数，定义方法如下\r\n``` Erlang\r\n-module(Name). %% 声明模块名，模块名必须是原子\r\n-export([Function1/Arity, Function2/Arity, ..., FunctionN/Arity]). %% 声明函数导出\r\n```\r\n下面就用就用[Erlang 入门-命名函数](https://www.ttalk.im/topics/7)中的greet函数编写一个msg模块：\r\n``` Erlang\r\n-module(msg).\r\n-export([greet/2]).\r\n\r\ngreet(male, Name) ->\r\n  io:format("Hello, Mr. ~s!~n", [Name]);\r\ngreet(female, Name) ->\r\n  io:format("Hello, Mrs. ~s!~n", [Name]);\r\ngreet(_, Name) ->\r\n  io:format("Hello, ~s!~n", [Name]).\r\n```\r\n\r\n### 如何在shell使用模块\r\n先假定`msg.erl`文件保存在`/home/david/erl`目录下，我们在这个目录下用`erl`命令打开Erlang的交互式shell\r\n``` Erlang\r\nErlang/OTP 20 [erts-9.1.5] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]\r\n\r\nEshell V9.1.5  (abort with ^G)\r\n1>  c("msg").\r\n{ok,msg}\r\n2>msg:greet(male,"David").\r\nHello, Mr. David!\r\nok\r\n3>\r\n```\r\n可以看到，当函数放到模块中的时候，调用函数就需要在函数前面增加模块名字和冒号，如`msg:greet(male,"David").`\r\n\r\n## 什么是Erlang的进程\r\n在Erlang中，最小执行单位是进程，当然这个进程并不是系统层面上的进程，也不是系统的线程线程，而是Erlang运行时中自己定义的一种轻量级的执行结构。\r\n\r\n### Erlang的进程是如何执行的\r\n\r\n在上面提到Erlang的进程是Erlang运行时中定义的一种轻量级的执行结构，那么这个结构就是由Erlang的运行时来进行调度。Erlang运行时在启动之后会创建出和内核数量相同的系统线程，每个线程上都绑定了一个Erlang虚拟机的CPU，然后Erlang通过调度算法将就绪的Erlang进程调度到这个虚拟机的CPU上。\r\n\r\n下面是调度逻辑的伪代码：\r\n``` C\r\npid schedule() {\r\n  static int majorReductions = MREDS;  // 计算自己执行多少个时钟\r\n  majorReductions--; // 减少时钟\r\n  if(majorReductions == 0) {  \r\n    externalPoll(); // 时钟为0，检查外部事件，主要是socket\r\n    majorReductions = MREDS;  // 重置时钟\r\n   }  \r\n  checkTimeouts(); // 检查超时\r\n  pid p = nextReady(readyQueue); // 在准备就绪队列中找出就绪的进程 \r\n  p->reductions = REDS;  // 给进程分配时间片\r\n  p->status = RUNNING; // 标记运行\r\n  return p; // 返回给CPU\r\n}\r\n```\r\n是不是非常像一个操作系统在调度进程？因为Erlang的运行时，本身就在模拟一个特殊的基于寄存器的CPU，以及上面的一个任务调度器（最简单OS）。\r\n\r\n### 如何创建一个Erlang进程\r\n\r\nErlang做为一个面向并发的计算机语言，它为我们提供了两个比较有意思的进程创建元语`erlang:spawn`和`erlang:spawn_link`。这两个元语唯一的差别是`erlang:spawn`在创建一个Erlang进程成功后就不管这个进程了。而`erlang:spawn_link`会将创建者和被创建者关联起来，如果创建者异常退出了，被创建者也会跟着退出，反之亦然。\r\n\r\n下面就用刚才建立好的msg模块演示下如何创建Erlang进程\r\n``` Erlang\r\nErlang/OTP 20 [erts-9.1.5] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:10] [hipe] [kernel-poll:false] [dtrace]\r\n\r\nEshell V9.1.5  (abort with ^G)\r\n1> c("msg").          \r\n{ok,msg}\r\n2> erlang:spawn(msg,greet,[male,"David"]).\r\nHello, Mr. David!\r\n<0.67.0>\r\n3> erlang:spawn_link(msg,greet,[male,"David"]).\r\nHello, Mr. David!\r\n<0.69.0>\r\n4> \r\n```\r\n在这里spawn_link创建的进程因为是正常退出，并没有引起shell的崩溃，在后面介绍异常的时候，将会讲解Erlang进程的异常退出和如何应对。\r\n\r\n### Erlang进程的特点\r\n\r\nErlang为什么要这么大费周章的去设置这样一种进程机制呢？因为它有以下特点：\r\n\r\n1. 可抢占的软实时，这是Go，lua以及Akka库做不到的，毕竟Erlang最初设计是给电话交换机使用\r\n1. 轻量级，可以快速创建和大量创建，在CPU和内存充足的条件下，一个Erlang运行时环境可以创建上百万的Erlang进程\r\n1. 可监控，Erlang进程是可以通过监控机制进行管理，在异常退出的场景下，快速恢复。\r\n\r\n## 总结\r\n虽然已经讲述了如何进行进程创建了，但是大家很快就发现了吧，进程在执行完函数就立刻退出了，同时通过前面的[文章](https://www.ttalk.im/topics/6)知道Erlang中的变量是不可变的，那么Erlang进程要如何交换数据呢。在后面的文章，将会逐步介绍消息传递，异常处理等知识。\r\n\r\n\r\n	f	2019-09-05 15:22:05.90455
164	Erlang 入门-命名函数	Erlang	## Erlang函数\r\n\r\n在上一篇教程中，我们介绍了Erlang的递归和模式匹配，其中就可以看到Erlang的函数是如何定义的。Erlang的函数有两类，一类是命名函数，另一类是匿名函数（高阶函数）。本篇将介绍命名函数，匿名函数（高阶函数）将会放在下一篇介绍。为了定义函数就需要先理解Erlang的一个基础类型原子。\r\n\r\n## Erlang的原子类型\r\n\r\nErlang虽然是一个动态类型的语言，但是Erlang中还是有类型定义的。原子类型就会Erlang的基础数据类型之一，Erlang的原子可以被认为是非常特殊的变量，它的字面含义就是它的值。Erlang原子语法要求是，小写字母开头的标识或者是使用单引号括（‘’）括起的子串。例如，atom，atom1，atom_n和‘This is an atom’都是合法的原子。\r\n\r\n虽然可以将原子认为是特殊的变量，但是原子毕竟不是变量。Erlang中原子的数量是有限的，一个原子一旦被定义直到Erlang虚拟机退出为止都不会被销毁。虽然这个数量是有限制的，但是可以在Erlang虚拟机启动的时候，通过+t这个参数去修改Erlang虚拟机中原子数量的上限。同时，需要注意的是，模块名称和函数名称都是原子。\r\n\r\n## 命名函数语法\r\n\r\nErlang中定义命名函数的规则是这样的：原子类型的函数名，后面跟随着小括号，小括号内可以放置任意多个（不能多于255个）的变量或常量，这些变量和常量之间用逗号隔开，在括号后面放置->，在函数体的最后一个语句以句号结尾。下面就是一个最简答的例子：\r\n```erlang\r\ngreet(_, Name) ->\r\n  io:format("Hello, ~s!", [Name]).\r\n```\r\n在上一篇的例子中，可以看到以分号尾的函数，这就是Erlang函数特点之一。Erlang可以使用以分号结束但具有相同名字和相同数量参数函数作为Erlang函数的分句，但是这些分句必须放在最终以句号结尾的函数前面，中间不能有任何不同名字和不同数量参数的函数分句或函数存在。如下面的例子：\r\n```erlang\r\ngreet(male, Name) ->\r\n  io:format("Hello, Mr. ~s!", [Name]);\r\ngreet(female, Name) ->\r\n  io:format("Hello, Mrs. ~s!", [Name]);\r\ngreet(_, Name) ->\r\n  io:format("Hello, ~s!", [Name]).\r\n```\r\nErlang的函数的特点之二，同名函数只要参数数量不同，Erlang会认为是两个完全不同的函数。如下面的例子：\r\n```erlang\r\nfactorial(N) -> factorial(N,1).\r\nfactorial(0,Acc) -> Acc;\r\nfactorial(N,Acc) when N > 0 -> factorial(N-1,N*Acc).\r\n```\r\nErlang的函数的特点之三，函数哨位，可以在函数后面跟随一个逻辑判断语句，在函数执行函数体之前对传入的参数进行判断看是否符合函数体执行的条件。如下面的例子：\r\n```erlang\r\nage_can_drive(X) when X >= 16, X =< 104 ->\r\n  true;\r\nage_can_drive(_) ->\r\n  false.\r\n```\r\n但是需要注意的是，函数的哨位不但可以只用逻辑判断，还可以使用数学操作符和类型函数。但是可以使用的函数是有限制的，哨位中使用的函数是无法使用用户自定义的函数。	f	2019-09-05 15:22:06.009344
165	eJabberd 的花名册和出席 (3)	XMPP	## 我又回来了\r\n\r\n前面的文章中，其中重点介绍了[花名册管理](https://www.ttalk.im/topics/55)和[出席订阅](https://www.ttalk.im/topics/58)。花名册通过在服务器存储，解决了用户好友关系在多个机器上漫游的问题。出席订阅机制重点的解决了如何建立好友关系的过程。    \r\n本篇将重点介绍下出席通知，那么出席通知主要解决什么问题呢？可能各位读者已经猜测到了，就是好友上线通知。\r\n\r\n## 出席通知\r\n\r\nXMPP出席通知是典型地遵循一个"发布-订阅"或"观察者"模型的通知系统。 这里，一个实体发送出席信息给它的服务器，它的服务器接着广播那个信息给所有订阅了该实体的出席信息的联系人。\r\n\r\n### 出席探测\r\n出席探测是一个对某联系人的当前出席信息的请求的操作， 由代表某个用户的服务器代表该用户发送；语法上它是一个`type`属性值为`probe`的出席信息节.。在出席信息订阅的上下文中，`from`地址的值必须是订阅的用户的纯JID（不带资源的JID）而`to`地址的值必须是被订阅的联系人的纯JID, 因为出席信息订阅是基于纯JID（不带资源的JID）的。 \r\n\r\n ``` XML\r\n<presence from='juliet@example.com'\r\n              id='ign291v5'\r\n              to='romeo@example.net'\r\n              type='probe'/>\r\n```\r\n用户上线后，虽然会立刻接收服务器发来的花名册，但是花名册并不携带用户好友的出席信息，因此需要服务器帮助探测所有的好友出席信息。\r\n\r\n### 出席通知\r\n一个客户端，在完成XMPP的[RFC6120 Extensible Messaging and Presence Protocol (XMPP): Core ](https://tools.ietf.org/html/rfc6120)中所有规定动作，就需要发送出席通知给服务器，告知服务器客户端已经上线，可以进行常规通讯了。这个出席通知非常简单，是一个没有任何属性的节。\r\n``` XML\r\n<presence/>\r\n```\r\n虽然该节不包含任何属性，但是该节可以包含<priority/>元素, <show/>元素, 一个一个或多个<status/>元素实例。    \r\n这个出席通知虽然很简单，但是会在服务器上触发一系列动作。\r\n\r\n### ejabberd如何实现\r\n\r\nejabberd在实现XMPP中`presence`的部分非常完善，在关于代表客户端操作的方法都集中在`ejabberd_c2s`中。如前面文章所说的，出席订阅部分集中在`presence_track`这部分，而关于出席通知这部分，重点集中在 `presence_update`部分。\r\n\r\n下面是比较重要的代码\r\n\r\n``` Erlang\r\n%% 更新出席信息\r\n%% @doc User updates his presence (non-directed presence packet)\r\n-spec presence_update(Acc :: mongoose_acc:t(),\r\n                      From :: 'undefined' | ejabberd:jid(),\r\n                      State :: state()) -> {mongoose_acc:t(), state()}.\r\npresence_update(Acc, From, StateData) ->\r\n    Packet = mongoose_acc:get(element, Acc),\r\n    case mongoose_acc:get(type, Acc) of\r\n        <<"unavailable">> ->\r\n            Status = case xml:get_subtag(Packet, <<"status">>) of\r\n                         false ->\r\n                             <<>>;\r\n                         StatusTag ->\r\n                             xml:get_tag_cdata(StatusTag)\r\n                     end,\r\n            Info = [{ip, StateData#state.ip}, {conn, StateData#state.conn},\r\n                    {auth_module, StateData#state.auth_module}],\r\n            Acc1 = ejabberd_sm:unset_presence(Acc,\r\n                                              StateData#state.sid,\r\n                                              StateData#state.user,\r\n                                              StateData#state.server,\r\n                                              StateData#state.resource,\r\n                                              Status,\r\n                                              Info),\r\n            Acc2 = presence_broadcast(Acc1, StateData#state.pres_a, StateData),\r\n            Acc3 = presence_broadcast(Acc2, StateData#state.pres_i, StateData),\r\n            % and here we reach the end\r\n            {Acc3, StateData#state{pres_last = undefined,\r\n                                   pres_timestamp = undefined,\r\n                                   pres_a = gb_sets:new(),\r\n                                   pres_i = gb_sets:new(),\r\n                                   pres_invis = false}};\r\n        <<"invisible">> ->\r\n            NewPriority = get_priority_from_presence(Packet),\r\n            Acc0 = update_priority(Acc, NewPriority, Packet, StateData),\r\n            case StateData#state.pres_invis of\r\n                false ->\r\n                    Acc1 = presence_broadcast(Acc0,\r\n                                              StateData#state.pres_a,\r\n                                              StateData),\r\n                    Acc2 = presence_broadcast(Acc1,\r\n                                              StateData#state.pres_i,\r\n                                              StateData),\r\n                    S1 = StateData#state{pres_last = undefined,\r\n                                         pres_timestamp = undefined,\r\n                                         pres_a = gb_sets:new(),\r\n                                         pres_i = gb_sets:new(),\r\n                                         pres_invis = true},\r\n                    presence_broadcast_first(Acc2, From, S1, Packet);\r\n                true ->\r\n                    {Acc0, StateData}\r\n            end;\r\n        <<"error">> ->\r\n            {Acc, StateData};\r\n        <<"probe">> ->\r\n            {Acc, StateData};\r\n        <<"subscribe">> ->\r\n            {Acc, StateData};\r\n        <<"subscribed">> ->\r\n            {Acc, StateData};\r\n        <<"unsubscribe">> ->\r\n            {Acc, StateData};\r\n        <<"unsubscribed">> ->\r\n            {Acc, StateData};\r\n        _ ->\r\n            presence_update_to_available(Acc, From, Packet, StateData)\r\n    end.\r\n\r\npresence_update_to_available(true, Acc, _, NewPriority, From, Packet, StateData) ->\r\n    Acc2 = ejabberd_hooks:run_fold(user_available_hook,\r\n                                   StateData#state.server,\r\n                                   Acc,\r\n                                   [StateData#state.jid]),\r\n    Res = case NewPriority >= 0 of\r\n              true ->\r\n                  Acc3 = ejabberd_hooks:run_fold(roster_get_subscription_lists,\r\n                                                 StateData#state.server,\r\n                                                 Acc2,\r\n                                                 [StateData#state.user,\r\n                                                 StateData#state.server]),\r\n                  {_, _, Pending} = mongoose_acc:get(subscription_lists, Acc3, {[], [], []}),\r\n                  Acc4 = resend_offline_messages(Acc3, StateData),\r\n                  resend_subscription_requests(Acc4,\r\n                                               StateData#state{pending_invitations = Pending});\r\n              false ->\r\n                  {Acc2, StateData}\r\n              end,\r\n    {Accum, NewStateData1} = Res,\r\n    %% 得到订阅者的信息，全局广播\r\n    presence_broadcast_first(Accum, From, NewStateData1, Packet);\r\n```\r\n其中，ejabberd会根据`type`进行判断，该进行哪些操作，接着`presence_update_to_available`会在客户端首次上线和从离线状态变为上线状态的时候进行出席通知。正如前面所描述的XMPP出席通知是典型地遵循一个"发布-订阅"或"观察者"模型的通知系统，因此出席通知会通知所有在出席订阅过程中订阅的用户也就是用户的好友。\r\n\r\n另一方面，eJabberd借助了Erlang的特性，会在客户端断开连接后通知用户的好友用户离线了。\r\n``` Erlang\r\n-spec terminate(Reason :: any(), statename(), state()) -> ok.\r\nterminate(_Reason, StateName, StateData) ->\r\n    case {should_close_session(StateName), StateData#state.authenticated} of\r\n        {false, _} ->\r\n            ok;\r\n        %% if we are in an state wich have a session established\r\n        {_, replaced} ->\r\n            ?INFO_MSG("(~w) Replaced session for ~s",\r\n                      [StateData#state.socket,\r\n                       jid:to_binary(StateData#state.jid)]),\r\n            From = StateData#state.jid,\r\n            StatusEl = #xmlel{name = <<"status">>,\r\n                              children = [#xmlcdata{content = <<"Replaced by new connection">>}]},\r\n            Packet = #xmlel{name = <<"presence">>,\r\n                            attrs = [{<<"type">>, <<"unavailable">>}],\r\n                            children = [StatusEl]},\r\n            Acc0 = mongoose_acc:from_element(Packet),\r\n            Acc = mongoose_acc:put(from_jid, From, Acc0),\r\n            ejabberd_sm:close_session_unset_presence(\r\n              StateData#state.sid,\r\n              StateData#state.user,\r\n              StateData#state.server,\r\n              StateData#state.resource,\r\n              <<"Replaced by new connection">>,\r\n              replaced),\r\n            Acc1 = presence_broadcast(Acc, StateData#state.pres_a, StateData),\r\n            presence_broadcast(Acc1, StateData#state.pres_i, StateData),\r\n            reroute_unacked_messages(StateData);\r\n        {_, resumed} ->\r\n            ?INFO_MSG("(~w) Stream ~p resumed for ~s",\r\n                      [StateData#state.socket,\r\n                       StateData#state.stream_mgmt_id,\r\n                       jid:to_binary(StateData#state.jid)]);\r\n        _ ->\r\n            ?INFO_MSG("(~w) Close session for ~s",\r\n                      [StateData#state.socket,\r\n                       jid:to_binary(StateData#state.jid)]),\r\n\r\n            EmptySet = gb_sets:new(),\r\n            case StateData of\r\n                #state{pres_last = undefined,\r\n                       pres_a = EmptySet,\r\n                       pres_i = EmptySet,\r\n                       pres_invis = false} ->\r\n                    ejabberd_sm:close_session(StateData#state.sid,\r\n                                              StateData#state.user,\r\n                                              StateData#state.server,\r\n                                              StateData#state.resource,\r\n                                              normal);\r\n                _ ->\r\n                    From = StateData#state.jid,\r\n                    Packet = #xmlel{name = <<"presence">>,\r\n                                    attrs = [{<<"type">>, <<"unavailable">>}]},\r\n                    Acc0 = mongoose_acc:from_element(Packet),\r\n                    Acc = mongoose_acc:put(from_jid, From, Acc0),\r\n                    ejabberd_sm:close_session_unset_presence(\r\n                      StateData#state.sid,\r\n                      StateData#state.user,\r\n                      StateData#state.server,\r\n                      StateData#state.resource,\r\n                      <<"">>,\r\n                      normal),\r\n                    Acc1 = presence_broadcast(Acc, StateData#state.pres_a, StateData),\r\n                    presence_broadcast(Acc1, StateData#state.pres_i, StateData)\r\n            end,\r\n            reroute_unacked_messages(StateData)\r\n    end,\r\n    (StateData#state.sockmod):close(StateData#state.socket),\r\n    ok.\r\n\r\n```\r\n\r\n不管是上线，还是离线，从代码中都可以看到这里面的两个函数`presence_broadcast`和`presence_broadcast_first`的命名上都含有broadcast，也就是说这两个函数会进行广播操作。\r\n\r\n## 必须知道的问题\r\n\r\nXMPP的花名册和出席机制是非常完美的，就是因为它很完美，这就给实际生产使用带来了一些弊端。      \r\n\r\n### 花名册\r\nXMPP的花名册现在已经通过版本机制来避免每次全量同步花名册的操作，所以在客户端开发的时候，一定要注意相关功能是否被启用。否则会被移动用户抱怨飞速的消耗流量。\r\n\r\n### 出席通知\r\n\r\n1. 在客户端首次上线的时候，会通过`presence_broadcast_first`来进行广播，从`presence_broadcast_first` 的代码中可以看到，服务器会给我们所有的订阅用户发送出席探测的消息，同时给所有订阅用户发送用户出席的信息，如果一个用户有超级多的好友的情况下，用户的`ejabberd_c2s`进程会长时间无法处理别的信息。\r\n1. 异常离线的时候，也会给所有用户的好友发送离线出席信息的广播，所以在网络环境不好的情况，对用户的好友的流量会产生极大的负担，同时会加重服务器的负担。\r\n1. 考虑到XMPP的分布式特性，XMPP服务器本身并不集中保存用户的出席状态，而是通过出席探测的方式进行逐个探测，这个虽然很准确。但是会给用户用户和好友造成大量的流量负担。\r\n\r\n### 如何解决\r\n对于流量负担，是在所难免的，但是可以通过自己定制出席通知的方式，建立出席信息集中存储来降低用户流量的负担。\r\n\r\n## 总结\r\n至此，已经带各位读者了解了部分ejabberd中是如何实现花名册和出席相关的知识，省下的部分就需要读者们进一步深入到源代码和RFC相关规范中，带着需求去阅读源代码，从而从根本上解决自己业务上的需求。\r\n\r\n	f	2019-09-05 15:22:06.010374
166	为什么要选 Erlang 来做消息总线	Erlang/Elixir	## 为什么写这个\r\n\r\n近期Erlang语言的排名上升了，算事可喜可贺的事情，国内知名的MQTT产品EMQ也受到了广大厂家和研发的认可。但是有人就提出了疑问，为什么EMQ选择使用Erlang而非Java作为开发？虽然并不了解作者本人的想法，但是本篇将从Java虚拟机和Erlang运行时的层面上说明下Erlang为什么更适合消息总线类产品。\r\n\r\n## 宏观比较\r\n\r\n### Erlang运行时\r\nErlang是一种函数类型语言，使用Actor模型。在Erlang中一个Actor就是一个Erlang进程，Actor通过彼此之间传递消息来完成通信。Erlang运行时采用执行beam文件中的bytecode来完成工作。\r\n\r\n### JVM\r\n\r\nJava是一门面向对象的语言，JVM是通过执行Java原文件编译后class文件中的bytecode来完成相应的工作，这让Java具备的一次编译只要JVM版本兼容就可以多处运行。同时JVM会通过JIT技术，将class文件中的bytecode进行即时编译生成高性能的本地代码以提高执行速度。\r\n\r\n## 线程使用\r\n\r\n### Erlang运行时\r\n\r\nErlang会为创建和系统中安装CPU数量相同的OS线程，这些线程被称为调度器。每个调度器会管理大量前面提到的Erlang进程。为了最大限度的利用调度器，Erlang会使用任务秘取相关技术，让Erlang进程自动在多个调度器中进行负载均衡。    \r\n这些调度器通过`reduction`机制严格限制了每个Erlang进程执行的时间，同时使用任务优先级机制可以让高优先级的进程优先执行，从而实现Erlang进程软实时特性。    \r\n由于Erlang的进程并非真正的OS线程或OS进程，只是Erlang运行时中的一组数据结构，因此非常轻量级，可以在创建成千上万个Erlang进程。\r\n\r\n\r\n### JVM\r\n\r\nJVM将Java中的线程直接影射到OS级别的线程，因此Java中的线程调度直接依赖于操作系统的线程调度机制。同时，由于是OS级别的线程，因此是非常消耗资源的。JVM也提供了线程池的封装，用来调度异步任务，但是这些异步任务是无法做到软实时的。    \r\n每个Java线程都会包含下面信息：\r\n1. 一个程序计数器PC，用来保存当前指令地址\r\n1. 一个栈用来保存栈帧\r\n1. 如果使用native方法还会创建一个native栈\r\n\r\n\r\n## 内存管理\r\n\r\n### Erlang运行时\r\n\r\n#### 内存分配\r\n\r\nErlang运行时会大量使用内存池，根据使用目的不同划分多个内存池。    \r\n由于Erlang本身并没有变量，每个Erlang的进程都拥有自己的堆和栈。Erlang进程的堆和栈共享一段内存空间，堆向上生长，栈向下生长，因此非常容易检测到堆栈溢出。    \r\nErlang在消息传递的过程中会使用内存复制，对于大于64bytes的二进制在Erlang运行时中会独立内存池进行分配，当在进程间传递这种消息的时候只是传递指向该二进制的指针。\r\n\r\n#### 垃圾回收\r\n\r\n对于超过64bytes的二进制使引用计数来进行垃圾回收。对于每个进程则采用内存分代垃圾回收。Erlang运行时的垃圾回收，是针对Erlang进程的堆栈进行的，当一个Erlang进程结束运行，可以将该进程所有内存直接回收，因此无需进行stop the world。\r\n\r\n\r\n### JVM\r\n\r\n#### 内存分配\r\nJVM将内存分为堆内存和非堆内存，堆内存保存了所有的Java对象，整个JVM共享这个堆。非堆内存，用来保存编译过的Java代码，以及JIT代码等。\r\n\r\n#### 垃圾回收\r\nJVM堆内存使用分代垃圾回收，并且可以使用多种垃圾回收算法。但是对于堆内存回收不管何种算法都需要stop the world阶段。\r\n\r\n\r\n\r\n## 并发\r\n\r\n### Erlang运行时\r\n\r\nErlang使用了Actor模型，在Erlang语言层面上Erlang进程是不存在互锁的机制，所有的通讯都是通过消息传递进行的。    \r\nErlang运行时中，当Erlang进程互发消息的时候，会使用off_heap机制，尽可能减少Erlang进程执行的时候需要加锁的次数\r\n\r\n### JVM\r\n由于Java线程是OS线程，所以可以只是使用OS线程锁的相关元语。\r\n\r\n## 网络IO\r\n涉及到消息系统，一定会涉及到网络IO，因此在这里面单独讨论下。\r\n\r\n### Erlang运行时\r\n\r\nErlang默认优先使用高级IO多路复用的API，在没有这个API的情况下，默认使用select作为IO多路复用。整个Erlang运行时共享一个IO多路复用。所有的调度器使用leader/follower模式，为了确保IO的实效和Erlang进程的软实时性，Erlang调度器会使用`reduction`机制，在执行一定量Erlang进程后强制检查IO是否有触发。但是与leader/follower模式稍有不同的是，如果一个Erlang调度器发现已经有另一个调度器在检查IO，会立刻放IO多路复用的锁去调取可执行的Erlang进程来执行。\r\n\r\n#### socket处理模式\r\n\r\n因为Erlang进程的轻量性，因此在Erlang中socket处理方案是为每个socket创建一个Erlang进程，socket断开连接后，可以选择Erlang进程直接退出。和socket绑定的Erlang进程可以直接进行业务处理，而不会影响IO复用器进行IO复用。\r\n\r\n\r\n### JVM\r\n\r\nJVM封装了多种IO多路复用，并且在支持AIO。但是JVM并不提供类似Erlang运行时的IO任务管理机制，需要研发人员自行开发。\r\n\r\n#### netty框架\r\nJava中开发网络IO，netty是一个非常完善的Java网络框架，并经过大量的实践检验，可以在netty代码中看到大量针对JVM的IO子系统的bug进行针对性优化的代码。将IO处理，任务处理和编解码进行非常完整的规划，并提供了大量的基础设施。    \r\nnetty使用的是IO Per Thread模型，在一般服务器开发中又使用acceptor和worker线程分开的方案，acceptor和worker实用的是boss/worker模式，当acceptor完成socket的接入流程就通过worker的wakup机制，将socket交付给worker的IO复用器进行复用。      \r\n需要注意的是，worker在进行业务处理的时候，会直接占用worker线程直到业务结束，在此期间和该worker绑定的IO复用器是无法进行IO复用的。因此在netty开发的是有，需要经常使用netty的future线程池，将耗时的业务交给专用的线程池进行处理。\r\n\r\n## 总结\r\n\r\n选择Erlang进行消息系统开发有下面的优势：\r\n\r\n1. Erlang本身就是Actor模式，无需设计复杂的线程间消息交换机制（锁力度，队列管理等等）\r\n1. Erlang的GC不存在stop the world，因此内存效率相对较高，可以有效的防止大链接量下因为GC抖动而引起的socket接入失败（句柄不足依然会引起socket接入失败）\r\n1. 软实时性，每个socket一个Erlang进程，所有的业务逻辑只需要线性思考（特殊的业务除外，依然需要进行异步思考），Erlang运行时自动完成IO，任务切换，不会因为线性思考而影响IO复用\r\n1. 自带分布式，在一定量级前无需过度思考机器间RPC\r\n1. Erlang的binary操作可以进行二进制位操作，进行位级别的编解码非常简单\r\n\r\n当然选择Erlang进行消息系统开发也有下面一些劣势：\r\n1. Erlang语法是函数式，受众群体小\r\n1. 单IO复用器（R21 有待解决）\r\n\r\n总体来讲，Erlang开发消息系统的时候，除了语法外，心智负担比较小。\r\n\r\n	f	2019-09-05 15:22:06.11694
167	eJabberd 的花名册和出席 (2)	XMPP	## 你是我的好友\r\n[前篇文章](https://www.ttalk.im/topics/55)中介绍了，什么是花名册和出席的机制。从数据关系的层面上看，这样已经构成了好友关系。在仔细观察这个流程就会发现，用户A添加用B为好友根本就没有得到用户B的准许，但是实际上并不是这样的，要真正完成好友添加，不单单是在花名册上完成好友关系的添加，还要进行出席订阅。\r\n\r\n## 什么是出席订阅\r\n为了保护XMPP用户们的隐私, 出席信息仅向某个用户已经批准的其他实体披露。当某个同意允许其他实体察看其出席信息时, 该实体被称为对该用户的出席信息有一个"订阅"。 一个对某用户的出席信息有订阅的实体或一个用户对其有出席信息订阅的实体被称为"联系人" ，这才真正完成XMPP的好友添加。\r\n\r\n从此处可以看出，当用A想要添加用B为好友的时候，是需要B用户同意的。从这也不难看出来，真正好友的添加流程都集中在XMPP的出席部分，而不是花名册部分，花名册只是在负责在服务器上保存和管理用户的联系人。换句话说，一个规范的客户端应当先进行出席订阅接着才会进行花名册保存。\r\n\r\n## eJabberd是如何处理出席的\r\n\r\n### mod_roster 如何处理出席订阅\r\n\r\neJabberd 对出席订阅和相关操作并没有重新定义，而是直接复用了roster记录\r\n``` Erlang\r\n-record(roster, {usj,\r\n                 us,\r\n                 jid,\r\n                 name = <<>>,\r\n                 subscription = none :: both | from | to | none | remove,\r\n                 ask = none,\r\n                 groups = [],\r\n                 askmessage = <<>>,\r\n                 xs = []}).\r\n```\r\n在这里，subscription代表着订阅关系，ask代表正在进行出席的操作，当出席订阅结束后该字段的意义就不重要了。\r\n\r\n所有出席的订阅处理都被`mod_roster`注册在`roster_in_subscription`和`roster_out_subscription`这两个hook上，最终交给`mod_roster:process_subscription_transaction`函数进行处理\r\n\r\n### 出席订阅\r\n#### 好友申请\r\n用户A要添加用B为好友，首先要做的就是要生成一个出站的出席订阅请求，也就是我们说的好友申请\r\n``` XML\r\n <presence id='xk3h1v69'\r\n              to='juliet@example.com'\r\n              type='subscribe'/>\r\n```\r\n##### 出站处理\r\n出站指的是用户A将申请发送到服务器上，并要求服务器更新A相关状态并转发给用户B的过程。  \r\neJabberd的服务器接收到该请求后，会使用`roster_out_subscription`的hook进行处理，在处理过程中如果发现roster的存储中没有用户到目标用的条目会在内存中建立一个默认条目。\r\n\r\n并且根据下面的规则，将这个roster的ask状态更新为out，subscription状态不变，存储到roster存储中，并将该出席信息转发给目标用户。\r\n```Erlang\r\nout_state_change(none, none, subscribe) -> {none, out};\r\n```\r\n##### 入站处理\r\n入站指的是服务器将用户A的请求发送给用户B，并在服务器上更新B的相关状态的过程。  \r\neJabberd在入站的过程中，ejabberd_sm会发现这个好友请求，并使用`roster_in_subscription`进行处理，在处理过程中如果发现roster的存储中没有用户到目标用的条目会在内存中建立一个默认条目。\r\n\r\n并且根据下面的规则，将这个roster的ask状态更新为in，subscription状态不变，存储到roster存储中，并将该出席信息转发给目标用户。\r\n\r\n```Erlang\r\nin_state_change(none, none, subscribe) -> {none, in};\r\n```\r\n\r\n#### 好友应答\r\n用户B收到用户A的好友申请后，就要做出回答，也就是我们说的好友批准流程，好友应答有两种情况\r\n``` XML\r\n<!-- 同意的情况 -->\r\n<presence id='h4v1c4kj'\r\n              to='romeo@example.net'\r\n              type='subscribed'/>\r\n\r\n<!-- 不同意的情况 -->\r\n<presence id='tb2m1b59'\r\n              to='romeo@example.net'\r\n              type='unsubscribed'/>\r\n```\r\n##### 出站处理\r\n此时的出站，指的是用户B将好友应答发送给服务器，并要求服务器更新B的相关状态，并将申请转发给A的过程\r\n同样eJabberd的服务器接收到该请求后，会使用`roster_out_subscription`的hook进行处理，这个时候会从roster存储中读取出ask状态为in，subscription状态为none的记录。\r\n\r\n根据下面的规则进行状态更新\r\n``` Erlang\r\nout_state_change(none, in, subscribed) -> {from, none};\r\nout_state_change(none, in, unsubscribed) -> {none, none};\r\n```\r\n- 不同意订阅，会返回{none,none}，在`mod_roster:process_subscription_transaction`的处理过程中将会将记录删除\r\n- 如果同意订阅，会返回{from, none}，会将subscription状态更新为from，ask状态更新为none并保存\r\n\r\n##### 入站处理\r\n此时的入站，指服务器将B的应答发送给A，并将更新状态并将消息发送给A的过程\r\n同样eJabberd在入站的过程中，ejabberd_sm会发现这个好友请求，并使用`roster_in_subscription`进行处理，这个时候会从roster存储中读取出ask状态为out，subscription状态为none的记录。\r\n\r\n根据下面的规则进行状态更新\r\n``` Erlang\r\nin_state_change(none, out, subscribed) -> {to, none};\r\nin_state_change(none, out, unsubscribed) -> {none, none};\r\n```\r\n- 不同意订阅，会返回{none,none}，在`mod_roster:process_subscription_transaction`的处理过程中将会将记录删除\r\n- 如果同意订阅，会返回{from, none}，会将subscription状态更新为to，ask状态更新为none并保存\r\n\r\n## 总结\r\n从整个出席订阅也就是我们常说的好友添加过程中，可以看出XMPP是非常严谨的，将好友添加合理分配给，请求方，服务器和被请求方进行处理，各司其职。本篇中还有几个处理并没有介绍，其中包括，出席订阅取消既好友删除，出席订阅预批准既好友添加白名单。\r\n	f	2019-09-05 15:22:06.224308
168	eJabberd 的花名册和出席 (1)	XMPP	## 什么是花名册和出席\r\nXMPP的[RFC6120 Extensible Messaging and Presence Protocol (XMPP): Core ](https://tools.ietf.org/html/rfc6120)非常详细的介绍了XMPP的核心协议。核心协议虽然非常好的完成了数据流交换机制，以及建立了非常强大的可扩展体系，但是这还不能称为即时通信系统。因此XMPP在[RFC6121 Extensible Messaging and Presence Protocol (XMPP):Instant Messaging and Presence](https://tools.ietf.org/html/rfc6121)中详细的介绍了，花名册，出席和端到端消息交换。\r\n\r\n### 花名册\r\n作为成熟的即时通讯系统，就必然有联系人的管理和存储机制，花名册就是XMPP用来进行管理和存储一个用户的好友们的机制。\r\n\r\n### 出席\r\nXMPP为了让用户知道自己的联系人什么时候在线和可进行通讯。XMPP建立了一种通知机制，当用户的联系人在线状态发生变化的时候，服务器会自动向用户发送通知，也就是出席机制。\r\n\r\n## 花名册的使用\r\n###  ver 属性\r\nver属性是一个标识名册信息的特定版本的字符串。它的值必须仅由服务器生成并且必须由客户端不透明地处理。服务器可以使用任何适当的方法来生成该版本ID, 类似名册数据的哈希值或一个严格递增的序列号。\r\n\r\n因为数据同步天生就存在很多不确定性，因此在RFC6121中就做出了明确规定，一切以服务器为准，这样就解决了同步操作中的冲突问题。\r\n\r\n### 名册管理\r\nXMPP中名册管理是通过IQ处理来完成的。在逻辑上并没有复杂的操作，只是常见的增删改查，唯一的增加的就是XMPP的名册管理多出了一个服务器推送名册的功能。这是因为XMPP支持多客户端（resource）同时登录的原因。\r\n\r\n#### 名册获取\r\n客户端会给服务器发送出下面的XML用来获取名册\r\n``` XML\r\n<iq from='juliet@example.com/balcony'\r\n       id='bv1bs71f'\r\n       type='get'>\r\n    <query xmlns='jabber:iq:roster'/>\r\n  </iq>\r\n```\r\n而服务器必须做出应答，即便是用户的名册为空的时候也不应返回error，而是返回空的result\r\n``` XML\r\n <iq id='bv1bs71f'\r\n       to='juliet@example.com/chamber'\r\n       type='result'>\r\n    <query xmlns='jabber:iq:roster' ver='ver7'>\r\n      <item jid='nurse@example.com'/>\r\n      <item jid='romeo@example.net'/>\r\n    </query>\r\n  </iq>\r\n<iq id='bv1bs71f'\r\n       to='juliet@example.com/chamber'\r\n       type='result'>\r\n    <query xmlns='jabber:iq:roster' ver='ver9'/>\r\n  </iq>\r\n```\r\n只有，且仅有名册服务不存在的时候，才应返回error应答\r\n``` XML\r\n<iq id='bv1bs71f'\r\n          to='juliet@example.com/chamber'\r\n          type='error'>\r\n       <error type='cancel'>\r\n         <item-not-found\r\n             xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\r\n       </error>\r\n     </iq>\r\n```\r\n#### 名册修改\r\n名册的修改是通过IQ的set操作完成的，所有的增加和修改都需要包含联系人的全部信息，因为XMPP不存在局部修改这个花名册中联系人功能\r\n``` XML\r\n<iq from='juliet@example.com/balcony'\r\n       id='ph1xaz53'\r\n       type='set'>\r\n     <query xmlns='jabber:iq:roster'>\r\n       <item jid='nurse@example.com'\r\n             name='Nurse'>\r\n         <group>Servants</group>\r\n       </item>\r\n     </query>\r\n   </iq>\r\n```\r\n而删除操作是复用了subscription，关于subscription属性会在第二部分关于出席里面进行详细介绍。在这个删除操作中会给subscription属性赋值为remove。\r\n``` XML\r\n<iq from='juliet@example.com/balcony'\r\n       id='hm4hs97y'\r\n       type='set'>\r\n     <query xmlns='jabber:iq:roster'>\r\n       <item jid='nurse@example.com'\r\n             subscription='remove'/>\r\n     </query>\r\n   </iq>\r\n```\r\n需要注意的是，因为[RFC3921](https://tools.ietf.org/html/rfc3921)，并没有定义花名册是带有版本的。因此会在流打开的时候通过下面的XML来协商特性。\r\n``` XML\r\n<ver xmlns='urn:xmpp:features:rosterver'/>\r\n```\r\n如果一个服务器支持带版本的名册，任何对花名册进行修改的操作都会引起版本的变动。\r\n\r\n## eJabberd中的花名册实现\r\n\r\n### mod_roster\r\neJabberd对花名册的管理是通过插件机制来完成，核心流程都是由mod_roster来完成的。eJabberd的花名册存储方式有多种方式，有Mnesia，Riak，LDAP和ODBC，并且这些存储引擎可以通过配置文件动态指定。\r\n\r\nmod_roster在初始化过程中会将自己加入Hook中，并构建对应的存储后端。最重要的是，mod_roster对花名册的IQ处理默认是使用单队列（一个Erlang进程）来序列处理。\r\n``` Erlang\r\nstart(Host, Opts) ->\r\n    %% 默认情况是使用一个队列完成所有处理的\r\n    IQDisc = gen_mod:get_opt(iqdisc, Opts, one_queue),\r\n    TrackedFuns = [read_roster_version,\r\n                   write_roster_version,\r\n                   get_roster,\r\n                   get_roster_by_jid_t,\r\n                   get_subscription_lists,\r\n                   roster_subscribe_t,\r\n                   get_roster_by_jid_with_groups_t,\r\n                   update_roster_t,\r\n                   del_roster_t,\r\n                   read_subscription_and_groups\r\n                   ],\r\n    %% 启动后端模块\r\n    gen_mod:start_backend_module(?MODULE, Opts, TrackedFuns),\r\n    mod_roster_backend:init(Host, Opts),\r\n    %% 注册roster相关的hook请求\r\n    ejabberd_hooks:add(roster_get, Host,\r\n                       ?MODULE, get_user_roster, 50),\r\n    ejabberd_hooks:add(roster_in_subscription, Host,\r\n                       ?MODULE, in_subscription, 50),\r\n    ejabberd_hooks:add(roster_out_subscription, Host,\r\n                       ?MODULE, out_subscription, 50),\r\n    ejabberd_hooks:add(roster_get_subscription_lists, Host,\r\n                       ?MODULE, get_subscription_lists, 50),\r\n    ejabberd_hooks:add(roster_get_jid_info, Host,\r\n                       ?MODULE, get_jid_info, 50),\r\n    ejabberd_hooks:add(remove_user, Host,\r\n                       ?MODULE, remove_user, 50),\r\n    ejabberd_hooks:add(anonymous_purge_hook, Host,\r\n                       ?MODULE, remove_user, 50),\r\n    ejabberd_hooks:add(roster_get_versioning_feature, Host,\r\n                       ?MODULE, get_versioning_feature, 50),\r\n    %% 添加roster的IQ处理流程\r\n    gen_iq_handler:add_iq_handler(ejabberd_sm, Host, ?NS_ROSTER,\r\n                                  ?MODULE, process_iq, IQDisc).\r\n```\r\n对花名册的处理主要都是由`mod_roster:process_iq`完成的，process_iq封装了process_iq_get和process_iq_set，get主要负责花名册的查询工作。\r\n``` Erlang\r\nprocess_iq_get(From, To, #iq{sub_el = SubEl} = IQ) ->\r\n    LServer = From#jid.lserver,\r\n    try\r\n        %% 请求带版本了\r\n        AttrVer = xml:get_tag_attr(<<"ver">>, SubEl),\r\n        %% 是否准许请求带版本\r\n        VersioningEnabled = roster_versioning_enabled(LServer),\r\n        %% 得到DB中的版本\r\n        VersionOnDb = roster_version_on_db(LServer),\r\n        %% 根据版本获取IQ\r\n        {ItemsToSend, VersionToSend} =\r\n        get_user_roster_based_on_version(AttrVer, VersioningEnabled, VersionOnDb,\r\n                                         From, To),\r\n        IQ#iq{type = result,\r\n              sub_el = create_sub_el(ItemsToSend, VersionToSend)}\r\n    catch\r\n        _:_ ->\r\n            IQ#iq{type = error,\r\n                  sub_el = [SubEl, ?ERR_INTERNAL_SERVER_ERROR]}\r\n    end.\r\n```\r\n在`get_user_roster_based_on_version`的时候会去判断是否需要发送版本，以及花名册数据。在`get_user_roster_based_on_version`的时候，会直接使用roster_get这个hook进行数据获取，这样就给开发者一个机会，可以在不用修改mod_roster的情况下，客户端要获取的花名册的过程中对花名册内部条目的修改。\r\n\r\n而process_iq_set的操作，更多是依赖数据库事务的遍历写入操作。\r\n``` Erlang\r\nprocess_iq_set(#jid{lserver = LServer} = From, To, #iq{sub_el = SubEl} = IQ) ->\r\n    #xmlel{children = Els} = SubEl,\r\n    %% 使用roster_set来过滤所有的消息\r\n    ejabberd_hooks:run(roster_set, LServer, [From, To, SubEl]),\r\n    %% 逐条处理消息\r\n    lists:foreach(fun(El) -> process_item_set(From, To, El) end, Els),\r\n    IQ#iq{type = result, sub_el = []}.\r\n```\r\n此处需要重点注意的是，`process_item_set`这个函数，每修改一个花名册条目，就会增加花名册版本一次。例如说一共处理10个item，初始版本是1，处理完后的版本就是11了。\r\n\r\n## 总结\r\neJabberd非常完整的实现了花名册部分，并且在多个关键点给出了Hook，让开发者可以非常容易的不修改mod_roster的情况下就能对花名册的一些功能进行扩展。后面的文章将会介绍出席，以及XMPP的出席和花名册机制的缺陷。\r\n\r\n	f	2019-09-05 15:22:06.327542
169	OCaml 通过 opam 安装 ZeroMQ	ML类语言	# 起因\r\n\r\n个人最近在学习OCaml和使用ZeroMQ，但是在我的OpenBSD上搞了好久，就是无法通过opam安装ZeroMQ的绑定。\r\n\r\n# 发现问题\r\n\r\n通过观察用户目录下.opam/system/build/可以发现，ZeroMQ的绑定依赖conf-zmq。而conf-zmq只是尝试编译一个文件test.c。在编译该文件的时候，使用的命令是gcc test.c -lzmq。通过查看test.c其中包含头文件的方式为#include<zmq.h>。根据gcc的参考文件，在Unix上会在下面这些文件夹中寻找头文件：\r\n```c\r\n/usr/local/include\r\n/usr/lib/gcc-lib/target/version/include\r\n/usr/target/include\r\n/usr/include\r\n```\r\n但是当我用gcc -v test.c -lzmq的时候，却发现只有：\r\n```c\r\n/usr/include\r\n```\r\n# 解决方式\r\n\r\ngcc在编译的时候，会使用几个标准的环境变量：\r\n\r\n```c\r\nC_INCLUDE_PATH, CPATH, CPLUS_INCLUDE_PATH, DEPENDENCIES_OUTPUT,\r\nOBJC_INCLUDE_PATH, SUNPRO_DEPENDENCIES\r\n```\r\n我们只需要将我们需要的路径加入到这些环境变量中就可以了\r\n```c\r\n#在PATH中找到可执行文件程序的路径。\r\nexport PATH =$PATH:$HOME/bin\r\n#gcc找到头文件的路径\r\nC_INCLUDE_PATH=$C_INCLUDE_PATH:/usr/local/include/:/usr/local/include/zmq\r\nexport C_INCLUDE_PATH\r\n#g++找到头文件的路径\r\nCPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:/usr/local/include/:/usr/local/include/zmq\r\nexport CPLUS_INCLUDE_PATH\r\n#找到动态链接库的路径\r\nLD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib\r\nexport LD_LIBRARY_PATH\r\n#找到静态库的路径\r\nLIBRARY_PATH=$LIBRARY_PATH:/usr/local/lib\r\nexport LIBRARY_PATH\r\n```\r\n接着我们只要重新执行\r\n```ocaml\r\nopam install zmq\r\n```\r\n	f	2019-09-05 15:22:06.435359
170	什么是 MQTT	MQTT	## 什么是MQTT\r\n\r\nMQTT（Message Queuing Telemetry Transport，消息队列遥测传输）是基于二进制消息的发布/订阅编程模式的消息协议，最早由IBM提出的，如今已经成为OASIS规范。由于规范很简单，非常适合需要低功耗和网络带宽有限的IoT场景。\r\n\r\n## MQTT特点\r\n\r\n1. 精简，不添加可有可无的功能。\r\n1. 发布/订阅（Pub/Sub）模式，方便消息在传感器之间传递。\r\n1. 允许用户动态创建主题，零运维成本。\r\n1. 把传输量降到最低以提高传输效率。\r\n1. 把低带宽、高延迟、不稳定的网络等因素考虑在内。\r\n1. 支持连续的会话控制。\r\n1. 理解客户端计算能力可能很低。\r\n1. 提供服务质量管理。\r\n1. 假设数据不可知，不强求传输数据的类型与格式，保持灵活性。\r\n\r\n为了满足不同的场景，MQTT支持三种不同级别的服务质量（Quality of Service，QoS）为不同场景提供消息可靠性：\r\n\r\n1. 级别0：尽力而为。消息发送者会想尽办法发送消息，但是遇到意外并不会重试。\r\n1. 级别1：至少一次。消息接收者如果没有知会或者知会本身丢失，消息发送者会再次发送以保证消息接收者至少会收到一次，当然可能造成重复消息。\r\n1. 级别2：恰好一次。保证这种语义肯待会减少并发或者增加延时，不过丢失或者重复消息是不可接受的时候，级别2是最合适的。\r\n\r\n## 和XMPP相比优缺点\r\n\r\n### MQTT\r\n如其名称所述，其主要目的是遥测或远程监控。其目标是从许多设备收集数据并将该数据传输到IT基础架构。它面向需要从云监控或控制的小型设备的大型网络。消息队列遥测传输（MQTT）实现了一个中心辐射系统。 MQTT很少尝试启用设备到设备的传输，也不会将数据“扇出”给许多收件人。\r\n\r\n由于它具有清晰，引人注目的单一应用，因此MQTT很简单，提供了很少的控制选项，它也不需要特别快，在这种情况下，“实时”通常以秒为单位。MQTT是一种中心辐射架构。所有设备都连接到数据集中器服务器，如IBM新的MessageSight设备。MQTT使应用程序能够监视巨大的石油管道泄漏或破坏，几千个传感器的数据都被集中在一个单独的位置进行分析。当系统发现问题时，可以采取行动来纠正该问题。 MQTT的其他应用包括电力使用监控，照明控制，甚至智能园艺。\r\n\r\n### XMPP\r\n如[本篇](https://www.ttalk.im/topics/2)中对XMPP的介绍，XMPP（可扩展消息处理现场协议）是基于可扩展标记语言（XML）的协议，它用于即时消息（IM）以及在线通讯的相关场景。    \r\n应用XMPP的核心XML流传输协议的定义使得XMPP能够在一个比以往网络通信协议更规范的平台上。借助于XML易于解析和阅读的特性，使得XMPP的协议能够非常容易被理解和调试。XMPP的即时通讯扩展应用部分是根据IETF在这之前对即时通讯的一个抽象定义的，与其他业已得到广泛使用的即时通讯协议，诸如AIM，QQ等相比，XMPP更加开放，更容易扩展并且天生就具有分布式特性。\r\n\r\n### 比较\r\n\r\nMQTT的优势：\r\n1. 协议简单且轻量级\r\n1. QoS管理\r\n1. 客户端不需要强大的计算力\r\n1. 数据可以自行定义，无强制要求\r\n1. 高带宽利用率，考虑慢速网络，连接速度快\r\n\r\nMQTT的劣势：\r\n1. 不擅长处理将数据交付给多个收件人的场景\r\n1. 不擅长处理复杂的业务控制，可扩展性取决于顶层机制\r\n1. 不擅长高速大队列的数据传输\r\n\r\n\r\n	f	2019-09-05 15:22:06.436625
171	Actor 模型介绍	Erlang	## Actor模型\r\n### Actor模型定义\r\n\r\nActor模型可以说是并发编程中非常常见的一种模型，该模型是Carl Hewitt在1973年提出的。\r\n\r\n### Actor模型如何工作\r\n\r\n1. Actor是独立的，每个Actor只管理自己的内部数据，对外暴露一个通信用的邮箱\r\n1. Actor都是通过向另一Actor暴露的邮箱发送消息来进行通信\r\n1. Actor之间的通讯行为是异步的\r\n\r\n### Actor模型中的Actor可以做什么\r\n\r\n1. 接收消息并进行相应处理\r\n1. 创建新的Actor\r\n1. 发送消息给另一个Actor\r\n\r\n## Actor实现\r\n### Erlang的Actor实现\r\n\r\n1. Erlang的Actor模型是基于Erlang进程实现的\r\n1. Erlang的Actor在死亡后会立刻进行垃圾处理\r\n1. Erlang的Actor直被Erts内部的POSIX线程调度\r\n\r\n### Akka的Actor实现\r\n\r\n1. Akka的Actor模型以类为基础，通过Java的类库来实现\r\n1. Akka的Actor在死亡后，需要等待JVM进行GC时才进行垃圾处理\r\n1. Akka的Actor是通过Java的线程池调度\r\n\r\n### 两种实现的差异\r\n\r\n#### Actor调度\r\nErlang的调度方式是抢占式公平调度（Erts强行切换），Akka的调度是协作式调度（完全依赖Actor主动放弃调度器）。\r\n\r\nErlang的Actor调度会受到CPU数量和Actor数量影响，具体例子可以看下面：\r\n\r\n- 我们的CPU为2Core时，process数为200，每个process平均获得CPU的能力 1/200 ＊ 2  ＝ 1% 。\r\n- 我们的CPU为4Core时，process数为200，每个process平均获得CPU的能力 1/200 ＊ 4 ＝ 2% 。\r\n- 我们的CPU为8Core时，process数为1000，每个process平均获得CPU的能力 1/1000 * 8 Core = 0.8%。\r\n\r\n也就是说，Erlang在进程数不变的时候，增加CPU会增加每个Erlang进程的执行时，而Akka的调度是协作式的调度，这就代表着我们无法得到上面例子中的算式，当一个调度器上的某个Actor在做一个非常长时间的计算，完全由可能让调度器上的其它Actor不能按时调度。\r\n\r\n#### IO操作\r\nErlang的Actor在执行IO的时候会进入等待状态，放弃调度线程，Akkaz不使用封装后的IO操作时会一直占用调度线程，使用封装的IO操作时才会放弃调度线程。\r\nErlang因为是Erts提供的IO操作，相对会比较统一，但是如果使用自己编写的Nif或Driver就需要注意是否存在同步的IO操作，因为这种原生的IO操作会让Actor一直占用调度线程。\r\n因此在Akka的Actor中，尽量不要使用Java提供的同步IO操作，而应该使用Akka提供的异步IO操作。\r\n\r\n\r\n	f	2019-09-05 15:22:06.437708
172	Erlang 的 Trap 机制	Erlang/Elixir	## 什么是Trap机制\r\n\r\n在分析erlang:send的bif时候发现了一个BIF_TRAP这一系列宏。参考了Erlang自身的一些描述，这些宏是为了实现一种叫做Trap的机制。Trap机制中将Erlang的代码直接引入了Erts中，可以让C函数直接"使用"这些Erlang的函数。\r\n\r\n## 为什么要实现Trap机制\r\n\r\n1. 将用C函数实现比较困难的功能用Erlang来实现，直接引入到Erts中。\r\n1. 延迟执行，将和Driver相关的操作或者需要通过OTP库进行决策的事情，交给Erlang来实现。\r\n1. 主动放弃CPU，让调度进行再次调度。这个相当于让BIF支持了yield，防止C函数执行时间过长，不能保证软实时公平调度。\r\n\r\n## Erlang是怎么实现Trap机制\r\n\r\nErlang的Trap机制是通过使用Trap函数，BIF_TRAP宏和调度器协作来完成的。下面让我以erlang:send这个BIF和beam_emu中的部分代码来说下Trap的流程。\r\n\r\n我们先看下进入BIF的代码：\r\n``` Erlang\r\n OpCase(call_bif_e):\r\n    {\r\n\t\t Eterm (*bf)(Process*, Eterm*, BeamInstr*) = GET_BIF_ADDRESS(Arg(0));\r\n\t\t Eterm result;\r\n\t\t BeamInstr *next;\r\n\r\n\t\t PRE_BIF_SWAPOUT(c_p);\r\n\t\t c_p->fcalls = FCALLS - 1;\r\n\t\t if (FCALLS <= 0) {\r\n\t\t\t  save_calls(c_p, (Export *) Arg(0));\r\n\t\t }\r\n\t\t PreFetch(1, next);\r\n\t\t ASSERT(!ERTS_PROC_IS_EXITING(c_p));\r\n\t\t reg[0] = r(0);\r\n\t\t result = (*bf)(c_p, reg, I);\r\n\t\t ASSERT(!ERTS_PROC_IS_EXITING(c_p) || is_non_value(result));\r\n\t\t ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);\r\n\t\t ERTS_HOLE_CHECK(c_p);\r\n\t\t ERTS_SMP_REQ_PROC_MAIN_LOCK(c_p);\r\n\t\t PROCESS_MAIN_CHK_LOCKS(c_p);\r\n\t\t //如果mbuf不空，且overhead已经超过了二进制堆的大小，那么需要进行一次垃圾回收\r\n\t\t if (c_p->mbuf || MSO(c_p).overhead >= BIN_VHEAP_SZ(c_p)) {\r\n\t\t\t  Uint arity = ((Export *)Arg(0))->code[2];\r\n\t\t\t  result = erts_gc_after_bif_call(c_p, result, reg, arity);\r\n\t\t\t  E = c_p->stop;\r\n\t\t }\r\n\t\t HTOP = HEAP_TOP(c_p);\r\n\t\t FCALLS = c_p->fcalls;\r\n//看是否直接得道了结果\r\n\t\t if (is_value(result)) {\r\n\t\t\t  r(0) = result;\r\n\t\t\t  CHECK_TERM(r(0));\r\n\t\t\t  NextPF(1, next);\r\n//没有结果，返回了THE_NON_VALUE\r\n\t\t } else if (c_p->freason == TRAP) {\r\n//设置进程的接续点\r\n\t\t\t  SET_CP(c_p, I+2);\r\n//设置改变scheduler正在执行的指令\r\n\t\t\t  SET_I(c_p->i);\r\n//重新进场，更新快存\r\n\t\t\t  SWAPIN;\r\n\t\t\t  r(0) = reg[0];\r\n\t\t\t  Dispatch();\r\n\t\t }\r\n```\r\n所有Erlang代码要调用BIF操作的时候，都会产生一个call_bif_e的Erts指令。当调度器执行到这个指令的时候，先要找到BIF函数的所在地址，然后通过C语言调用执行BIF获得result，同时根据约定如果result存在则直接放入快存x0(r(0))然后继续执行，如果没有返回值同时freason是TRAP，那么我们就触发TRAP机制。\r\n\r\n再让我们看下erl_send的部分代码\r\n``` Erlang\r\n    switch (result) {\r\n    case 0:\r\n\t/* May need to yield even though we do not bump reds here... */\r\n\t\t if (ERTS_IS_PROC_OUT_OF_REDS(p))\r\n\t\t\t  goto yield_return;\r\n\t\t BIF_RET(msg); \r\n\t\t break;\r\n    case SEND_TRAP:\r\n\t\t BIF_TRAP2(dsend2_trap, p, to, msg); \r\n\t\t break;\r\n    case SEND_YIELD:\r\n\t\t ERTS_BIF_YIELD2(bif_export[BIF_send_2], p, to, msg);\r\n\t\t break;\r\n    case SEND_YIELD_RETURN:\r\n    yield_return:\r\n\t\t ERTS_BIF_YIELD_RETURN(p, msg);\r\n    case SEND_AWAIT_RESULT:\r\n\t\t ASSERT(is_internal_ref(ref));\r\n\t\t BIF_TRAP3(await_port_send_result_trap, p, ref, msg, msg);\r\n    case SEND_BADARG:\r\n\t\t BIF_ERROR(p, BADARG); \r\n\t\t break;\r\n    case SEND_USER_ERROR:\r\n\t\t BIF_ERROR(p, EXC_ERROR); \r\n\t\t break;\r\n    case SEND_INTERNAL_ERROR:\r\n\t\t BIF_ERROR(p, EXC_INTERNAL_ERROR);\r\n\t\t break;\r\n    default:\r\n\t\t ASSERT(! "Illegal send result"); \r\n\t\t break;\r\n    }\r\n``` \r\n我们可以看到这里面使用了BIF_TRAP很多宏，那么这个宏做了什么呢？这宏非常简单\r\n```\r\n#define BIF_TRAP2(Trap_, p, A0, A1) do {\t\t\t\\\r\n      Eterm* reg = ERTS_PROC_GET_SCHDATA((p))->x_reg_array;\t\\\r\n      (p)->arity = 2;\t\t\t\t\t\t\\\r\n      reg[0] = (A0);\t\t\t\t\t\t\\\r\n      reg[1] = (A1);\t\t\t\t\t\t\\\r\n      (p)->i = (BeamInstr*) ((Trap_)->addressv[erts_active_code_ix()]); \\\r\n      (p)->freason = TRAP;\t\t\t\t\t\\\r\n      return THE_NON_VALUE;\t\t\t\t\t\\\r\n } while(0)\r\n```\r\n就是偷偷的改变了Erlang进程的指令i，同时，直接让函数返回THE_NON_VALUE。\r\n\r\n这个时候有人大概会说，这不是天下大乱了，偷偷改掉了Erlang进程执行的指令，那么这段代码执行完了，怎么能回到原来模块的代码中呢。我们可以再次回到调度器的代码中，我们可以看到，调度器的全局指令I还是正在执行的模块的代码，调度器发现了TRAP的存在，先让进程的接续指令cp（相当Erlang函数的退栈返回地址）直接为I＋2也就是原来模块中的下一条指令，然后再将全局指令I设置为Erlang进程指令i，接着执行下去。从Trap宏中，我们不难看出Trap函数是什么了，就是一个Export的数据结构。\r\n\r\n## 总结\r\n最后我们分析下为什么Erlang要这样实现TRAP。主要原因是Erlang是OPCode解释型的，Erlang进程执行的流程可控。另一个原因是，直接使用C语言的编译器来完成C函数的退栈和堆栈操作时，兼容性和稳定性要好很多不需要编写平台相关的汇编代码去操作C的堆栈。\r\n\r\n\r\n\r\n\r\n\r\n	f	2019-09-05 15:22:06.438678
173	EMQ 中的 session 管理	MQTT	## EMQ的session定义\r\n前一篇[EMQ 一个客户链接的资源消耗](https://www.ttalk.im/topics/63)中，提到了EMQ是使用链接进程(`emqtt_client`)和session进程(`emqtt_session`)分开的策略，其中\r\n`emqtt_session`负责管理EMQ的客户端的会话。  \r\n因此可以看出`emqtt_session`做为会话的管理者和网络socket没有任何关系。`emqtt_session`主要管理客户端离线后的消息，高QoS 2消息的确认管理，管理订阅以及packet identify的管理。\r\n\r\n## emqtt_session的创建\r\n\r\n当`emqtt_client`进程确认客户端的合法性后，会使用`emqtt_sm`中的函数去创建`emqtt_session`进程。\r\n``` Erlang\r\ncreate_session(CleanSess, {ClientId, Username}, ClientPid) ->                                                                     \r\n    case emqttd_session_sup:start_session(CleanSess, {ClientId, Username}, ClientPid) of                                          \r\n        {ok, SessPid} ->                                                                                                          \r\n            Session = #mqtt_session{client_id = ClientId, sess_pid = SessPid, clean_sess = CleanSess},                            \r\n            case insert_session(Session) of                                                                                       \r\n                {aborted, {conflict, ConflictPid}} ->                                                                             \r\n                    %% Conflict with othe node? 同名ID同时上线了                                                                  \r\n                    lager:error("SM(~s): Conflict with ~p", [ClientId, ConflictPid]),                                             \r\n                    {error, mnesia_conflict};                                                                                     \r\n                {atomic, ok} ->                                                                                                   \r\n                    {ok, SessPid}                                                                                                 \r\n            end;                                                                                                                  \r\n        {error, Error} ->                                                                                                         \r\n            {error, Error}                                                                                                        \r\n    end.\r\n```\r\n从代码中可以清晰的看出，`emqtt_client`并没有使用`spawn_link`机制来直接创建`emqtt_session`，而是使用`emqttd_session_sup`这个监督者来创建session进程。但是在`emqtt_session`的进程中，`emqtt_session`会主动的去关联`emqtt_client`进程，同时`emqtt_session`还会建立一个`monitor`去监控`emqtt_client`进程。    \r\n为什么要这样做呢？是因为以下几点原因：\r\n1. `emqtt_session`进程退出后，`emqtt_client`必须跟着退出\r\n1. `emqtt_client`进程退出后，根据情况需要保留`emqtt_session`进程，继续服务\r\n\r\n## emqtt_session恢复\r\n当MQTT客户端在CONNECT包中将，`clean session`设置为false的时候，`emqtt_session`进程会在`emqtt_session`进程退出之后，继续接收一段时间消息，这个时间段可以通过`mqtt.session.expiry_interval`来进行配置。    \r\n当然，在订阅某主题，并持续有消息广播的情况下，`emqtt_session`进程在失去`emqtt_session`进程后维持越久，所消耗的内存将会越多。\r\n``` Erlang\r\nhandle_cast({resume, ClientId, ClientPid},                                                                                        \r\n            State = #state{client_id       = ClientId,                                                                            \r\n                           client_pid      = OldClientPid,                                                                        \r\n                           clean_sess      = CleanSess,                                                                           \r\n                           retry_timer     = RetryTimer,                                                                          \r\n                           await_rel_timer = AwaitTimer,                                                                          \r\n                           expiry_timer    = ExpireTimer}) ->                                                                     \r\n                                                                                                                                  \r\n    ?LOG(debug, "Resumed by ~p", [ClientPid], State),                                                                             \r\n                                                                                                                                  \r\n    %% Cancel Timers                                                                                                              \r\n    lists:foreach(fun emqttd_misc:cancel_timer/1,                                                                                 \r\n                  [RetryTimer, AwaitTimer, ExpireTimer]),                                                                         \r\n    %% 踢掉老的客户端                                                                                                             \r\n    case kick(ClientId, OldClientPid, ClientPid) of                                                                               \r\n        ok -> ?LOG(warning, "~p kickout ~p", [ClientPid, OldClientPid], State);                                                   \r\n        ignore -> ok                                                                                                              \r\n    end,    \r\n    true = link(ClientPid),                                                                                                       \r\n                                                                                                                                  \r\n    State1 = State#state{client_pid      = ClientPid,                                                                             \r\n                         binding         = binding(ClientPid),                                                                    \r\n                         old_client_pid  = OldClientPid,                                                                          \r\n                         clean_sess      = false,                                                                                 \r\n                         retry_timer     = undefined,                                                                             \r\n                         awaiting_rel    = #{},                                                                                   \r\n                         await_rel_timer = undefined,                                                                             \r\n                         expiry_timer    = undefined},                                                                            \r\n                                                                                                                                  \r\n    %% Clean Session: true -> false?                                                                                              \r\n    if                                                                                                                            \r\n        CleanSess =:= true ->                                                                                                     \r\n            ?LOG(error, "CleanSess changed to false.", [], State1),                                                               \r\n            emqttd_sm:register_session(ClientId, false, info(State1));                                                            \r\n        CleanSess =:= false ->                                                                                                    \r\n            ok                                                                                                                    \r\n    end,                                                                                                                                                                                                                                                            \r\n    %% Replay delivery and Dequeue pending messages                                                                               \r\n    hibernate(emit_stats(dequeue(retry_delivery(true, State1)))); \r\n```\r\n从这些代码上，不难看出在`emqtt_session`在恢复过程中，会做下面几件事情：\r\n1. 踢掉老的客户端进程，和新客户端进程建立关联\r\n1. 检测`clean session`的变化，并根据情况重新注册session\r\n1. 重发所有堆积的消息\r\n\r\n## 总结\r\n\r\n使用链接进程(`emqtt_client`)和session进程(`emqtt_session`)分开的策略，充分的利用了Erlang的actor模型，简化了代码的编写同时利用Erlang的调度机制提高了消息的实时性（CPU数量充足）。\r\n\r\n但是这个设计并不是无懈可击的，当使用集群和session超时和`clean session`设置不当的时候，会出内网流量暴增以及某些节点内存暴增。同时因为`happens before`这种可能性，在下面场景会引起QoS 0的消息丢失。    \r\n`emqtt_session`因某些未知原因退出，同时`emqtt_client`进程的socket已经接收完数据，但未发送给`emqtt_client`进程，这个时候`link`机制的退出消息已经推送给`emqtt_client`进程。接着`emqtt_client`进程被Erlang调度器调度，这时候，`emqtt_client`直接进行退出操作，忽略所有已经收到的socket数据。 \r\n \r\n当然该会话管理模型还有很多优点和缺点，望读者们自己逐步去发现。\r\n	f	2019-09-05 15:22:06.546215
174	EMQ 一个客户链接的资源消耗	MQTT	## 为什么探讨这个话题\r\n[EMQ](http://www.emqtt.io/) 作为一个非常不错的开源MQTT服务器，被广泛使用。虽然广泛使用，但是对EMQ的消耗并没有特别多的了解，因此本篇将讲述下一个客户端链接到EMQ服务器上会产生多少消耗，以便在部署服务器前做好一定的规划。\r\n\r\n## Erlang进程消耗\r\n\r\nEMQ对客户端链接使用链接进程(`emqtt_client`)和session进程(`emqtt_session`)分开的策略。 当一个mqtt的客户端连接到EMQ的服务器上的时候，首先会建立一个负责管理连接的进程(`emqtt_client`)，当验证客户端有效后会建立另一个进程(`emqtt_session`)，负责该客户端的会话。\r\n\r\n在EMQ中，每一个clientID只能登录一次，因此后登录的客户端会将先登录的客户端踢下线。\r\n\r\n## 主要内存消耗\r\n\r\n### 数据表\r\n\r\n当一个客户端成功完成了验证，EMQ会在`mqtt_session`中添加一个表项目，同时会在`mqtt_local_session`和`mqtt_client`这两张ets表中添加表项目。\r\n\r\n### 进程上下文\r\n\r\n链接进程(`emqtt_client`)负责接收客户端发来的数据和接受服务器内部要发送给客户端的数据，并使用编解码器进行编解码，因此链接进程的上下文消耗，主要取决接收到的数据包大小和将要发送的数据包大小和数量。\r\n\r\nsession进程(`emqtt_session`)会保持一个inflight队列，用来对QoS大于0的消息进行应答等待，默认会保存32个消息在等待应答，如果超过这个量级就会放入等待队列。因此session进程(`emqtt_session`)的主要内存消耗，取决于多少等待应答的消息，以及这些需要应答消息的数据包的大小。\r\n\r\n## 主要CPU消耗\r\n\r\n### 定时器\r\n\r\n链接进程(`emqtt_client`)，默认会启动一个心跳定时器，定期的检查链接是否存活。session进程(`emqtt_session`)同样会开启一个重新发送定时器，用来检查QoS大于0的消息的infligt响应，当客户端发布QoS为2的消息时还会开启另外一个定时器，用来检测REPL信息的响应，当然session进程(`emqtt_session`)有可能会在客户端离线后保持一段时间，因此在这段时间会建立一个超时退出的定时器。因此session进程(`emqtt_session`)在某一个时刻会同时存在三个定时器。\r\n\r\n### 监控\r\n\r\nsession进程(`emqtt_session`)为了发现链接进程的退出，会建立一个针对链接进程的监控。而在客户端上线成功后后在向`mqtt_local_session`和`mqtt_client`这两张ets表中添加项目的时候，会分别建立两个监控，用来监控session进程(`emqtt_session`)和链接进程(`emqtt_client`)的退出。\r\n\r\n### 进程消息\r\n因为EMQ使用了链接进程(`emqtt_client`)和session进程(`emqtt_session`)分开的策略，因此产生进程消息传递是无法避免的。因为session进程(`emqtt_session`)会负责接收服务器发送给客户端的消息，并进行预先处理，处理完之后再交付给链接进(`emqtt_client`)程进行发送。\r\n\r\n当使用持久化session的时候，session进程(`emqtt_session`)的查找和恢复时也会产生大量的进程消息。\r\n\r\n## 总结\r\n\r\n从上面的介绍中，可以看出，在部署一个EMQ服务器前需要考虑，一个客户端平均消息的量级，QoS占比和数据包大小，同时根据有多少客户端进行CPU频率和数量的选择（参考[Actor模型](https://www.ttalk.im/topics/21#Actor%E8%B0%83%E5%BA%A6)中的调度部分）。\r\n\r\n当运营一个EMQ服务器的时候，如果在消息量级和客户端数量没有明显变化的情况下，CPU突然飙升，就要去考虑下是否出现客户端频繁上下线的情况。当然这只是一个简单的例子，还有很多情况在此就不一一列举了。\r\n\r\n\r\n\r\n	f	2019-09-05 15:22:06.647895
\.


--
-- Data for Name: tags; Type: TABLE DATA; Schema: public; Owner: david
--

COPY public.tags (id, title, intro, enabled) FROM stdin;
\.


--
-- Name: links_id_seq; Type: SEQUENCE SET; Schema: public; Owner: david
--

SELECT pg_catalog.setval('public.links_id_seq', 1, false);


--
-- Name: page_tags_id_seq; Type: SEQUENCE SET; Schema: public; Owner: david
--

SELECT pg_catalog.setval('public.page_tags_id_seq', 1, false);


--
-- Name: pages_id_seq; Type: SEQUENCE SET; Schema: public; Owner: david
--

SELECT pg_catalog.setval('public.pages_id_seq', 174, true);


--
-- Name: tags_id_seq; Type: SEQUENCE SET; Schema: public; Owner: david
--

SELECT pg_catalog.setval('public.tags_id_seq', 1, false);


--
-- Name: links links_pkey; Type: CONSTRAINT; Schema: public; Owner: david
--

ALTER TABLE ONLY public.links
    ADD CONSTRAINT links_pkey PRIMARY KEY (id);


--
-- Name: page_tags page_tags_pkey; Type: CONSTRAINT; Schema: public; Owner: david
--

ALTER TABLE ONLY public.page_tags
    ADD CONSTRAINT page_tags_pkey PRIMARY KEY (id);


--
-- Name: pages pages_pkey; Type: CONSTRAINT; Schema: public; Owner: david
--

ALTER TABLE ONLY public.pages
    ADD CONSTRAINT pages_pkey PRIMARY KEY (id);


--
-- Name: tags tags_pkey; Type: CONSTRAINT; Schema: public; Owner: david
--

ALTER TABLE ONLY public.tags
    ADD CONSTRAINT tags_pkey PRIMARY KEY (id);


--
-- Name: links_title_key; Type: INDEX; Schema: public; Owner: david
--

CREATE UNIQUE INDEX links_title_key ON public.links USING btree (title);


--
-- Name: page_tag_key; Type: INDEX; Schema: public; Owner: david
--

CREATE UNIQUE INDEX page_tag_key ON public.page_tags USING btree (page_id, tag_id);


--
-- Name: tags_title_key; Type: INDEX; Schema: public; Owner: david
--

CREATE UNIQUE INDEX tags_title_key ON public.tags USING btree (title);


--
-- PostgreSQL database dump complete
--

